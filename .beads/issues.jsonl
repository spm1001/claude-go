{"id":".claude-0fi","title":"Test Google Workspace MCP tool coverage","description":"Test Calendar, Docs, Sheets, Chat, Drive tools in google-workspace MCP. Verify which work with current ITV OAuth scopes.","design":"## Tools to test\n- calendar.listEvents, calendar.createEvent\n- docs.create, docs.getText\n- sheets.getText, sheets.getRange\n- chat.listSpaces (may fail — new scope)\n- drive.search\n\n## Expected issues\n- Chat scopes may not be approved by ITV\n- gmail.modify vs gmail.readonly difference","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-03T14:53:34.259077Z","updated_at":"2026-01-03T15:31:37.247747Z","closed_at":"2026-01-03T15:31:37.247747Z","close_reason":"Moved to mcp-workspace-google-9z2 in ~/Repos/mcp-workspace-google"}
{"id":".claude-0zt","title":"Make /open skill's beads invocation more effective","description":"The /open skill says to invoke Skill(beads) when BEADS_EXISTS=true, but this instruction didn't land - Claude skipped it and went straight to synthesis. The skill needs to make this step harder to miss.","design":"## Options\n1. Add reminder to script output: \"BEADS_SKILL_INVOKE=true\" as explicit flag\n2. Restructure skill to make step 2 more prominent\n3. Add to script output itself: \"→ Next: Skill(beads)\"\n4. Combine steps 1+2 so beads skill loads as part of context gathering\n\n## Consideration\nThe skill is already clear (\"If BEADS_EXISTS=true: Skill(beads)\"). \nThe failure mode is Claude reading the synthesis instruction before completing prerequisites.\nMaybe the fix is ordering/prominence, not more words.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T09:09:54.867842Z","updated_at":"2025-12-26T09:33:19.043247Z","closed_at":"2025-12-26T09:33:19.043247Z","close_reason":"Added explicit '→ Next: Skill(beads)' reminder to script output. Makes the instruction visible in the output Claude parses, not just in the skill prose."}
{"id":".claude-17w","title":"Decide MCP/skill pairing strategy","design":"Standardize: skill lives with MCP repo OR accept mixed patterns","notes":"Resolution: Skills with companion MCP servers live in the MCP repo (symlinked into ~/.claude/skills). Skills without MCP companions live wholly in ~/.claude/skills. Applied: maintaining-linux-servers stays local with references copied in; obsolete linux-server-fluency deleted from infra-linux-servers repo.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T18:58:02.227308Z","updated_at":"2025-12-22T10:04:10.328243Z","closed_at":"2025-12-22T10:04:10.328253Z"}
{"id":".claude-1u4","title":"Rename MCP repos to mcp-* prefix","design":"Part of naming convention cleanup. Pattern established: skill-* for skills, mcp-* for MCP servers.\n\nRepos to rename:\n- infra-mcp-workspace → mcp-workspace (Google Workspace MCP server)\n- myitv-search-mcp → mcp-myitv-search (ITV intranet search)\n- infra-html-tool-executor → mcp-html-executor (HTML tools via JSDOM)\n\nAfter rename: update any references in CLAUDE.md, .mcp.json files, symlinks.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-28T21:39:55.579674Z","updated_at":"2025-12-28T22:05:18.011977Z","deleted_at":"2025-12-28T22:05:18.011977Z","deleted_by":"daemon","delete_reason":"delete","original_type":"task"}
{"id":".claude-1ws","title":"Fix episodic-memory path in close-session skill","description":"The close-session skill checks 'command -v episodic-memory' but the CLI isn't in PATH — it's at ~/.claude/plugins/cache/superpowers-marketplace/episodic-memory/*/cli/episodic-memory. Update the skill to use the full path or a glob pattern.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-24T09:45:50.846135Z","updated_at":"2025-12-24T12:45:37.571297Z","closed_at":"2025-12-24T12:45:37.571297Z","close_reason":"Fixed: updated SKILL.md to use full path with glob resolution instead of relying on PATH"}
{"id":".claude-1wz","title":"SessionStart and SessionStop hooks for automating handoffs","design":"Automate session boundaries with hooks that:\n\n**SessionStart:**\n- Detect working directory → map to Todoist project (Repos, Work, etc.)\n- Fetch and display relevant tasks from Todoist\n- Show local bd ready if .beads exists\n- Detect model version changes → prompt for config review\n\n**SessionStop:**\n- Capture session learnings\n- Update CLAUDE.md if discoveries made\n- Close/update relevant beads\n\nRequires:\n- Todoist MCP authentication check (auth is short-lived)\n- Directory pattern matching\n- Model version tracking\n- Graceful fallbacks\n\nConsolidates: .claude-t63 (model-change detection), .claude-bl0 (context-aware SessionStart)","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-14T23:40:03.265011Z","updated_at":"2025-12-22T10:46:41.139235Z","closed_at":"2025-12-22T10:46:41.139235Z","close_reason":"No fully automatic approach found. Manual /handoff and /close commands work well enough."}
{"id":".claude-2ao","title":"Add Claude's view of key decisions before Phase 6 questions","description":"Before asking reflection questions, Claude should offer its summary of key decisions/moments from the session. Gives user something to react to instead of cold retrieval.","design":"Add pre-reflection summary between Phase 5 and Phase 6 questions. Format: 'Here's what stood out to me: [list]. What resonates with you?'","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T00:36:22.547233Z","updated_at":"2025-12-26T09:59:01.300343Z","closed_at":"2025-12-26T09:59:01.300343Z","close_reason":"Added 'Step 1: Offer Claude's View First' to Phase 6 in close-session skill. Claude now shares key observations before asking reflection questions, giving user something to react to rather than cold retrieval."}
{"id":".claude-2b6","title":"Built Natural Planning Model skill for strategic work (or included in todoist-gtd)","design":"Link GTD Natural Planning Model (purpose, vision, brainstorming, organizing, next actions) to beads skill. Should inform how issues are structured and how bd skill guides creation.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-14T19:29:18.645198Z","updated_at":"2025-12-30T19:48:13.008023Z","closed_at":"2025-12-30T19:48:13.008023Z","close_reason":"Relocated to skill-todoist-gtd repo. NPM is GTD methodology, belongs bundled there."}
{"id":".claude-2bp","title":"Verify cross-references after skill rename","design":"After major skill rename session (2025-12-28), grep for old names that might still be referenced.\n\nOld → New:\n- working-together → collaborating\n- looking → screenshotting\n- close-session → session-closing\n- svg-dataviz → diagramming\n- maintaining-linux-servers → server-maintenance\n- itv-brand → itv-styling\n- skill-quality-gate → skill-checker\n- driving-browser-skill → browser-driving\n\nCheck: CLAUDE.md (global + project), other skills, commands, any .md files in ~/.claude","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-28T21:49:11.129649Z","updated_at":"2025-12-28T22:05:18.157235Z","deleted_at":"2025-12-28T22:05:18.157235Z","deleted_by":"daemon","delete_reason":"delete","original_type":"task"}
{"id":".claude-2o6","title":"Add bd info --whats-new to /open script","description":"Skill says to check bd info --whats-new at session start, but /open script doesn't do this. Given how fast bd evolves, surfacing version changes matters.","design":"## Approach\nAdd to open-context.sh after BEADS section. Only show if bd exists and output is non-empty.\nConditional on BEADS_EXISTS=true.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T09:06:57.536544Z","updated_at":"2025-12-26T09:33:18.926656Z","closed_at":"2025-12-26T09:33:18.926656Z","close_reason":"Added bd info --whats-new output to BEADS section of open-context.sh. Shows version changes when beads exists."}
{"id":".claude-2pj","title":"Hook-writing skill and documentation","design":"Create a skill for writing Claude Code hooks correctly.\n\nKEY LEARNINGS (Dec 2025 session):\n\n⚠️ WARNING: Anthropic's documentation is incomplete/misleading about hook output formats\\!\nThe claude-code-guide agent gave incorrect info - had to learn from actual validation errors.\n\nACTUAL SCHEMA (from validation error output):\n\nTop-level fields (available to ALL hooks):\n  - continue: boolean (optional)\n  - suppressOutput: boolean (optional)\n  - stopReason: string (optional)\n  - decision: 'approve' | 'block' (optional)\n  - reason: string (optional)\n  - systemMessage: string (optional)  ← USE THIS FOR SessionStart/SessionEnd\n  - permissionDecision: 'allow' | 'deny' | 'ask' (optional)\n\nhookSpecificOutput ONLY works for these events:\n  - PreToolUse: hookEventName, permissionDecision, permissionDecisionReason, updatedInput\n  - UserPromptSubmit: hookEventName, additionalContext (REQUIRED)\n  - PostToolUse: hookEventName, additionalContext (optional)\n\nSessionStart and SessionEnd do NOT have hookSpecificOutput definitions\\!\nMust use top-level 'systemMessage' field instead.\n\nCORRECTED PATTERNS:\n\nFor SessionStart/SessionEnd:\n  {\"systemMessage\": \"Your message here\"}\n\nFor PostToolUse (like WebFetch reminder):\n  {\"hookSpecificOutput\": {\"hookEventName\": \"PostToolUse\", \"additionalContext\": \"...\"}}\n\nFor UserPromptSubmit:\n  {\"hookSpecificOutput\": {\"hookEventName\": \"UserPromptSubmit\", \"additionalContext\": \"...\"}}\n\nEXIT CODES:\n  - 0: Success, JSON parsed\n  - 2: Emergency block, stderr only, JSON ignored\n\nGOTCHAS:\n  - Documentation says hookSpecificOutput works everywhere - IT DOESN'T\n  - Must test hooks against actual validation, not just docs\n  - Different events have DIFFERENT available fields\n  - Quote all variables, use absolute paths\n\nSCOPE:\n  - Document ACTUAL schema for all hook events\n  - Provide tested templates for common patterns\n  - Include testing guidance\n  - Note documentation gaps\n\nRELATED:\n  - Working examples: ~/.claude/hooks/session-start.sh, session-end.sh\n  - WebFetch hook in settings.json (PostToolUse example)","notes":"ADDITIONAL FINDINGS FROM DEC 2025 TESTING:\n\nCONFIRMED: SessionStart/End hook output is architecturally invisible to users.\n\nTESTED (all failed for user visibility):\n- Plain echo → silent\n- JSON hookSpecificOutput → validation error (only valid for PreToolUse, UserPromptSubmit, PostToolUse)\n- JSON systemMessage → silent\n- stderr + exit 2 → silent (unlike validation errors which DO show)\n\nGITHUB ISSUES:\n- #11120: Feature request for displayOutput flag (open, no response)\n- #4084: Hook output visibility blocked\n- #12151: Plugin hook output not captured\n\nKEY INSIGHT: The only visible output is Claude Code's OWN error messages (like JSON validation). User-provided output is silently discarded for SessionStart/End.\n\nWORKAROUND IMPLEMENTED:\n- Hooks simplified to silent file operations\n- Created /handoff slash command for manual session context check\n\nSkill auto-activation does NOT work as hoped - skills trigger on task context, not session events.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-20T07:51:11.90891Z","updated_at":"2025-12-22T10:41:02.575008Z","closed_at":"2025-12-22T10:41:02.575008Z","close_reason":"Hook schema learnings documented in design field. Reference material, not standalone skill."}
{"id":".claude-2po","title":"Figured out how to review and plan beads across Repos","design":"## Vision\nSingle view of all open beads across all repos (Work, Repos, ~/.claude).\nAnswers: \"What's open everywhere?\"\n\n## Components\n\n### 1. Scanner Script\nScan known bead locations:\n- ~/.claude/.beads\n- ~/Repos/.beads (meta)\n- ~/Repos/*/.beads (each repo)\n- ~/Google Drive/My Drive/Work/.beads\n- ~/Google Drive/My Drive/Work/**/.beads (project-specific)\n\nFor each: `bd list --json` and collect.\n\n### 2. Output Format\nCombined JSON/markdown showing:\n- Location (repo/folder)\n- Open epics with child task counts\n- Ready items (unblocked)\n- In-progress items\n\n### 3. Integration Points\n- SessionStart hook: Show summary on startup\n- Slash command: /beads-all\n- Weekly review: Full inventory\n\n### 4. Context-Aware Filtering\nWhen in ~/Repos: Show Repos beads prominently\nWhen in ~/Google Drive/Work: Show Work beads prominently\nWhen in ~/.claude: Show config beads\n\n## Implementation\nCould be:\n- Shell script (simple, portable)\n- Python script (richer formatting)\n- HTML tool (visual dashboard)","notes":"SESSION DISCUSSION (2025-12-26):\n\nUser insight: \"When I'm reasoning about what to work on I'd ideally be able to reason *across* my projects - and do work with you to shape the agenda. But I'm mainly reduced to dipping in and out of Repo folders to peck at things.\"\n\nKEY CLARIFICATION: This is NOT what bd's cross-project dependencies solve. Those are for \"A depends on B being shipped\" — orchestration, not visibility.\n\nWhat's needed: Unified dashboard/synthesis — \"here are the P1s across everything, help me prioritize.\"\n\nSTILL RELEVANT: The original design (scanner + synthesis) is the right approach. Not a bd feature, but a tool that queries bd across repos.\n\nIMPLEMENTATION CONSIDERATION: Could be a /portfolio command that runs as part of weekly review. SessionStart integration might be too noisy for daily use.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-14T19:31:56.481193Z","updated_at":"2025-12-30T20:09:19.250989Z","closed_at":"2025-12-30T20:09:19.250989Z","close_reason":"Done — implemented as part of beads skill."}
{"id":".claude-3dq","title":"Build skill to discover official MCP servers","design":"## Problem\n\nMCPs exist that Claude doesn't know about unless explicitly enabled per-project. workspace-developer is one example - provides Google API docs, very useful for Apps Script work, but not globally enabled.\n\n## Desired Outcome\n\nA skill (or automated process) that:\n1. Scans known sources for official/vetted MCP servers\n2. Compares against currently-installed MCPs\n3. Suggests relevant ones based on current work context\n\n## Sources to Scan\n\n- Anthropic's official MCP repository (modelcontextprotocol org on GitHub)\n- Google's workspace-developer MCP and similar official integrations\n- Possibly community-curated lists (with trust assessment)\n\n## Open Questions\n\n- Should this be a skill (invoked on demand) or a hook (runs at session start)?\n- How to assess relevance to current project?\n- How to handle trust/vetting of community MCPs vs official ones?\n- Integration with the \"Available MCPs\" section in global CLAUDE.md\n\n## Prior Art\n\n- workspace-developer: Google's official MCP for Workspace API docs\n- The MCP ecosystem is growing - need to stay current","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T23:37:16.483858Z","updated_at":"2025-12-30T20:30:21.279229Z","closed_at":"2025-12-30T20:30:21.279229Z","close_reason":"Instead of building a discovery skill, adding 'Services to watch for MCPs' section to CLAUDE.md. Landscape is too fragmented for automation."}
{"id":".claude-43e","title":"Refactor /open /close with handoff accumulation and bidirectional learning","design":"## Context\nFrom xr4 discussion: user wants to develop architectural intuition through working with Claude. Key insight: /close could ask learning questions, user answers, Claude reflects. This makes the ritual bidirectional and creates a learning artifact.\n\nAdditionally, .handoff files are too valuable to overwrite — they're opinionated summaries worth accumulating.\n\n## Scope\n\n### Handoff Accumulation\n- Stop overwriting .handoff\n- Store handoffs with timestamp + project metadata\n- Location TBD: central (~/.claude/handoffs/) vs per-repo vs hybrid\n\n### Bidirectional /close\n- After standard closedown, Claude asks 1-2 learning questions:\n  - \"What decision did we make that you want to remember?\"\n  - \"What did you learn about the problem domain?\"\n  - \"What would you do differently?\"\n- User answers\n- Claude reflects on answers using wider knowledge\n- Reflection stored with handoff\n\n### /open Discovery\n- Look in central handoffs folder\n- Pick most apt (by project, recency) or ask if ambiguous\n- Time awareness: \"5 minutes ago\" not \"yesterday\"\n\n### Fixes\n- Path error in /close (needs diagnosis)\n- CWD flexibility already works, preserve it\n\n## Design Questions\n1. Central vs per-repo vs hybrid storage?\n2. Handoff + reflection: one file or two?\n3. Naming scheme for accumulated handoffs?\n4. How does /open match handoffs to context?\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","notes":"SESSION: 2025-12-26 (continued)\n\nCOMPLETED THIS SESSION:\n- Session 1 work (ftz bug fix, dqg handoff accumulation) \n- Bonus: Initial c9j implementation (bidirectional reflection recording)\n- Integration tests passed\n- Session boundary pattern added to beads skill\n\nc9j changed from \"implement\" to \"review adequacy\" — did quick implementation during /close, now needs validation.\n\nREMAINING:\n- c9j: Review/strengthen bidirectional reflection implementation\n- zfw: Improve /open discovery with central handoffs\n- 4di: Review episodic-memory integration (parallel)\n\nNEXT SESSION:\nTest the infrastructure with fresh Claude. Does handoff + beads provide clean pickup?\nThen review c9j adequacy or tackle zfw.","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-25T22:25:43.821431Z","updated_at":"2025-12-26T00:31:14.741512Z","closed_at":"2025-12-26T00:31:14.741512Z","close_reason":"Core objective met: handoff accumulation, bidirectional reflection, /open discovery with central handoffs. P2 follow-on work (43e.1, 4di) continues as standalone tasks."}
{"id":".claude-43e.1","title":"Added plan file cleanup to /close ritual","description":"When closing an epic, /close should detect and handle associated plan files.","design":"## Approach\n1. Detect plan files matching epic (by ID in filename or content)\n2. Offer: archive or delete\n3. If archive, move to ~/.claude/plans/archive/{name}-{date}.md\n\n## Where\nAdd to Phase 3 (Execute) in close-session SKILL.md, after beads updates.\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","acceptance_criteria":"- [ ] /close detects plan files when closing epics\n- [ ] Offers archive/delete choice\n- [ ] Archive moves to plans/archive/ with date suffix\n- [ ] Delete removes the file\n- [ ] Skip if no plan file found","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T00:14:38.173078Z","updated_at":"2025-12-29T09:48:29.141886Z","closed_at":"2025-12-29T09:48:29.141886Z","close_reason":"Migrated to skill-session-management (ssm-x06)","dependencies":[{"issue_id":".claude-43e.1","depends_on_id":".claude-43e","type":"parent-child","created_at":"2025-12-26T00:14:38.174791Z","created_by":"daemon","metadata":"{}"}]}
{"id":".claude-45b","title":"Adopt ASCII project structure diagrams in per-project CLAUDE.md","description":"Add ASCII directory tree diagrams as a standard pattern in project CLAUDE.md files.\n\nFrom ClaudeForge analysis: ASCII diagrams help Claude quickly understand directory layout\nwithout needing to run ls commands. Simple, token-efficient, and effective.","design":"## Pattern from ClaudeForge\n\nClaudeForge templates include ASCII tree diagrams:\n\n```\nproject/\n├── src/\n│   ├── components/\n│   │   └── ...\n│   ├── services/\n│   │   └── ...\n│   └── index.ts\n├── tests/\n├── package.json\n└── README.md\n```\n\n## Why This Helps\n\n1. **Immediate orientation**: Claude sees structure without tool calls\n2. **Token efficient**: ~50 tokens for a useful overview\n3. **Stable reference**: Doesn't drift like auto-generated listings\n4. **Human readable**: Users benefit too when reading CLAUDE.md\n\n## Implementation\n\n### Manual Approach\nWhen creating/updating project CLAUDE.md, include a tree diagram:\n\n```bash\n# Generate tree (exclude common noise)\ntree -L 2 -I 'node_modules|.venv|__pycache__|.git' --dirsfirst\n```\n\n### Automated in /init-project-claude-md\nThe init skill (sibling bead) should auto-generate this section.\n\n### Maintenance\n- Update when major restructuring happens\n- Don't track every file change\n- Keep to 2-3 levels of depth\n\n## Scope\n\nWhich projects need this?\n\n**High value:**\n- ~/Repos/* (development projects)\n- Complex subdirectories of Google Drive Work projects\n\n**Low value:**\n- Simple single-file projects\n- Projects where structure is obvious from name\n\n## Example for claude-memory\n\n```\nclaude-memory/\n├── src/\n│   └── mem/\n│       ├── cli.py          # Main CLI entry point\n│       ├── database.py     # SQLite + FTS5 operations\n│       ├── extraction.py   # LLM-based content extraction\n│       ├── adapters/       # Source-specific adapters\n│       └── glossary.py     # Entity resolution\n├── scripts/\n│   └── close-extraction.sh # Hook integration\n├── tests/\n└── pyproject.toml\n```\n\n## Success Criteria\n- [ ] 3+ project CLAUDE.md files have ASCII diagrams\n- [ ] Pattern documented in global CLAUDE.md or exegesis\n- [ ] /init-project-claude-md skill generates diagrams automatically\n\n## Effort\n- Adding to existing projects: Low (10 min each)\n- Automating in init skill: Part of that bead's scope","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-31T16:04:28.161911Z","updated_at":"2026-01-03T14:14:55.344698Z","closed_at":"2026-01-03T14:14:55.344698Z","close_reason":"Deferring - not a priority right now"}
{"id":".claude-45v","title":"Add /init-project-claude-md skill for bootstrapping new projects","description":"Create a skill that generates skeleton project CLAUDE.md files for new repositories,\ninspired by ClaudeForge's initialization workflow but producing our style of documentation.\n\nClaudeForge (https://github.com/alirezarezvani/ClaudeForge) has an interactive init flow\nthat explores a repo and generates CLAUDE.md. We want similar convenience but with our\nstructure and quality standards.","design":"## Context from ClaudeForge Analysis\n\nClaudeForge's approach:\n1. Explores repo structure (package.json, pyproject.toml, etc.)\n2. Detects tech stack, team size, project phase\n3. Generates CLAUDE.md from templates (solo/small-team/modular)\n4. Has a \"guardian agent\" for ongoing sync\n\nWhat we want differently:\n- Our structure (not ClaudeForge's generic templates)\n- Integration with existing skills architecture\n- No auto-sync (we prefer human-in-the-loop /close rituals)\n\n## Proposed Skill Structure\n\n```\n~/.claude/skills/init-project-claude-md/\n├── SKILL.md           # Skill definition\n└── templates/\n    ├── python-repo.md     # Python project template\n    ├── node-repo.md       # Node.js project template\n    ├── infra-repo.md      # Infrastructure docs template\n    └── generic.md         # Fallback template\n```\n\n## Workflow\n\n1. **Trigger**: User says \"init claude.md\" or runs `/init-project-claude-md`\n\n2. **Detection Phase**:\n   - Check for package.json → Node template\n   - Check for pyproject.toml/setup.py → Python template\n   - Check for Dockerfile, terraform, ansible → Infra template\n   - Fallback to generic\n\n3. **Exploration Phase**:\n   - Read existing README.md for project description\n   - List directory structure\n   - Identify key entry points (main.py, index.js, etc.)\n   - Check for existing .claude/ directory\n\n4. **Generation Phase**:\n   - Fill template with detected values\n   - Generate ASCII directory tree\n   - Add tech stack section\n   - Add setup commands (from README or inferred)\n\n5. **Review Phase**:\n   - Show generated CLAUDE.md to user\n   - Ask for confirmation before writing\n   - Open in editor for refinement\n\n## Template Structure (Our Style)\n\n```markdown\n# CLAUDE.md\n\n## What This Project Does\n[One paragraph from README or user input]\n\n## Project Structure\n[ASCII tree diagram]\n\n## Key Files\n[Prose explanation of important directories/files]\n\n## Setup\n[Commands to get running]\n\n## Development Workflow\n[How to test, build, deploy]\n\n## Decisions \u0026 Gotchas\n[Empty section for future documentation]\n```\n\nNote: Deliberately minimal. Grows organically via /close insights.\n\n## Success Criteria\n- [ ] Detects Python/Node/Infra projects correctly\n- [ ] Generates ASCII tree diagram\n- [ ] Extracts project description from README\n- [ ] Produces valid CLAUDE.md in our style\n- [ ] Asks for confirmation before writing\n- [ ] Works for ~/Repos projects\n\n## Considerations\n\n1. **Don't over-generate**: ClaudeForge templates are 150-175 lines. Ours should start at ~50 lines and grow organically.\n\n2. **No auto-sync**: We document via /close reflection, not automated scanning.\n\n3. **Respect existing**: If CLAUDE.md exists, offer to enhance rather than replace.\n\n4. **Project vs global**: This creates PROJECT-level CLAUDE.md, not modifications to global ~/.claude/CLAUDE.md.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-31T16:04:26.330497Z","updated_at":"2026-01-03T14:14:54.19832Z","closed_at":"2026-01-03T14:14:54.19832Z","close_reason":"Deferring - not a priority right now"}
{"id":".claude-485","title":"Extended episodic-memory (or similar) to work across Claude desktop and Code","design":"Build infrastructure for unified memory across Claude Desktop and Claude Code, with background processing for learning extraction.\n\nSTARTING POINT: Review Jesse Kriss's episodic-memory system (superpowers submodule) - full semantic search of past conversations via SQLite + vectors.\n\nKEY COMPONENTS:\n1. Conversation archive: Parse JSONL (Code) + Desktop transcripts into unified store\n2. Vector search: Semantic retrieval of relevant past context\n3. Learning extraction: Distill patterns/decisions from conversations (needs LLM)\n4. Background processing: 'LLM cronjob' for heavy extraction work\n5. Cross-platform sync: Desktop and Code share the same memory\n\nCONSTRAINTS:\n- Anthropic doesn't provide integration between Desktop and Code memory\n- Background LLM processing needs infrastructure (launchd? direct API?)\n- Must be fast at session start - heavy work happens async\n\nRELATED:\n- .claude-w0t (conversation memory extraction prototype)\n- .claude-tvq (session hooks for triggering)\n\nBLOCKS: Needs Jesse's approach reviewed first before implementation design.","notes":"Blocked by .claude-ers (simpler conversation memory spec). Once we have the summary-based approach working for Code, can evaluate extending to Desktop.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-20T07:36:24.954494Z","updated_at":"2025-12-30T19:07:53.96797Z","closed_at":"2025-12-30T19:07:53.96797Z","close_reason":"Superseded — pivoted from cross-platform MCP server to grounding skill approach. Simpler architecture, same goal.","dependencies":[{"issue_id":".claude-485","depends_on_id":".claude-67z","type":"blocks","created_at":"2025-12-22T10:19:57.358342Z","created_by":"daemon","metadata":"{}"},{"issue_id":".claude-485","depends_on_id":".claude-ers","type":"blocks","created_at":"2025-12-26T22:54:37.684186Z","created_by":"daemon","metadata":"{}"}]}
{"id":".claude-4di","title":"Completed episodic-memory integration and decided whether to keep","description":"Assess current episodic-memory value vs issues. Decide: fix, deprecate, or redesign.","design":"## Context\nEpisodic-memory evaluation — determining whether to keep, fix, complement, or deprecate.\n\n## Plan\nFull evaluation plan at: ~/.claude/plans/structured-beaming-glade.md\n\n## Child Tasks (sequential)\n1. .claude-ghj: Verify correct usage (read docs, check patterns)\n2. .claude-oip: Controlled tests (known-phrase, keyword, semantic, pollution audit)\n3. .claude-hwo: Assess fundamental fit (embedding model, chunking, alternatives)\n4. .claude-o1v: Research modern RAG/embedding options\n5. .claude-xx8: Make keep/fix/complement/deprecate decision\n\n## North Star\n\"What interesting things have we built that others might find useful?\"\n- Artifacts (skills, MCPs, workflows)\n- Learnings (patterns, gotchas, insights)\n\n## Session Notes\n2025-12-26: Created epic structure. Initial tests showed poor results (1-6% match, pollution). Next session starts with Phase 1.","acceptance_criteria":"- [ ] Sync issue diagnosed and fixed (or documented)\n- [ ] Large summary issue diagnosed\n- [ ] Decision made: fix/deprecate/redesign\n- [ ] If fix: issues resolved\n- [ ] If redesign: plan documented","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-25T23:46:41.199252Z","updated_at":"2025-12-26T22:54:10.412029Z","closed_at":"2025-12-26T22:54:10.412029Z","close_reason":"Evaluation complete. Findings:\n\n1. CORPUS: 45% noise (warmups, summarizer pollution, rituals)\n2. EMBEDDINGS: Too flat — clusters by text similarity, not work-type\n3. USAGE: Claude reads whole conversations (up to 1MB), not chunks\n4. VALUE: Summaries for triage, not vectors for similarity\n\nDecision: COMPLEMENT\n- Keep episodic-memory for keyword search (it works)\n- Fix summary generation (80% missing)\n- Add triage guidance: read summary first, drill only if promising\n- Vectors are optional overhead, not core value\n\nNext: Spec simpler conversation memory system based on summaries + text search.","dependencies":[{"issue_id":".claude-4di","depends_on_id":".claude-43e","type":"parent-child","created_at":"2025-12-25T23:46:50.116326Z","created_by":"daemon","metadata":"{}"}]}
{"id":".claude-4im","title":"Add forward momentum to /close handoff State field","design":"The State field in .handoff currently describes what exists (inventory) but not where to go next. Previous Claude left:\n\n  'MCP has 4 tools... 3 beads open... scratch file not committed'\n\nThis is snapshot, not momentum. A useful State would be:\n\n  'Next: Keep mapping URL patterns via top nav. SITEMAP.md only covers search results and redirects — main navigation unexplored.'\n\nFIX: Update /close skill to prompt for 'suggested next action' as part of State. The question isn't 'what's the current state?' but 'if the user opens here tomorrow, what should they do first?'\n\nFile: ~/.claude/skills/close-session/SKILL.md","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T13:36:00.266988Z","updated_at":"2025-12-23T16:00:12.280324Z","closed_at":"2025-12-23T16:00:12.280324Z","close_reason":"Replaced Pull with Interesting/Next fields. Question framing matters more than structure."}
{"id":".claude-5lw","title":"Fix handoff/open ritual to follow work location","design":"## Problem\nCurrently .handoff is global (~/.claude/.handoff), written at launch directory. This causes:\n- Handoff from project A shows up when opening project B\n- Sessions spawned from container dirs (~/Repos, ~/Work) write handoff to wrong place\n- Work that *creates* a new project leaves handoff in container, not the new project\n\n## Solution\nMake handoff follow the work, not the launch directory.\n\n### At /close:\n1. Detect where substantive work happened:\n   - New git repo created → that's the project\n   - Concentrated file edits in specific directory → that's the project\n   - .beads/ created → that's the project\n   - Fallback: launch directory (if truly scattered/navigational)\n\n2. Write .handoff to detected project directory\n\n3. Nudge user: \"Handoff written to ~/Repos/foo/.handoff. Start next session there for continuity.\"\n\n### At /open:\n- Read ./.handoff (per-project) if exists\n- No global fallback - if no local handoff, that's fine\n\n### Related fixes to include:\n- Date bug in handoff generation (says 2024 not 2025)\n- Episodic memory alignment (ensure looking at same scope as handoff)\n- Momentum capture improvements (what goes INTO handoff)","notes":"Implemented per-project handoff with work location detection. Changes in .gitignore, CLAUDE.md, commands/open.md, skills/close-session/SKILL.md","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-23T11:55:53.341289Z","updated_at":"2025-12-23T12:09:43.867934Z","closed_at":"2025-12-23T12:09:43.867943Z"}
{"id":".claude-5ss","title":"Test looking skill with multiple monitors","design":"Test screencapture behavior with multi-monitor setup. Questions: Does -m capture main only? Does -D work for specific displays? Update SKILL.md limitations section with findings.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-15T23:05:38.73625Z","updated_at":"2025-12-23T16:26:44.515003Z","closed_at":"2025-12-23T16:26:44.515003Z","close_reason":"Multi-monitor works - tested on user's multi-monitor setup, captures succeeded without issues."}
{"id":".claude-61p","title":"Write README for spm1001/workspace fork","description":"Document standalone OAuth setup for team sharing. Branch: itv-auth.","design":"## Content needed\n- Why the fork exists (ITV OAuth approval)\n- How to set up credentials.json\n- Build instructions\n- How to sync with upstream","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-03T14:53:42.195963Z","updated_at":"2026-01-03T15:33:21.904764Z","closed_at":"2026-01-03T15:33:21.904764Z","close_reason":"Created FORK.md documenting standalone OAuth setup, credentials config, and upstream sync"}
{"id":".claude-67z","title":"Review Jesse's episodic-memory before installing","design":"Review obra's episodic-memory skill in superpowers submodule before installing.\n\nQuestions to answer:\n- What does it actually do? (architecture, data flow)\n- Where does it store data? (privacy/cleanup implications)\n- What hooks/triggers does it use?\n- Token cost at session start?\n- How does it integrate with /close workflow?\n- Any security concerns? (what gets indexed)\n\nLocation: ~/.claude/skills/anthropic/ or superpowers submodule\nReference: https://blog.fsck.com/2025/10/23/episodic-memory/\n\nDon't install until reviewed and comfortable with the approach.","notes":"RESOLVED: 2025-12-22\n\nInstalled and verified working.\n\n## What's Running\n- Plugin: episodic-memory@superpowers-marketplace v1.0.15\n- Archive: ~/.config/superpowers/conversation-archive/\n- CLI: ~/.claude/plugins/cache/.../cli/episodic-memory\n\n## Status\n- 55 conversations indexed (out of ~960)\n- SessionStart hook syncs incrementally (10 per run)\n- Search functional via CLI and MCP tools\n\n## Trial Period\n2-3 weeks to evaluate. Jesse's test: \"Ask Claude if episodic memory has been useful.\"\n\n## Integration\n- close-session skill already references episodic-memory sync\n- search-conversations agent available\n- MCP tools available","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-22T10:19:52.809349Z","updated_at":"2025-12-22T13:32:00.727523Z","closed_at":"2025-12-22T13:32:00.727534Z"}
{"id":".claude-6fo","title":"Add 'check bd blocked for strategic context' to beads skill","description":"At session start, checking only bd ready gives task queue but not strategic picture. Should also check bd blocked to understand dependency graph and what completing current work unlocks.","design":"Add to Session Start Protocol section: after bd ready, run bd blocked to see what's waiting. Helps orient to 'what am I building toward' not just 'what can I do next'.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T22:40:09.526885Z","updated_at":"2025-12-30T19:17:06.389411Z","closed_at":"2025-12-30T19:17:06.389411Z","close_reason":"Relocated to skill-beads repo as skill-beads-e4e (P1). Skills have moved out of ~/.claude."}
{"id":".claude-6xl","title":"Investigate launch directory env var for looking skill","design":"Currently screenshots go to pwd. User wants them in the directory Claude was launched from. Investigate: Is there a CLAUDE_LAUNCH_DIR or similar? Can we capture initial pwd at skill load? Or document current behavior as intentional.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-15T23:05:38.923744Z","updated_at":"2025-12-23T16:26:44.757693Z","closed_at":"2025-12-23T16:26:44.757693Z","close_reason":"Fixed: Screenshots now default to /tmp/claude-screenshots/ for ephemeral captures."}
{"id":".claude-7jh","title":"Verify all skill symlinks resolve correctly","design":"After skill migration, verify symlinks work:\n\nls -la ~/.claude/skills/*/SKILL.md\n\nShould show resolved paths, not broken symlinks. Also test that skills load in new Claude session.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-28T21:49:12.539654Z","updated_at":"2025-12-28T22:05:18.186303Z","deleted_at":"2025-12-28T22:05:18.186303Z","deleted_by":"daemon","delete_reason":"delete","original_type":"task"}
{"id":".claude-85r","title":"Improve screenshotting skill proactive triggers","design":"Issue: Proactive use ('verify state after uncertain CLI operations') doesn't fire reliably.\n\nOptions:\n1. Add BEFORE/MANDATORY pattern to description\n2. Move proactive behavior to CLAUDE.md as baseline behavior\n3. Add specific trigger phrases: 'did that work?', 'check if it ran'\n\nTest with adversarial prompts to verify trigger reliability.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-28T21:13:48.427735Z","updated_at":"2025-12-28T22:05:18.242343Z","deleted_at":"2025-12-28T22:05:18.242343Z","deleted_by":"daemon","delete_reason":"delete","original_type":"task"}
{"id":".claude-95c","title":"Codify ritual prompts as structural scaffolding","description":"Observation: prompts like 'what have we missed?', 'what could go wrong?', 'what could be better?' are unreasonably effective but require user to remember to ask. These should be built into skill phase gates, hooks, or periodic nudges — not dependent on human memory. Also relates to inter-Claude communication (passing messages between parallel sessions).","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-28T10:00:54.996123Z","updated_at":"2025-12-29T09:48:29.176481Z","closed_at":"2025-12-29T09:48:29.176481Z","close_reason":"Migrated to skill-session-management (ssm-s55)"}
{"id":".claude-979","title":"Researched and decided whether to use bd close hooks mechanism","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T11:16:23.11452Z","updated_at":"2025-12-26T21:36:38.908307Z","closed_at":"2025-12-26T21:36:38.908307Z","close_reason":"Researched: bd close hooks (hooks.close config) run post-event when issues close. Useful for notifications/logging, not for blocking/enforcement. Not applicable to ritual gates — those need pre-event blocking which bd doesn't provide."}
{"id":".claude-9jf","title":"Sync claude-config-public with private config","design":"~/Repos/claude-config-public is the public version of ~/.claude with redactions.\n\nNeeds updating with:\n- Current CLAUDE.md (redact ITV-specific, personal details)\n- looking skill (for blog post)\n- Auto-update hooks/scripts\n- Any other shareable patterns\n\nBLOCKS:\n- Blog post: Giving Claude Eyes (looking skill)\n- Blog post: Auto-Update Hooks\n\nLast synced: Nov 2024 (stale)","notes":"Completed in separate session.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-19T22:22:14.237841Z","updated_at":"2025-12-20T08:25:25.997908Z","closed_at":"2025-12-20T08:25:25.997921Z"}
{"id":".claude-9ky","title":"Improve close skill to capture next direction/momentum in handoff","design":"## Problem\n\nThe handoff currently captures Done/Learned/State/Spark but misses **momentum** - what was about to happen next.\n\n## Failure Example (2025-12-23)\n\nSession built myitv-search MCP, then user said:\n\u003e \"now let's concentrate on those results... I think we need to do some test searches to work out the different kinds of information that are returnable, and teach the MCP to send you token-efficient extracts\"\n\nClaude started exploring raw API response, found different result types (PromotedItem, File, Page) - then session closed. Handoff said:\n\u003e State: MCP working, registered globally\n\nThis was true but incomplete. Lost the direction: \"enhance MCP to return token-efficient extracts with deep links.\"\n\n## Related Issue: Episodic Archive Location\n\nWhen session starts in Work folder but work happens in ~/Repos/myitv-search-mcp, the conversation archives to Work folder's archive. Finding \"the last conversation about X\" requires knowing which folder the session was launched from, not where the code lives.\n\nThis makes /open's episodic lookup fragile - it checks cwd's archive, but the relevant conversation might be in a parent/different folder's archive.\n\n## Proposed Fix\n\nAdd a \"Next\" or \"Momentum\" field to handoff:\n- What was the user about to do?\n- What direction was the conversation heading?\n- Capture even if work was \"complete\" - there's often a next step\n\nConsider: Should handoff capture the session's starting cwd separately from final cwd?","notes":"Subsumed by .claude-5lw (handoff ritual epic)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T11:43:46.279862Z","updated_at":"2025-12-23T11:56:10.843297Z","closed_at":"2025-12-23T11:56:10.843303Z"}
{"id":".claude-9um","title":"Review local and external skills one-by-one","design":"COMPLETED:\n- Deleted visual-documentation (superseded by looking skill)\n- Deleted ~/.claude/tools/capture_window.py (superseded by looking)\n- Reviewed 8 local skills - all solid conceptually\n\nDISCOVERED ISSUES:\n1. Skill descriptions don't follow Anthropic best practices:\n   - Should be third-person\n   - Should include user-detectable triggers (not abstract states like \"overcommitment\")\n   - working-with-sameer, todoist-strategy, core-fluency need rewrites\n\n2. skill-quality-gate doesn't check for:\n   - Third-person descriptions\n   - User-detectable trigger phrases\n   - Needs update based on Anthropic best practices doc\n\n3. Companion skills pattern:\n   - linux-server-fluency: ✓ correctly symlinked to infra-linux-servers\n   - workspace-fluency: diverged, needs merge (.claude-zqy)\n   - todoist-strategy: should move to infra-todoist-sync\n   - core-fluency: should move to claude-knowledge-graph\n\n4. WebFetch hook was being ignored - updated to stronger \"STOP\" framing\n\nREMAINING:\n- Rewrite skill descriptions (separate issue?)\n- Update skill-quality-gate checklist\n- Reorganize companion skills after merge","notes":"CLOSED 2025-12-21: Major cleanup complete.\n\nDONE:\n- beads (renamed from bd-issue-tracking)\n- core-fluency, crash-recovery (deleted - not used)\n- todoist-gtd (merged todoist-strategy + desired-outcomes)\n- infra-todoist-sync archived\n- workspace-fluency symlinked to repo\n- Skill descriptions: third-person rewrites\n\nREMAINING (new session):\n- Review: itv-brand, looking, session-closedown, svg-dataviz\n- Test: working-with-sameer (keep for now)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-19T23:08:31.56965Z","updated_at":"2025-12-21T20:13:12.993706Z","closed_at":"2025-12-21T20:13:12.993718Z"}
{"id":".claude-9vf","title":"Improve session open/close symmetry and skills pairing","design":"The /handoff and /close commands should work as a matched pair but don't.\n\nCurrent state:\n- /close invokes close-session skill, generates handoff prompt (Phase 5)\n- /handoff checks for digest files but isn't actually used\n\nProblems:\n1. Naming: 'handoff' is wrong - should be 'opening' or 'picking-up' to pair with 'close'\n2. Not wired together: /close generates something, /handoff looks for something else\n3. Not being used: neither Claude nor user invokes /handoff at session start\n\nGoal: Symmetric pair that actually works:\n- /close → generates session context artifact\n- /opening → consumes it and orients the new session","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-22T10:15:44.6254Z","updated_at":"2025-12-22T21:54:02.00664Z","closed_at":"2025-12-22T21:54:02.00664Z","close_reason":"Completed: Symmetric /open and /close commands now work\n\nImplementation:\n- Renamed /handoff → /open (pairs with /close)\n- /open reads episodic-memory summary + beads + todoist\n- /close generates handoff (captured automatically by episodic-memory sync)\n- Deleted broken digest infrastructure (folder, hooks, markers)\n- Updated CLAUDE.md with \"Inter-Session Memory Architecture\" section\n\nKey insight: The close-session handoff prompt flows through episodic-memory \nsummarization automatically. The LLM summary preserves it. No separate \nhandoff file needed - /open synthesizes from existing sources.\n\nAdded: Optional Claude Journal question in close-session for high watermark moments."}
{"id":".claude-aig","title":"Extract workspace-fluency to separate skill repo","design":"Currently lives inside mcp-workspace repo at skills/workspace-fluency/. \n\nDecision made: skills should be decoupled from MCPs for visibility (ls ~/Repos | grep skill- shows the set).\n\nSteps:\n1. Create ~/Repos/skill-workspace-fluency/\n2. Copy content from mcp-workspace/skills/workspace-fluency/\n3. Update symlink ~/.claude/skills/workspace-fluency → new location\n4. Remove skills/ folder from mcp-workspace repo\n5. Update any cross-references","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-28T21:39:56.832847Z","updated_at":"2025-12-28T22:05:18.041288Z","deleted_at":"2025-12-28T22:05:18.041288Z","deleted_by":"daemon","delete_reason":"delete","original_type":"task"}
{"id":".claude-aku","title":"Reviewed ~/.claude config on release of new model","design":"Reminder to repeat the Opus 4.5 config refresh process when the next major model update arrives. Pattern: 1) Review system prompt changes 2) Audit what's now redundant 3) Add new capabilities to leverage 4) Update 'Last refreshed' date. Trigger: New Claude model announcement (Claude 5, etc). Keep this issue open and visible in bd ready.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-24T21:22:34.422151Z","updated_at":"2026-01-03T14:10:55.962964Z","closed_at":"2026-01-03T14:10:55.962964Z","close_reason":"Major CLAUDE.md restructure completed. New structure: About Me → You, your tools and environment → How best to work together → The Typical Session. Added Theatre of Input concept, Core Skills table with GODAR pattern, session lifecycle with baton metaphor. Trimmed ~130 lines of redundant content. Not triggered by new model release, but by organic refinement session."}
{"id":".claude-ap6","title":"Update beads skill for v0.36.0 (mol spawn removal, formulas, gates)","description":"Beads skill references outdated patterns. bd mol spawn was removed in v0.36.0, replaced by bd pour/bd wisp create. Also missing: formula system (bd cook), gate issue type, activity command.","design":"## Scope\n1. SKILL.md molecules section - remove spawn, document pour/wisp create\n2. references/MOLECULES.md - add v0.35-0.36 additions (formulas, gates, activity, bonding)\n3. Quick Index - add formula and gate references\n\n## Approach\nRead current skill files, identify outdated references, update to match v0.36.0 reality.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T09:06:55.044189Z","updated_at":"2025-12-26T09:30:21.318194Z","closed_at":"2025-12-26T09:30:21.318194Z","close_reason":"Updated SKILL.md and MOLECULES.md for v0.36.0: removed mol spawn refs, added pour/wisp create, documented formulas, gates, activity monitoring. Updated Quick Index. Filed #746 upstream about --resolution regression."}
{"id":".claude-bl0","title":"Context-aware SessionStart with Todoist","design":"SessionStart hook that:\n1. Detects working directory\n2. Maps to Todoist project:\n   - ~/Repos/* → Claude@Repos\n   - ~/Google Drive/My Drive/Work/* → Claude@Work\n3. Fetches and displays relevant tasks\n4. Also shows local bd ready if .beads exists\n\nRequires:\n- Todoist MCP authentication check (auth is short-lived)\n- Directory pattern matching\n- Graceful fallback if MCP unavailable\n\nRelated: Add \"auth Todoist on first daily use\" reminder.","notes":"Consolidated into .claude-1wz (SessionStart/SessionStop hooks epic)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T19:32:04.268302Z","updated_at":"2025-12-14T23:40:17.713923Z","closed_at":"2025-12-14T23:40:17.713938Z"}
{"id":".claude-c9j","title":"Check adequacy of initial bidirectional reflection implementation","description":"After standard closedown, Claude asks learning questions and records reflection in handoff.","design":"## Approach\nAdd Phase 7 to close skill:\n1. Claude asks 1-2 learning questions based on session content\n2. User answers (via AskUserQuestion or freeform)\n3. Claude reflects - connects to wider patterns, suggests implications\n4. Reflection appended to handoff under ## Reflection section\n\n## Sample Questions\n- \"What decision from today do you want to remember?\"\n- \"What surprised you about how we solved X?\"\n- \"What would you do differently next time?\"\n\n## Files\n- SKILL.md (add Phase 7)\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","acceptance_criteria":"- [ ] Phase 7 added to close skill\n- [ ] Learning questions designed (2-3 good ones)\n- [ ] ## Reflection section format defined\n- [ ] Test full /close flow with reflection","notes":"SESSION: 2025-12-26\n\nInitial implementation done ad-hoc during /close:\n- Added MANDATORY section to Phase 6 requiring reflection recording\n- Format: Q/A/Insight structure appended to handoff\n- Archive copy update included\n\nNEEDS REVIEW:\n- Is the probing guidance strong enough? Current: \"Be discursive, not transactional\"\n- Should there be example probes for each question type?\n- Is the \"skipped (user declined)\" fallback sufficient?\n- Test with next Claude: does it actually follow through?\n\nThis bead is now about validating the implementation, not creating it.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-25T23:46:38.802171Z","updated_at":"2025-12-26T00:26:32.990618Z","closed_at":"2025-12-26T00:26:32.990618Z","close_reason":"Reviewed and improved Phase 6: reframed from 'exhausted context' to 'rich context for learning', added purpose statement, contrast example (transactional vs discursive), new reflection format (User said / Claude reflected), 2 questions as default","dependencies":[{"issue_id":".claude-c9j","depends_on_id":".claude-43e","type":"parent-child","created_at":"2025-12-25T23:46:49.887755Z","created_by":"daemon","metadata":"{}"}]}
{"id":".claude-ckh","title":"Make /open skill's beads invocation more effective","description":"The /open skill says to invoke Skill(beads) when BEADS_EXISTS=true, but this instruction didn't land - Claude skipped it and went straight to synthesis. The skill needs to make this step harder to miss.","design":"## Options\n1. Add reminder to script output: \"BEADS_SKILL_INVOKE=true\" as explicit flag\n2. Restructure skill to make step 2 more prominent\n3. Add to script output itself: \"→ Next: Skill(beads)\"\n4. Combine steps 1+2 so beads skill loads as part of context gathering\n\n## Consideration\nThe skill is already clear (\"If BEADS_EXISTS=true: Skill(beads)\"). \nThe failure mode is Claude reading the synthesis instruction before completing prerequisites.\nMaybe the fix is ordering/prominence, not more words.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-26T09:08:14.847874Z","updated_at":"2025-12-26T09:08:35.678202Z","deleted_at":"2025-12-26T09:08:35.678202Z","deleted_by":"daemon","delete_reason":"delete","original_type":"task"}
{"id":".claude-cm6","title":"Test web-init.sh in Claude Code web environment","design":"Verify the web-init.sh script works when running Claude Code from claude.ai web interface:\n\n1. Start a Claude Code web session (claude.ai → terminal)\n2. Check if CLAUDE_CODE_REMOTE=true is set\n3. Run the web-init.sh script manually or via hooks\n4. Verify beads CLI installs correctly\n5. Test bd commands work in the web environment\n\nAcceptance:\n- [ ] Web session correctly detects CLAUDE_CODE_REMOTE=true\n- [ ] beads CLI installs via go install\n- [ ] bd commands work (bd ready, bd show, etc.)\n- [ ] Update script or mark as working","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T16:33:06.6622Z","updated_at":"2025-12-30T20:20:30.668469Z","closed_at":"2025-12-30T20:20:30.668469Z","close_reason":"Won't pursue — web Claude Code doesn't support user-level skills or local MCPs. Would need to restructure entire skills approach for marginal benefit."}
{"id":".claude-dcg","title":"Create HTML Tools skill","description":"Move HTML Tools documentation from CLAUDE.md to a proper skill. The pattern (one tool, two principals) is useful but belongs as a procedure, not environment context.","design":"## Context\n\nHTML Tools is a pattern where single-file HTML+JS+CSS applications serve both humans (browser UI) and Claude (MCP execution). Discovered via Simon Willison's work.\n\n## Current State\n\nDocumented in ~/.claude/CLAUDE.md under \"HTML Tools Pattern\" section (being removed as part of CLAUDE.md cleanup - Dec 2024).\n\nKey details from that section:\n- Part of \"Accessibility for Agent Era\" philosophy (design for human/machine × self/other matrix)\n- Tools work for humans: open in browser, visual interactive UI\n- Tools work for Claude: execute via `mcp__html-tools__execute_html_tool(url, params)`\n- The `#machine-output` element provides structured data for Claude alongside human-readable UI\n- Tools live at planetmodha.com/tools/ (GitHub Pages) or kube.lan:8888/ (local)\n\n## MCP Server\n\nThe executor lives at ~/Repos/infra-html-tool-executor/\n\n## Skill Should Document\n\n1. When to use HTML tools vs Skills:\n   - HTML tool: Deterministic transformation, no Claude judgment (curly quotes, format conversion)\n   - Skill: Pattern requiring judgment (debugging approach, workflow guidance)\n\n2. How to invoke: mcp__html-tools__execute_html_tool(url, params)\n\n3. The #machine-output pattern for structured responses\n\n4. Example tools and their use cases\n\n## Why This Matters\n\nThis is the \"one tool, two principals\" pattern - same logic, two access paths. Elegant because it doesn't bifurcate implementations for human vs machine consumption.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-23T06:48:39.998998Z","updated_at":"2025-12-30T20:08:05.488181Z","closed_at":"2025-12-30T20:08:05.488181Z","close_reason":"Skill not needed — MCP is self-documenting. Filed mcp-run-html-tools bead for adding resources/prompts instead."}
{"id":".claude-dhs","title":"Healthcheck findings: Dec 2025","design":"Comprehensive healthcheck of ~/.claude config identified multiple improvement opportunities.\n\n## Findings\n\n### 1. New Claude Code Features (Not Yet Adopted)\n- `.claude/rules/` directory for modular rules (auto-loaded)\n- Path-specific rules via YAML frontmatter\n- Prompt-based hooks (`type: \"prompt\"`) for LLM evaluation\n- Named sessions (`/rename`, `/resume \u003cname\u003e`)\n\n### 2. Conversation Log Mining\n- Sessions stored in `~/.claude/projects/[path]/[uuid].jsonl`\n- Format is readable JSONL (NOT base64)\n- Contains full messages, summaries, timestamps\n- OPPORTUNITY: Build cross-session memory system\n\n### 3. Symlink Inconsistencies\n- linux-server-fluency follows MCP companion pattern\n- workspace-fluency does NOT (lives locally, not with MCP)\n- DECISION NEEDED: Standardize pattern\n\n### 4. Submodule Tracking\n- Anthropic and Superpowers submodules update automatically\n- NO notification of new skills added\n- OPPORTUNITY: Add new-skill detection to update-all.sh\n\n### 5. update-all.sh Improvements\n- bd version detection should use `bd version` not brew\n- Could add macOS notification on failures\n- Could log submodule changes (not just \"updated\")\n\n### 6. Session Closedown Automation\n- Currently voluntary (SessionEnd shows reminder)\n- NEW: prompt-based hooks might enable auto-invocation\n- TEST: `\"type\": \"prompt\"` in Stop/SessionEnd hook\n\n### 7. Model-Change Detection\n- .claude-aku tracks intent but not mechanism\n- Could add to SessionStart: check model, prompt review if changed\n\n## Next Steps\nCreate child tasks for actionable items.","notes":"WebFetch hook verified working 2025-12-19. JSON format (hookSpecificOutput.additionalContext) successfully injects reminder into Claude's context. Tested by fetching blog post - reminder appeared as expected.\n\nAdded child task .claude-jjg for BEFORE gate skills decision.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-14T18:57:34.461525Z","updated_at":"2025-12-22T10:40:58.916454Z","closed_at":"2025-12-22T10:40:58.916454Z","close_reason":"Epic complete. Core findings addressed (hooks, skills, submodules, MCP patterns). Memory work continues in .claude-485/.claude-w0t.","dependencies":[{"issue_id":".claude-dhs","depends_on_id":".claude-tvq","type":"blocks","created_at":"2025-12-14T18:58:14.669808Z","created_by":"daemon","metadata":"{}"},{"issue_id":".claude-dhs","depends_on_id":".claude-k7p","type":"blocks","created_at":"2025-12-14T18:58:14.762922Z","created_by":"daemon","metadata":"{}"},{"issue_id":".claude-dhs","depends_on_id":".claude-w0t","type":"blocks","created_at":"2025-12-14T18:58:14.841305Z","created_by":"daemon","metadata":"{}"},{"issue_id":".claude-dhs","depends_on_id":".claude-17w","type":"blocks","created_at":"2025-12-14T18:58:14.914436Z","created_by":"daemon","metadata":"{}"},{"issue_id":".claude-dhs","depends_on_id":".claude-t63","type":"blocks","created_at":"2025-12-14T18:58:14.992056Z","created_by":"daemon","metadata":"{}"},{"issue_id":".claude-dhs","depends_on_id":".claude-jjg","type":"blocks","created_at":"2025-12-19T22:07:14.769818Z","created_by":"daemon","metadata":"{}"}]}
{"id":".claude-dl2","title":"Clean up web playground repos","design":"Four repos identified, most redundant:\n\nKEEP:\n- claude-web-playground - Has actual code (browser-vs-fetch experiment), good docs\n- playpen-browsermcp - Has local .mcp.json for BrowserMCP, use as canonical 'heavy MCP' workspace\n\nDELETE:\n- playpen-playwright - Empty skeleton, no code, no setup done\n- claude-playwright-env - Already deleted this session\n\nAfter cleanup: update ~/Repos/CLAUDE.md if it references these","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-28T21:39:59.380628Z","updated_at":"2025-12-28T22:05:18.097204Z","deleted_at":"2025-12-28T22:05:18.097204Z","deleted_by":"daemon","delete_reason":"delete","original_type":"task"}
{"id":".claude-dqg","title":"Implement handoff accumulation with local rotation","description":"Handoffs should accumulate in central archive and rotate locally, not overwrite.","design":"## Approach\n1. Create ~/.claude/handoffs/ directory\n2. Modify close skill to copy handoff to archive\n3. Add project slug + timestamp naming: {project-slug}-{timestamp}.md\n4. Implement local rotation: .handoff, .handoff.1, .handoff.2\n\n## Files\n- SKILL.md (add archive copy step)\n- Possibly close-context.sh\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","acceptance_criteria":"- [ ] ~/.claude/handoffs/ directory exists\n- [ ] /close copies handoff to archive with timestamp\n- [ ] Project slug derived from directory or git remote\n- [ ] Local rotation preserves .handoff, .handoff.1, .handoff.2\n- [ ] Old local handoffs rotate (not deleted)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-25T23:46:37.311244Z","updated_at":"2025-12-25T23:49:31.286389Z","closed_at":"2025-12-25T23:49:31.286389Z","close_reason":"Implemented handoff accumulation: created ~/.claude/handoffs/ directory, added local rotation (.handoff → .handoff.1 → .handoff.2), and archive copy with project-slug-timestamp naming. Slug derived from git remote or directory name.","dependencies":[{"issue_id":".claude-dqg","depends_on_id":".claude-43e","type":"parent-child","created_at":"2025-12-25T23:46:49.771643Z","created_by":"daemon","metadata":"{}"}]}
{"id":".claude-dvl","title":"Formalize /open /close with structural gates","description":"Add machine-readable gates and checkpoints to /open and /close rituals. Plan at ~/.claude/plans/ancient-tickling-muffin.md","design":"## Summary\nTurn prose \"shoulds\" into structural \"musts\" for:\n- Skill(beads) invocation after /open\n- Draw-down before bead work\n- Reflection recording in /close\n\n## Key Changes\n1. open-context.sh: Add GATE_REQUIRED + NEXT_ACTION outputs\n2. open.md: Add Gate Check section\n3. close-session/SKILL.md: Add Reflection Checkpoint\n4. Cross-ritual verification (handoff structure check)\n\n## Files\n- ~/.claude/scripts/open-context.sh\n- ~/.claude/commands/open.md  \n- ~/.claude/skills/close-session/SKILL.md\n\n## Decision\nStructural gates (script + skill enforcement), not full bd gates.\nSilent integrity checks (only warn on issues).\n\nSee plan file for full details.","notes":"SESSION: 2025-12-26\n\nCOMPLETED (but incomplete):\n- Added GATE_REQUIRED + NEXT_ACTION to open-context.sh\n- Added Gate Check section to /open command\n- Added Draw-Down Gate section to /open\n- Added Reflection Checkpoint to /close skill\n- Added cross-ritual verification (HANDOFF_WARNING)\n\nKEY REALIZATION:\nWe built prose dressed up as gates. \"GATE:\" and \"VERIFY:\" and \"CHECKPOINT:\" in capital letters — but no actual enforcement. Claude can still ignore these instructions.\n\nThe plan decided \"Structural gates (script + skill enforcement), not full bd gates\" — but that decision may have been wrong. We didn't use the bd v0.36.0 gate infrastructure at all.\n\nWHAT bd GATES ACTUALLY DO:\n- `bd gate create \"description\" --await manual|timer|gh:*`\n- Gates are issue types that block dependent work\n- `bd gate approve \u003cid\u003e` for manual gates\n- Real blocking, not prose instructions\n\nOPEN QUESTION:\nDo bd gates fit ritual enforcement? They're designed for async coordination. Creating a gate every session might be heavyweight. But maybe that friction IS the point — real enforcement costs something.\n\nNEXT SESSION NEEDS TO:\n1. Observe whether the prose gates actually changed behavior (meta-test)\n2. If they didn't enforce anything, explore using bd gates properly\n3. Consider: what would \"gate before draw-down\" look like with real bd gates?\n\nThe handoff from this session is itself a test case — did /close enforce reflection, or did it get rushed?","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-26T10:11:51.27051Z","updated_at":"2025-12-26T11:27:36.666861Z","closed_at":"2025-12-26T11:27:36.666861Z","close_reason":"Explored bd gate infrastructure for ritual enforcement. Conclusion: bd gates are async coordination primitives (timer, GitHub events, human approval) — none can programmatically prevent Claude from skipping steps. Human approval gates would work but shift friction to user. Prose gates (what we built) are the appropriate tool for in-session enforcement; they worked this session. No bd feature exists to make skipping 'impossible' — that would require Claude Code-level changes.","comments":[{"id":2,"issue_id":".claude-dvl","author":"modha","text":"Realized we built prose 'gates' but didn't use actual bd gate infrastructure. Need to reconsider whether bd gates fit ritual enforcement.","created_at":"2025-12-26T10:53:45Z"}]}
{"id":".claude-enm","title":"Improve collaborating skill triggers and reduce CLAUDE.md overlap","design":"Issues identified:\n1. Vague trigger 'when noticing drift from stated principles' doesn't fire reliably\n2. Side quests philosophy duplicated in both CLAUDE.md and skill\n3. Need sharper MANDATORY/BEFORE language in description\n\nImprovements needed:\n- Add specific trigger phrases that will actually fire\n- Dedupe side quests content (keep in CLAUDE.md, reference from skill)\n- Consider BEFORE pattern: 'BEFORE adding to plate, check overcommitment'\n- Test trigger reliability with adversarial prompts","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-28T21:10:46.968221Z","updated_at":"2025-12-28T22:05:18.212877Z","deleted_at":"2025-12-28T22:05:18.212877Z","deleted_by":"daemon","delete_reason":"delete","original_type":"task"}
{"id":".claude-ers","title":"Spec simpler conversation memory: summaries + text search","design":"## Spec Complete\n\nFull handoff spec v2 produced via Desktop Claude research.\nPlan summary at: ~/.claude/plans/conversation-memory-v2.md\n\n## Architecture\n\nText search (BM25/FTS5) over entity-resolved summaries.\nNo vectors — they don't add value for work-type retrieval.\n\n## Key Components\n\n1. **Multi-source ingest** — Code, Desktop, Google Workspace, local files\n2. **Entity extraction** — LLM extracts, checks against glossary\n3. **Interactive resolution** — Tiered confidence, terminal UI for candidates\n4. **Summarization** — Uses resolved canonical names\n5. **Search** — FTS5 with drill-on-demand to full sources\n6. **MCP server** — For Desktop integration\n\n## Implementation Phases\n\n1. Core loop (conversations only, manual summaries)\n2. Extraction pipeline (LLM + glossary)\n3. Full automation (scan/extract/summarize commands)\n4. Multi-source (Desktop, Drive, local files)\n5. Polish (MCP server, digest, relocate)\n\n## Prior Art Incorporated\n\n- episodic-memory: archive structure, sync patterns\n- claude-knowledge-graph: entity shards, alias resolution\n- claude-memory-feature-test: MECE, glossary-grounded prompts\n- workspace-fluency: search→triage→drill workflow","notes":"## Scope Expanded: This is a Program of Work\n\nToo big for a single bead. Needs a plan + epic structure.\n\n### Dimensions to Address\n\n1. **Ergonomics** - Must feel natural, model on workspace-fluency patterns\n2. **Summary generation** - Entity-aware prompts, domain glossary integration\n3. **Cross-platform** - Desktop + Code unified. Desktop cache at ~/Library/Application Support/Claude/\n4. **Prior art** - episodic-memory, claude-knowledge-graph (archived), claude-memory-feature-test, workspace-fluency\n5. **Corpus scope** - Conversations primary, but Repos docs/READMEs worth considering (bridging code + knowledge work)\n\n### Prior Art to Salvage\n\n| Source | What to Take |\n|--------|--------------|\n| episodic-memory | Archive structure, sync hooks, summary generation |\n| claude-knowledge-graph | Entity shards, alias→canonical patterns |\n| claude-memory-feature-test | MECE, 25:1 compression, glossary-based prompts |\n| workspace-fluency | Search→triage→drill workflow pattern |\n\n### Open Research\n\n- How do others solve agent conversation memory?\n- Anthropic Memory patterns (Desktop has this natively)\n- Cross-platform unification approaches\n- Entity-aware summarization techniques\n\n### Next Steps\n\n1. Deep research on prior art (Desktop Claude prompt drafted)\n2. Create plan file with epic structure\n3. Identify minimum viable slice to test","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-26T22:54:24.42306Z","updated_at":"2025-12-30T19:07:51.450191Z","closed_at":"2025-12-30T19:07:51.450191Z","close_reason":"Spec complete, evolved into claude-memory repo. Phases 1-2 implemented. Work now tracked in claude-memory/.beads."}
{"id":".claude-esq","title":"Make switch config authoritative for port assignments","design":"Switch-centric model: gs324tp_ports (and future zyxel_ports) becomes canonical source for port→device mapping, VLANs, PoE. AP definitions don't duplicate. Add infra_lib helper: get_switch_port(device_name) to query from switch config. Enables switch config generation for ZyXEL.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T10:32:38.740711Z","updated_at":"2025-12-30T19:03:54.462925Z","closed_at":"2025-12-30T19:03:54.462925Z","close_reason":"Implemented in infra-openwrt. Bead was created in wrong location."}
{"id":".claude-ew5","title":"Reflash isaacap (broken by incomplete bridge-vlan config)","design":"## What happened\nAdded bridge-vlan for VLAN 10 without preserving VLAN 1, breaking all network traffic.\nConfig persisted via uci commit, survives power cycle.\n\n## To fix\n1. Factory reset (hold reset 10+ sec) OR pull off wall\n2. Download new AP image from build 20570461080\n3. Flash via sysupgrade\n4. Verify Antimatter AND Antimacassar both work\n\n## Root cause to fix in code\nThe firstboot script needs BOTH bridge-vlan entries:\n- VLAN 1 untagged (main LAN)\n- VLAN 10 tagged (guest)\n\nThis needs adding to 99-campbell-ap before any more AP flashing.","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-29T10:36:00.864933Z","updated_at":"2025-12-30T19:03:15.509295Z","closed_at":"2025-12-30T19:03:15.509295Z","close_reason":"Fixed. AP reflashed, infra-openwrt project matured. This bead was created in wrong location (~/.claude instead of infra-openwrt)."}
{"id":".claude-f6w","title":"Try brainstorming skill and diagnose zero usage","design":"The superpowers brainstorming skill has 0 invocations despite being symlinked.\n\nGoals:\n1. Read the skill, understand its triggers\n2. Try it together on a real task\n3. Diagnose why it never fires - trigger mismatch? workflow assumption?\n4. Decide: keep as-is, rework triggers, or archive\n\nThis is the ONE superpowers skill we're keeping to evaluate properly.","notes":"RESOLUTION: Tested brainstorming skill hands-on. Verdict: ARCHIVE. Skill adds structure (questions, 2-3 approaches) but doesn't add intelligence. Feels clunky with a user who already comes with partly-formed thoughts. The one-question-per-message pace is mechanical. Skill removed from symlinks, added to .known-unlinked. Core insight: 'before X' triggers don't work because Claude doesn't naturally pause at workflow gates.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-19T23:08:40.877322Z","updated_at":"2025-12-20T07:32:45.545655Z","closed_at":"2025-12-20T07:32:45.545666Z"}
{"id":".claude-fbh","title":"Claude 4 prompting best practices audit","design":"Review Claude 4 best practices docs and assess impact on: global CLAUDE.md, skills, output styles, hooks. Update config where needed.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-14T19:29:18.783064Z","updated_at":"2025-12-22T10:41:00.096946Z","closed_at":"2025-12-22T10:41:00.096946Z","close_reason":"Superseded by Opus 4.5 config refresh (.claude-a6b). No standalone audit needed."}
{"id":".claude-ftz","title":"Fix container detection bug in close scripts","description":"Shell globs don't work in case statements. Container detection fails for Google Drive paths.","design":"## Problem\n`case \"$1\" in` with glob patterns like `*` doesn't expand - it's literal matching.\n\n## Fix\nReplace with `[[ ]] pattern matching:\n```bash\nis_container() {\n    [[ \"$1\" == \"$HOME/Repos\" ]] \u0026\u0026 return 0\n    [[ \"$1\" == \"$HOME/.claude\" ]] \u0026\u0026 return 0\n    [[ \"$1\" == \"$HOME/Library/CloudStorage/GoogleDrive-\"*\"/My Drive/Work\" ]] \u0026\u0026 return 0\n    return 1\n}\n```\n\n## Files\n- close-context.sh\n- SKILL.md (2 locations)\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","acceptance_criteria":"- [ ] close-context.sh uses [[ ]] pattern matching\n- [ ] SKILL.md container detection fixed (2 locations)\n- [ ] Test: /close from ~/Repos detects container correctly\n- [ ] Test: /close from Google Drive Work detects container correctly","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-25T23:46:08.33763Z","updated_at":"2025-12-25T23:48:17.929684Z","closed_at":"2025-12-25T23:48:17.929684Z","close_reason":"Fixed container detection: replaced case statement globs with [[ ]] pattern matching. Fixed in close-context.sh and SKILL.md (2 locations). All tests pass.","dependencies":[{"issue_id":".claude-ftz","depends_on_id":".claude-43e","type":"parent-child","created_at":"2025-12-25T23:46:49.642331Z","created_by":"daemon","metadata":"{}"}]}
{"id":".claude-ghj","title":"Verified correct usage of episodic-memory","description":"Phase 1: Read docs, check query patterns, verify configuration","notes":"## Phase 1 Complete: Correct Usage Verified\n\n### Key Finding: Usage Pattern Mismatch\n\nOur query \"what interesting things have we built\" was a **meta-question** about the corpus.\nThe tool is designed for **specific topic retrieval**.\n\nEmbeddings are generated from: `User: \u003cmsg\u003e\\nAssistant: \u003cresponse\u003e\\nTools: \u003cnames\u003e`\nThis means queries need to match *content that appears in exchanges*, not *questions about what happened*.\n\n### Correct vs Incorrect Usage\n\n**Works:**\n- \"skill workflow\" — matches conversations about skills\n- \"MCP server authentication\" — matches specific implementations\n- [\"skill\", \"creating\", \"SKILL.md\"] — multi-concept AND search\n- `--text \"built new\"` — action-oriented keyword search\n\n**Doesn't work:**\n- \"what interesting things have we built\" — meta-analysis question\n- \"flavoursome analysis\" — abstract concept\n\n### Technical Findings\n\n| Component | Status |\n|-----------|--------|\n| Index | 4,738 embeddings, healthy |\n| Vector search | Working (sqlite-vec) |\n| Embedding model | all-MiniLM-L6-v2 (2000 char truncate) |\n| Sync | Running via session hooks |\n\n### Separate Issue: Missing Summaries\n\n80% of conversations lack AI-generated summaries.\nSummaries are for *display* (showing context in results), not *search*.\nNot the cause of poor search, but worth addressing separately.\n\n### Verdict\n\nNot broken — we were misusing it. \nTool is for: \"find conversations about X topic\"\nNot for: \"what have we accomplished\"\n\nFor meta-analysis, need different approach:\n- Beads (tracks completed work explicitly)\n- Handoffs (captures what was done each session)\n- Git history (shows what changed)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T21:58:02.705052Z","updated_at":"2025-12-26T22:11:18.775532Z","closed_at":"2025-12-26T22:11:18.775532Z","close_reason":"Usage pattern mismatch identified. Tool designed for topic retrieval, not meta-analysis. Not broken - we were misusing it.","dependencies":[{"issue_id":".claude-ghj","depends_on_id":".claude-4di","type":"parent-child","created_at":"2025-12-26T21:58:58.730083Z","created_by":"daemon","metadata":"{}"}]}
{"id":".claude-gv0","title":"Speed up /open ritual - not everything needs to fire every time","design":"The /open ritual is slow. Current flow checks:\n- Episodic memory search\n- Beads ready\n- Todoist intake\n- Git status\n- .handoff file\n- Journal opportunity\n\nNot all of these are needed every time:\n- Todoist: Only relevant for certain projects/contexts\n- Journal: Rarely actionable, adds latency\n- Episodic search: Expensive LLM call, maybe only if no .handoff?\n\nConsider:\n1. Tiered approach: fast path (handoff + beads) vs full path\n2. Parallel execution where possible\n3. Skip checks that aren't relevant to current directory\n4. Cache/memoize expensive operations\n\nFile: ~/.claude/commands/open.md and related skills","notes":"Resolution: Consolidated 6 parallel bash calls into single open-context.sh script. Added once-daily gate for Todoist checks (writes timestamp to .todoist-checked-{context}). Episodic search now only runs if no handoff exists. Result: 1 bash call + conditional Todoist MCP, down from 6 bash + 1 MCP.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T13:39:39.508209Z","updated_at":"2025-12-23T14:15:23.052433Z","closed_at":"2025-12-23T14:15:23.052449Z"}
{"id":".claude-h6f","title":"Improve session-closing to capture work-in-progress","design":"Gap identified: close ritual asks about git/learnings but doesn't check for incomplete work.\n\nShould add: 'TodoWrite has N items, M beads created. Capture outstanding work as beads before closing?'\n\nThis prevents context loss when sessions end with pending tasks.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-28T21:49:09.569451Z","updated_at":"2025-12-28T22:05:18.126385Z","deleted_at":"2025-12-28T22:05:18.126385Z","deleted_by":"daemon","delete_reason":"delete","original_type":"task"}
{"id":".claude-hwo","title":"Assessed fundamental fit and alternatives","description":"Phase 3: Embedding model suitability, chunking strategy, compare to handoffs/git/beads","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T21:58:02.965449Z","updated_at":"2025-12-26T22:39:02.400905Z","closed_at":"2025-12-26T22:39:02.400905Z","close_reason":"Embedding space (all-MiniLM-L6-v2) is too flat-footed for work-type retrieval. Clusters by lexical/structural similarity, not intent or outcome. Cross-project 'themes' were mostly mechanical (git, beads, rituals) not semantic. Alternative embeddings (Instructor, fine-tuned) could help but add complexity.","dependencies":[{"issue_id":".claude-hwo","depends_on_id":".claude-4di","type":"parent-child","created_at":"2025-12-26T21:58:58.973379Z","created_by":"daemon","metadata":"{}"},{"issue_id":".claude-hwo","depends_on_id":".claude-oip","type":"blocks","created_at":"2025-12-26T21:58:59.469013Z","created_by":"daemon","metadata":"{}"}]}
{"id":".claude-i9q","title":"Taught Claude how to make decent quality conceptual charts","design":"Build a skill for creating conceptual charts and diagrams. Evolved from SVG visual feedback pipeline work. Uses sips for fast SVG→PNG rendering (\u003c10s feedback). Integrates ITV design system for brand consistency.","notes":"SESSION: 2025-12-23\n\nPROGRESS: Substantial skill expansion, but not yet fluent execution\n\nCOMPLETED:\n- Added Composition Check (centering calculation, orphan detection)\n- Added Reduced Size Check step\n- Added Chesterton's Fence principle\n- Added Respect the Metaphor (ladder rungs inside rails, etc.)\n- Added No Orphan Elements, Key/Legend hierarchy\n- Updated Fill the Space to include centering\n\nKEY DISCOVERIES:\n- CRAP checks element relationships, not composition placement — that was the gap\n- \"Explanation\" vs \"noise\" — kept removing things that were doing work\n- Centering: calculate (left+right)/2, don't eyeball\n- Reduced size reveals problems that hide at full size\n- Iterative loop (draw → user edits → learn) surfaces things book reading missed\n\nCURRENT STATE:\n- Skill has the principles now\n- Execution still not fluent — can't reliably center, still make ragged alignments\n- Need more practice with real diagrams\n\nNEXT:\n- Genre recipes (specific compositional patterns for Venn, ladder, flow)\n- Example gallery of before/after\n- More iterative practice to build fluency","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-14T19:29:18.924774Z","updated_at":"2025-12-30T19:51:56.550153Z","closed_at":"2025-12-30T19:51:56.550153Z","close_reason":"Relocated to skill-diagramming repo as P1 epic. Principles captured, execution fluency needs iterative practice."}
{"id":".claude-izv","title":"Test new-skills notification system","design":"Test the update-all.sh → .new-skills-notification → Claude AskUserQuestion flow.\n\nSteps:\n1. Temporarily add a fake skill to a submodule (or remove one from .known-unlinked)\n2. Run update-all.sh manually\n3. Verify .new-skills-notification is created\n4. Start new Claude session, verify it prompts via AskUserQuestion\n5. Clean up test data\n\nSuccess: User gets prompted about new skills in a way that's hard to ignore.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-19T23:11:17.156068Z","updated_at":"2025-12-22T10:41:03.757044Z","closed_at":"2025-12-22T10:41:03.757044Z","close_reason":"Implementation complete in update-all.sh. Testing opportunistic."}
{"id":".claude-jjg","title":"Decide fate of BEFORE gate skills","design":"8 skills from superpowers submodule never trigger based on Dec 2025 audit: systematic-debugging, test-driven-development, verification-before-completion, crash-recovery, desired-outcomes, todoist-strategy, working-with-sameer, core-fluency. These are 'BEFORE gate' skills requiring methodical engineering workflow that doesn't match actual usage patterns. Options: (a) remove them, (b) rework triggers to match workflow, (c) accept as dormant reference. Related to MCP/skill pairing decision (.claude-17w).","notes":"RESOLUTION: Diagnosed why superpowers skills fail to trigger. Evidence: All have 'before X' triggers (before proposing fixes, before writing code, before committing). These are workflow gates - they assume Claude will pause and check 'am I about to do X?' But Claude doesn't pause, it just does the work. Working skills trigger on ARTIFACTS (file types, user requests), failing skills trigger on WORKFLOW PHASES. Dec 19 already pruned 6 superpowers skills. Brainstorming tested and archived Dec 20. Pattern documented in plan file.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-19T22:07:08.290856Z","updated_at":"2025-12-20T07:33:02.225821Z","closed_at":"2025-12-20T07:33:02.225831Z"}
{"id":".claude-k0z","title":"Add validation gates to spec → beads workflow","description":"Acceptance criteria answer \"did we build it?\" but not \"does it serve the purpose?\"\nNeed explicit validation milestones in specs that become gate beads.\n\nSurfaced twice recently - once in claude-memory extraction, once before.","design":"## Proposal\n\n1. Specs get `## Validation Gate` sections after each phase\n2. Gate describes: what questions must be answerable? what should work?\n3. When spec → beads, validation gates become \"validate\" type beads\n4. Validate beads block downstream phases\n\n## Where to implement\n\n- skill-creator: add validation gate guidance to spec template\n- beads skill: mention validation gates in issue creation guidance\n- Plan agent: prompt for validation criteria when planning phases\n\n## Example\n\n```markdown\n## Phase 2: Entity Pipeline\n\n### Deliverables\n- Hook triggers extraction\n- Entities stored in database\n\n### Validation Gate (before Phase 3)\n**Test:** Can we answer these from extracted data?\n1. What were the big builds recently?\n2. What skills are used most?\n\nIf not → iterate before proceeding.\n```","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T16:58:05.091172Z","updated_at":"2025-12-30T20:31:51.611145Z","closed_at":"2025-12-30T20:31:51.611145Z","close_reason":"Won't do — too fussy."}
{"id":".claude-k7p","title":"Add new-skill detection to update-all.sh","design":"Compare skills in submodules against existing symlinks, report new ones","notes":"RESOLVED: Added skill detection to QUICK tier of update-all.sh. Checks both anthropic/skills and superpowers/skills submodules, compares against symlinks in ~/.claude/skills/, reports any missing. Tested - found 16 un-symlinked skills (8 anthropic, 8 superpowers). Commit: 9cec6c5","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T18:58:01.591318Z","updated_at":"2025-12-19T22:25:16.403593Z","closed_at":"2025-12-19T22:25:16.403596Z"}
{"id":".claude-k82","title":"Reflect on explore-sonnet agent effectiveness","design":"After 1-2 weeks of use, assess: Does Sonnet for exploration justify the cost vs Haiku? Look at: quality of exploration results, time saved, missed nuances caught. Reference: agents/explore-sonnet.md and CLAUDE.md note about 'deeper analysis than Haiku'. Created: 2024-12-22.","notes":"SESSION: 2025-12-22\n\nUsed explore-sonnet agents (3 in parallel) to search conversation logs for skill usage patterns. Found:\n- 16 of 932 sessions used multiple skills (1.7%)\n- 6 sessions used close-session\n- Multi-skill sessions follow pipelines: data → viz → presentation\n\nThe agent worked well for this broad search task. Will continue to evaluate over next 1-2 weeks whether Sonnet's cost is justified vs Haiku for exploration.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T10:23:33.305351Z","updated_at":"2025-12-30T19:40:00.398886Z","closed_at":"2025-12-30T19:40:00.398886Z","close_reason":"Done. Conclusion: Sonnet hands-down. Documented in CLAUDE.md with guidance to use explore-sonnet agent. Custom agent exists in ~/.claude/agents/."}
{"id":".claude-kzx","title":"Update GitHub remotes to match renamed repos","design":"All skill repos were renamed locally but GitHub remotes not updated.\n\nPattern: gh repo rename NEW-NAME --repo OWNER/OLD-NAME\n\nRepos needing GitHub rename (check which have remotes first):\n- skill-todoist-gtd, skill-collaborating, skill-screenshotting, skill-session-closing, skill-session-opening, skill-diagramming, skill-filing, skill-beads, skill-server-maintenance, skill-itv-styling, skill-checker, skill-cleanup-github, skill-browser-driving\n\nSome may be local-only (no remote yet). For those, just create new GitHub repo with correct name.","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-28T21:39:57.993131Z","updated_at":"2025-12-28T22:05:18.069357Z","deleted_at":"2025-12-28T22:05:18.069357Z","deleted_by":"daemon","delete_reason":"delete","original_type":"task"}
{"id":".claude-lsh","title":"Validate Phase 2 extraction output","description":"Validation gate for Phase 2: Does extraction actually support the 5 benchmark questions?\n\nThis is the explicit pause to check purpose-correctness before moving to Phase 3.","design":"## Validation Test\n\nRun winning extraction (after cn2 evaluation) on diverse sessions.\nAttempt to answer:\n\n1. How can we improve /open /close ritual?\n2. What were the big builds and learnings recently?\n3. Top 5 TIL blog post candidates?\n4. Claude.ai vs Claude Code interaction differences?\n5. Top skills used + improvement patterns?\n\n## Pass Criteria\n\n- At least 3/5 questions answerable with reasonable completeness\n- Data retrieval is feasible (not buried, queryable)\n- No major entity categories missing\n\n## If Fails\n\n- Iterate on prompt/model before Phase 3\n- Document what's missing\n- Adjust glossary or extraction approach","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-28T16:58:05.128973Z","updated_at":"2025-12-30T19:07:53.069641Z","closed_at":"2025-12-30T19:07:53.069641Z","close_reason":"Validation done — Phase 2 marked complete in spec.md v5. Grounding skill proved the extraction approach works."}
{"id":".claude-m06","title":"Add means-ends alignment gate to beads skill","description":"At epic close (or phase transition), prompt: \"Does the next phase still serve the original goals, given what this phase learned?\"\n\nDiscovered during claude-memory work: Phase 2 validated hybrid extraction, but Phase 3 spec still assumed entity-centric approach. The means and ends had drifted. An alignment check would have surfaced this earlier.\n\nGate should trigger at:\n- Epic close when dependent phases exist\n- Phase transitions in multi-phase work\n- Possibly at session start when picking up blocked work that just became unblocked","design":"Add to beads skill SKILL.md:\n\n## Means-Ends Alignment Gate\n\n**Trigger:** When closing an epic that unblocks other work, or at phase transitions.\n\n**Prompt:** \"Before moving to the next phase — do the means still match the ends? Given what we learned in [closed phase], does [next phase] still serve the original benchmark/goal?\"\n\n**If misaligned:** Pause, reframe the next phase, possibly close/recreate with updated scope.\n\nLocation: ~/.claude/skills/beads/SKILL.md","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T23:31:48.579544Z","updated_at":"2025-12-30T19:22:10.371907Z","closed_at":"2025-12-30T19:22:10.371907Z","close_reason":"Relocated to skill-beads repo as skill-beads-3g5 (P1). Includes note about session-management skill coordination."}
{"id":".claude-mte","title":"Explore scrollback/viewport capture options","design":"Current limitation: only captures visible viewport. Research: Can macOS capture full scrollable content? Third-party tools (Shottr, CleanShot X) do this interactively. Any scriptable approach? May remain as documented limitation.","notes":"User notes: super hard/weird - may not be feasible. Low priority.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-15T23:05:39.109702Z","updated_at":"2025-12-23T16:26:44.634386Z","closed_at":"2025-12-23T16:26:44.634386Z","close_reason":"Documented as limitation. Scrollback not feasible without invasive automation."}
{"id":".claude-mzi","title":"Created image generation skill for Claude to use NanoBanana","design":"Build a skill for creating images using Google Imagen (Vertex AI). Primary use cases: presentation images, conceptual illustrations. Needs: API integration, prompt engineering guidance, ITV brand constraints.","notes":"## Reference Material (To Digest)\n\n### Nano Banana Pro: 10 Tips\nURL: https://x.com/GoogleAIStudio/status/1994480371061469306\nStatus: NEEDS MANUAL RETRIEVAL (X blocks scraping)\nSource: Google AI Studio Twitter\n\nWhen retrieved, add key tips to skill references/ folder.\n\n### Other References\n- Vertex AI Imagen documentation\n- ITV brand guidelines (get from brand team)","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-08T18:09:53.817321Z","updated_at":"2025-12-30T19:46:36.754924Z","closed_at":"2025-12-30T19:46:36.754924Z","close_reason":"Relocated to ~/Repos/skill-image-generation as skill-image-generation-3hb. Repo skeleton created."}
{"id":".claude-ns0","title":"Improve updater to surface actionable commands from updates and consider hook vs manual /open","design":"Two parts: (1) When updates surface things like 'bd upgrade review', tell user to run them or offer to run them. (2) Consider whether updater should fire a hook automatically vs current manual /open ritual.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T11:36:01.383909Z","updated_at":"2025-12-29T09:48:29.207328Z","closed_at":"2025-12-29T09:48:29.207328Z","close_reason":"Migrated to skill-session-management (ssm-t7u)"}
{"id":".claude-o1v","title":"Researched modern RAG/embedding options","description":"Phase 3b: Embedding models, chunking strategies, retrieval enhancements, off-the-shelf alternatives","notes":"## RAG vs RG: The Core Question\n\nDo we need the \"A\" (augmented/vector embeddings) or is RG (retrieval + generation) sufficient?\n\n### Option A: RAG with better embeddings\n- Instructor embeddings (task-steerable)\n- HyDE (embed hypothetical answer)\n- Reranking (cheap vectors → expensive cross-encoder)\n- Adds complexity, may still miss work-type semantics\n\n### Option B: RG (text search + Claude)\nArchitecture: text search → candidate exchanges → Claude filters/summarizes\n\nAdvantages:\n- Text search is fast (ripgrep over JSONL)\n- Claude IS the semantic layer — understands work-type, intent, outcome\n- No embedding maintenance, no pollution issues\n- Already have the archive, just need search interface\n\nDisadvantages:\n- More tokens per query (Claude reads candidates)\n- No \"similar to this\" capability (need exact keywords)\n\n### The token question\nIs text search + Claude token-efficient enough?\n- 10 candidate exchanges × ~500 tokens = 5k tokens input\n- Claude summarizes → ~500 tokens output\n- Total: ~6k tokens per query\n\nCompare to current: vector search → subagent reads → summarizes\nSimilar token cost, but simpler architecture.\n\n### Decision needed\n1. Keep episodic-memory for keyword retrieval (it works for that)\n2. Accept it won't do work-type retrieval\n3. For \"what have we built\" questions, use structured tools (beads, handoffs, git)\n4. OR: build RG alternative with text search + Claude\n\nWhich path?","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T21:58:03.097043Z","updated_at":"2025-12-26T22:53:59.447172Z","closed_at":"2025-12-26T22:53:59.447172Z","close_reason":"RAG vs RG resolved: vectors don't add value for our use cases. Text search + Claude judgment is sufficient. The value is in summaries for triage, not embeddings for similarity.","dependencies":[{"issue_id":".claude-o1v","depends_on_id":".claude-4di","type":"parent-child","created_at":"2025-12-26T21:58:59.096638Z","created_by":"daemon","metadata":"{}"},{"issue_id":".claude-o1v","depends_on_id":".claude-hwo","type":"blocks","created_at":"2025-12-26T21:58:59.587604Z","created_by":"daemon","metadata":"{}"}]}
{"id":".claude-obq","title":"Create /replan skill for beads-TodoWrite-plan alignment","design":"## Problem\n\nManual friction when transitioning from strategic planning (beads) to session execution (TodoWrite). User has to explicitly say \"draw down the beads into TodoWrite\" each time. This breaks flow and is easy to forget.\n\n## Current State\n\nThree planning layers exist but don't auto-sync:\n1. **Plan files** (`~/.claude/plans/*.md`) — detailed implementation plans for approval\n2. **Beads** (`.beads/`) — project-level issue tracker with dependencies\n3. **TodoWrite** — session-level execution view\n\nThe translation between them is manual:\n- User says \"let's work on bead X\"\n- Claude reads bead, extracts acceptance criteria\n- Claude populates TodoWrite\n- If TodoWrite drifts, no reconciliation happens\n\n## Proposed /replan Skill\n\n### Trigger Conditions\n- Explicit: user says \"/replan\" or \"align todos\"\n- Implicit (stretch): session start when beads exist, or when user references a bead\n\n### Core Operations\n\n**1. Populate from beads:**\n```\nbd ready → find unblocked work\nbd show \u003cid\u003e → read acceptance criteria\nTodoWrite ← acceptance criteria as items\n```\n\n**2. Check plan files:**\n```\nls ~/.claude/plans/*.md → active plans\nIf plan exists for current work → incorporate steps\n```\n\n**3. Detect drift/orphans:**\n```\nCompare TodoWrite items to bead acceptance criteria\nFlag: \"These todos aren't tracked in any bead: [list]\"\nOffer: \"Create bead?\" or \"Mark as session-only work?\"\n```\n\n**4. Sync status back:**\n```\nWhen TodoWrite item completed → check if bead acceptance criteria met\nIf all criteria done → prompt to close bead\n```\n\n### Open Questions\n\n- **One-shot vs watching?** Is the pain at session start (populate) or mid-session (drift)?\n- **Plan file format?** Do plans need structure for parsing, or freeform OK?\n- **Multi-bead sessions?** What if working on 2-3 beads simultaneously?\n\n### Implementation Notes\n\n- Could be a skill that invokes existing tools (bd CLI, TodoWrite)\n- Needs to handle: no beads, no plan, bead with no acceptance criteria\n- Should be lightweight — don't over-engineer the alignment","acceptance_criteria":"- [ ] /replan skill triggers on explicit command\n- [ ] Reads bd ready and populates TodoWrite from acceptance criteria\n- [ ] Checks ~/.claude/plans/ for relevant plan files\n- [ ] Detects orphan todos not tracked in beads\n- [ ] Prompts for bead closure when criteria complete\n- [ ] Graceful when no beads/plans exist","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T10:01:40.102698Z","updated_at":"2025-12-30T20:31:25.764515Z","closed_at":"2025-12-30T20:31:25.764515Z","close_reason":"Tracked elsewhere."}
{"id":".claude-oip","title":"Ran controlled tests on episodic-memory retrieval","description":"Phase 2: Known-phrase, keyword, semantic, concept intersection, mode comparison, pollution audit","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T21:58:02.837727Z","updated_at":"2025-12-26T22:39:01.132558Z","closed_at":"2025-12-26T22:39:01.132558Z","close_reason":"Clustering analysis revealed: 45% corpus is noise (warmups, summarizer pollution, rituals). Signal subset clusters by project, not work-type. Skill-building work scattered across 4 clusters based on surface text, not semantic coherence.","dependencies":[{"issue_id":".claude-oip","depends_on_id":".claude-4di","type":"parent-child","created_at":"2025-12-26T21:58:58.85191Z","created_by":"daemon","metadata":"{}"},{"issue_id":".claude-oip","depends_on_id":".claude-ghj","type":"blocks","created_at":"2025-12-26T21:58:59.342582Z","created_by":"daemon","metadata":"{}"}]}
{"id":".claude-owd","title":"Polish open/close ritual edge cases","design":"Fixes identified from claude-memory research session (2025-12-28):\n\n## /open improvements\n1. **Plan \u003e Beads integration** — If plan file exists (spec.md, .claude/plans/*.md), reference it and show where ready beads fit in the larger plan\n2. **Scope mismatch detection** — Question incongruent handoffs based on cwd (don't blindly present handoff from project A when in project B)\n3. **Git distraction reduction** — Only surface uncommitted files if actually concerning; ignore .handoff, plan debris, normal session artifacts\n\n## /close improvements  \n4. **Phase counter** — Add \"Phase N of Q\" to output for situational awareness\n5. **Time greetings** — Get actual time via command, or drop time-based salutations entirely\n6. **Reflection closed-list energy** — Reframe Claude's observations as \"what resonates / what am I missing?\" not \"pick from this list\"\n7. **Reflection answer mismatch** — Consider more open prompting (\"what's on your mind?\") vs specific questions that trigger off-topic responses\n\n## Context\n- Friction patterns surfaced by analyzing /open and /close usage via claude-memory\n- User feedback: wants ritual to remember plan context, reduce cognitive load from non-issues, make reflection feel like dialogue not data collection","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T11:28:54.793388Z","updated_at":"2025-12-29T09:48:29.105713Z","closed_at":"2025-12-29T09:48:29.105713Z","close_reason":"Migrated to skill-session-management (ssm-pgl)"}
{"id":".claude-qmm","title":"Skill: Multi-agent design iteration patterns","design":"Extract learnings from SVG pipeline work (typed-sparking-narwhal plan, now deleted) into a skill.\n\nKey insights to capture:\n- Separate content spec (WHAT, frozen) from design principles (HOW, evolving)\n- Principles need three levels: WHAT (goals), WHY (rationale), HOW (implementation)\n- Multi-agent loops good for discovery/critique, single agent better for final polish\n- Designer → Reviewer → Updater pattern tested but had limitations\n- Agents repeat mistakes when principles say WHAT but not HOW\n\nCould be useful for any iterative creative work: slides, diagrams, documents.\nRelated: svg-dataviz skill, itv-brand skill","notes":"Folded into .claude-i9q (Conceptual charts skill) as methodology section.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-15T12:28:39.405561Z","updated_at":"2025-12-22T10:12:35.099277Z","closed_at":"2025-12-22T10:12:35.099288Z"}
{"id":".claude-qpn","title":"Check for official MCPs: Google Workspace, Calendar","description":"Watch for official MCPs from Google for Workspace (Drive, Docs, Sheets) and Calendar. Currently using custom mcp-google-workspace.\n\nWhere to check:\n- modelcontextprotocol/servers (GitHub)\n- Google developer announcements  \n- Claude Connectors (Anthropic-hosted)\n\nAlready official: GitHub, Todoist, Slack (community)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T20:34:40.803864Z","updated_at":"2026-01-03T14:46:50.239087Z","closed_at":"2026-01-03T14:46:50.239087Z","close_reason":"Found official Google Workspace MCP at gemini-cli-extensions/workspace. Forked to spm1001/workspace, created itv-auth branch with standalone OAuth support (no cloud function dependency). Works with ITV-approved OAuth credentials. Team can clone from fork."}
{"id":".claude-soh","title":"Fix bd show --json output parsing","description":"bd show \u003cid\u003e --json output can't be parsed with simple jq field access like .title - suggests structure is array or nested differently than expected","design":"Investigate actual JSON structure, document correct jq patterns, possibly file upstream issue if structure is awkward","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-26T00:16:40.910725Z","updated_at":"2025-12-26T09:15:32.812526Z","closed_at":"2025-12-26T09:15:32.812526Z","close_reason":"Documented correct jq patterns in SKILL.md. Array output is consistent design, not a bug - same parsing works for bd show, bd list, bd ready. Added examples for single-item and multi-item cases."}
{"id":".claude-t63","title":"Add model-change detection to SessionStart","design":"Track model version, prompt review on change","notes":"Consolidated into .claude-1wz (SessionStart/SessionStop hooks epic)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T18:58:02.563816Z","updated_at":"2025-12-14T23:40:17.65727Z","closed_at":"2025-12-14T23:40:17.657274Z"}
{"id":".claude-to1","title":"Resolve grep vs rg alias footgun in shell scripts","description":"Recurring issue: shell scripts use 'grep' expecting GNU grep semantics, but system aliases grep→rg. Causes subtle breakage (different flag syntax, output format, exit codes).\n\nTradeoff:\n(a) rg is genuinely better for interactive use (faster, better defaults)\n(b) Scripts expect grep semantics - 'command grep' is defensive but easy to forget\n(c) System instructions encourage using Grep tool (which uses rg), but Claude often writes bash with 'grep' anyway\n\nOptions to consider:\n1. Always use 'command grep' in scripts (verbose, easy to forget)\n2. Unalias grep in shell scripts (shebang with --norc?)\n3. Write scripts to use rg explicitly with rg flags\n4. Add shellcheck or linting to catch grep usage in scripts\n5. Document pattern in CLAUDE.md as gotcha\n\nDec 2025: Hit this twice - once in ap-audit.py subprocess calls, once in verify-firstboot.sh. Each time cost 15-20 min debugging.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T18:47:01.721107Z","updated_at":"2025-12-30T19:33:35.576855Z","closed_at":"2025-12-30T19:33:35.576855Z","close_reason":"Fixed by removing ~/.local/bin/grep wrapper script. grep now resolves to /usr/bin/grep. Claude follows system prompt guidance to use Grep tool or rg directly, so the wrapper was causing more harm than good."}
{"id":".claude-tvq","title":"Test prompt-based SessionEnd hook","design":"Test if type:'prompt' hooks can auto-invoke session-closedown skill.\n\nTwo approaches to explore:\n1. SessionEnd/Stop hook with type:'prompt' - fires when session ends\n2. Hook /exit command itself - intercept before exit, run closedown\n\nGoal: Automatic session-closedown without manual invocation.","notes":"RESOLUTION: SessionStart/End hook output is architecturally invisible to users (confirmed via GitHub issues #11120, #4084, #12151). Tested: plain echo, JSON hookSpecificOutput, JSON systemMessage, stderr+exit2 - none show in terminal.\n\nWORKAROUND: Created /handoff slash command for manual session context check. Hooks remain silent but functional for file operations (marker files, updater).\n\nSee: https://github.com/anthropics/claude-code/issues/11120 for feature request.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T18:58:01.298769Z","updated_at":"2025-12-20T08:13:35.408054Z","closed_at":"2025-12-20T08:13:35.408063Z"}
{"id":".claude-u88","title":"Used beads proto to create repeatable workflow template for skill development","description":"Encode skill creation as a beads proto with quality gates as required steps. Prevents skipping anthropic checker and skill-quality-gate.","design":"## Proto Structure\n\nmol-skill-creation\n├── Step 1: Create skill structure (SKILL.md, references/)\n│   └── Acceptance: SKILL.md exists with valid frontmatter\n├── Step 2: Run anthropic skill checker\n│   └── Depends: Step 1 closed\n│   └── Acceptance: Checker passes or issues addressed\n├── Step 3: Run skill-quality-gate\n│   └── Depends: Step 2 closed  \n│   └── Acceptance: Gate passes\n├── Step 4: Final review and commit\n│   └── Depends: Step 3 closed\n\n## Invocation\nbd pour mol-skill-creation --var name=\u003cskill-name\u003e\n\n## Related Skills\n- anthropic/skill-creator/ (checker)\n- ~/.claude/skills/skill-quality-gate/ (quality gate)\n\n## Variant Needed\nmol-skill-update for significant changes to existing skills (same gates, different Step 1)\n\n## Notes\nStashed for later. Try after open/close formalization proves the pattern.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-26T10:03:07.501816Z","updated_at":"2025-12-30T20:13:16.012366Z","closed_at":"2025-12-30T20:13:16.012366Z","close_reason":"Relocated to skill-beads repo."}
{"id":".claude-ulv","title":"Polish up the Looking skill","design":"The looking skill (screen capture for Claude) needs polish. Consolidated from Dec 2025 investigation.\n\n## Subtasks (from closed beads)\n\n### Multi-monitor support (.claude-5ss)\n- Test screencapture behavior with multi-monitor setup\n- Does -m capture main only? Does -D work for specific displays?\n- Update SKILL.md limitations section with findings\n\n### Launch directory investigation (.claude-6xl)\n- Currently screenshots go to pwd\n- User wants them in directory Claude was launched from\n- Investigate: CLAUDE_LAUNCH_DIR or similar env var?\n- May document current behavior as intentional\n\n### Scrollback/viewport capture (.claude-mte)\n- Current limitation: only captures visible viewport\n- Research scriptable approaches for full scrollable content\n- Third-party tools (Shottr, CleanShot X) do this interactively\n- May remain as documented limitation\n\n## General\n- Reliability improvements\n- Documentation updates","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-22T10:09:41.727028Z","updated_at":"2025-12-23T16:27:21.941311Z","closed_at":"2025-12-23T16:27:21.941311Z","close_reason":"Polished: added window categories (--categories, --category), fixed screenshot location (/tmp default), confirmed multi-monitor works, documented scrollback limitation.","dependencies":[{"issue_id":".claude-ulv","depends_on_id":".claude-5ss","type":"blocks","created_at":"2025-12-22T10:09:55.140028Z","created_by":"daemon","metadata":"{}"},{"issue_id":".claude-ulv","depends_on_id":".claude-6xl","type":"blocks","created_at":"2025-12-22T10:10:19.786187Z","created_by":"daemon","metadata":"{}"},{"issue_id":".claude-ulv","depends_on_id":".claude-mte","type":"blocks","created_at":"2025-12-22T10:13:51.271357Z","created_by":"daemon","metadata":"{}"}]}
{"id":".claude-w0t","title":"Build conversation memory extraction prototype","design":"Parse session JSONL files, extract patterns, build memories.jsonl","notes":"## Reference\nobra's episodic-memory article: https://blog.fsck.com/2025/10/23/episodic-memory/\n- Full semantic search of past conversations (SQLite + vector)\n- Already in superpowers submodule\n\n## Our Focus: Learning Extraction (not full recall)\nPriority is extracting PATTERNS and LEARNINGS, not raw conversation backup.\n- What techniques worked/failed\n- Decisions made and why\n- Discoveries worth remembering\n- Skills/workflows that emerged\n\nobra's plugin gives full recall. We want distillation → memories.jsonl.\nThese are complementary: extract learnings from the archive episodic-memory creates.\n\n## Possible Approach\n1. Install episodic-memory for archiving + search\n2. Build extraction layer on top: periodic summarization → learnings\n3. Output: structured memories.jsonl or CLAUDE.md updates","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T18:58:01.879417Z","updated_at":"2025-12-30T19:07:55.33052Z","closed_at":"2025-12-30T19:07:55.33052Z","close_reason":"Superseded — extraction prototype evolved into mem CLI + grounding skill in claude-memory repo.","dependencies":[{"issue_id":".claude-w0t","depends_on_id":".claude-485","type":"blocks","created_at":"2025-12-20T07:36:32.25019Z","created_by":"daemon","metadata":"{}"}]}
{"id":".claude-wtk","title":"Fix date typo in close skill handoff generation (says 2024 not 2025)","notes":"Subsumed by .claude-5lw (handoff ritual epic)","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-23T11:36:01.124925Z","updated_at":"2025-12-23T11:56:10.704915Z","closed_at":"2025-12-23T11:56:10.704919Z"}
{"id":".claude-x3j","title":"Create Crash Recovery skill","description":"Create skill for crash/context-loss recovery protocol. Currently only existed in CLAUDE.md (now removed). The procedure helps future Claude reconstruct context when session history is lost.","design":"## Context\n\nWhen Claude Code crashes and conversation history is lost, there's a protocol for reconstructing context. This was documented in ~/.claude/CLAUDE.md (being removed as part of cleanup - Dec 2024).\n\n## The Protocol (from CLAUDE.md)\n\n1. Check git status, git diff, git log -1 --stat\n2. Check bd ready and bd list --status in_progress (if using beads)\n3. Ask user: \"What were we working on when it crashed?\"\n4. Summarize reconstruction for confirmation before continuing\n\n### Session Reconstruction: Check All Working Directories\n\nWhen reconstructing, search ALL filesystem zones, not just current directory:\n\n```bash\n# Find all repos with recent commits\nfor repo in ~/Repos/*/; do\n  commits=$(git -C \"$repo\" log --oneline --since=\"yesterday\" 2\u003e/dev/null | head -1)\n  [ -n \"$commits\" ] \u0026\u0026 echo \"$repo: $commits\"\ndone\n```\n\n### Common Mistakes to Avoid\n\n- Focusing only on ~/.claude when implementation work lives in ~/Repos\n- Treating plan files as ground truth (plans describe intent, git logs show completion)\n- Guessing repo names instead of listing ~/Repos first\n\n### Ground Truth Hierarchy\n\nGit commits \u003e bd issue status \u003e plan files \u003e conversation memory\n\n## Skill Should Include\n\n1. The reconstruction protocol as a procedure\n2. Commands to run (git, bd)\n3. Filesystem zones to check\n4. The \"ground truth hierarchy\" principle\n5. Trigger: context loss, \"what were we working on\", session start after crash\n\n## Why Skill vs CLAUDE.md\n\nThis is a PROCEDURE to follow, not context about the user/environment. Skills are for procedures.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-23T06:48:56.245653Z","updated_at":"2025-12-30T20:10:00.450572Z","closed_at":"2025-12-30T20:10:00.450572Z","close_reason":"Won't do — idea didn't hold up."}
{"id":".claude-xl2","title":"Test Google MCP OAuth scope coverage with ITV","description":"Identify which scopes from Google's MCP are approved by ITV OAuth. Chat scopes are new and likely need approval.","design":"## Scopes to verify\nFrom google-workspace MCP:\n- chat.spaces, chat.messages, chat.memberships (NEW)\n- gmail.modify (was: gmail.readonly)\n- presentations.readonly, spreadsheets.readonly\n\n## Process\n1. Try each tool category\n2. Document which fail with auth errors\n3. Request additional scope approval if needed","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-03T14:53:50.021668Z","updated_at":"2026-01-03T15:31:15.154342Z","closed_at":"2026-01-03T15:31:15.154342Z","close_reason":"ITV OAuth scope testing deferred - MCP working with current scopes"}
{"id":".claude-xr4","title":"Design user tactics for working with Claude","design":"## Context\nFrom reflective session on multi-session learning patterns. User asked \"how can I get better at working with you?\" - we encoded Claude behaviors but deferred user tactics.\n\n## Scope\n- Concrete things USER can do, not just Claude behaviors\n- Anticipating architectural things without formal architecture background\n- When to interrupt, what phrases to use (\"draw it down\", \"pause\")\n- How to spot drift before it compounds\n- Using the buggy context indicator (10% = 20-30%) as closure trigger\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-25T21:17:50.341615Z","updated_at":"2025-12-25T22:46:20.908501Z","closed_at":"2025-12-25T22:46:20.908501Z","close_reason":"Evolved into epic .claude-43e (refactor /open /close with bidirectional learning). The original question 'how to develop architectural intuition' is addressed by adding reflection questions to /close ritual."}
{"id":".claude-xx8","title":"Made keep/fix/complement/deprecate decision","description":"Phase 4: Final decision with documented reasoning","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T21:58:03.228673Z","updated_at":"2025-12-26T22:54:00.831326Z","closed_at":"2025-12-26T22:54:00.831326Z","close_reason":"Decision: COMPLEMENT. Keep episodic-memory for keyword search. Real value is summaries (80% missing). Spec simpler system: generate summaries, text search them, drill into full conversations when promising. Skip vectors entirely.","dependencies":[{"issue_id":".claude-xx8","depends_on_id":".claude-4di","type":"parent-child","created_at":"2025-12-26T21:58:59.220673Z","created_by":"daemon","metadata":"{}"},{"issue_id":".claude-xx8","depends_on_id":".claude-o1v","type":"blocks","created_at":"2025-12-26T21:58:59.709232Z","created_by":"daemon","metadata":"{}"}]}
{"id":".claude-zfw","title":"Improve /open discovery with central handoffs","description":"When no local .handoff, check central archive and offer relevant handoffs.","design":"## Approach\n1. Check current directory for .handoff (existing behavior)\n2. If not found, check ~/.claude/handoffs/ for recent entries\n3. Match by: project name similarity, recency, or ask if ambiguous\n4. Time awareness: \"5 minutes ago\" not \"yesterday\"\n\n## Priority Logic\n| Scenario | What exists | Action |\n|----------|-------------|--------|\n| Normal | Local .handoff + central match | Use local |\n| Session from different dir | Central has fresher | Central wins |\n| Cross-project | Recent from other project | Offer it |\n| Stale local only | Local from weeks ago | Use local |\n\n## Files\n- open-context.sh\n- open.md\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","acceptance_criteria":"- [ ] open-context.sh checks central handoffs\n- [ ] Time-aware language implemented\n- [ ] Priority logic: match by project_path, then recency\n- [ ] Cross-project handoffs offered if recent and nothing else matches\n- [ ] End-to-end test of discovery","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-25T23:46:39.945217Z","updated_at":"2025-12-26T00:30:01.25481Z","closed_at":"2025-12-26T00:30:01.25481Z","close_reason":"Implemented central handoff discovery: time-aware language, project_path matching, cross-project fallback. Updated open-context.sh and open.md. All tests pass.","dependencies":[{"issue_id":".claude-zfw","depends_on_id":".claude-43e","type":"parent-child","created_at":"2025-12-25T23:46:50.002768Z","created_by":"daemon","metadata":"{}"},{"issue_id":".claude-zfw","depends_on_id":".claude-dqg","type":"blocks","created_at":"2025-12-25T23:46:50.232631Z","created_by":"daemon","metadata":"{}"}]}
{"id":".claude-zqy","title":"Merge workspace-fluency divergence","design":"Two versions have diverged, need proper merge:\n\nSOURCE OF TRUTH GOING FORWARD: ~/Repos/infra-mcp-workspace/skills/workspace-fluency/\n(skill should live with its companion MCP)\n\nKEEP FROM LOCAL (~/.claude/skills/workspace-fluency/):\n- search_workspace() two-stage pattern (newer tool)\n- Explicit core-fluency integration references\n- PARA-aware folder creation logic (0 Inbox, 1 Projects, etc.)\n- Leaner structure (removed verbose inline examples)\n\nKEEP FROM REPO (~/Repos/infra-mcp-workspace/skills/):\n- \"Claude Research\" naming (newer convention, replaces \"0 Inbox\")\n- MCP-aligned workflow descriptions\n- Memory integration patterns (may overlap with core-fluency)\n\nAFTER MERGE:\n1. Update repo version with merged content\n2. Delete ~/.claude/skills/workspace-fluency/\n3. Create symlink: ln -s ~/Repos/infra-mcp-workspace/skills/workspace-fluency ~/.claude/skills/workspace-fluency\n\nRELATED: Part of skills-with-companion-repos pattern established with linux-server-fluency.","notes":"Merged: Added search_workspace() docs, core-fluency integration, local vs remote access, PARA folder logic. Condensed workflows to reference file. Symlinked to repo. 577 lines (vs 678 before).","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-20T09:05:22.418015Z","updated_at":"2025-12-21T19:22:11.845605Z","closed_at":"2025-12-21T19:22:11.845641Z"}
{"id":"Repos-01a","title":"Meta: Build/fix iOS and macOS Shortcuts","design":"Master epic pointing to infra-shortcuts repo work. See infra-shortcuts-772.","notes":"Not tractable for Claude - Shortcuts are GUI-only, stored in CloudKit, no programmatic access. CLI can only run/list. Jellycuts would enable text-based authoring but adds complexity. Better suited to human work in GUI.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-14T19:30:23.239307Z","updated_at":"2025-12-22T22:04:56.373396Z","closed_at":"2025-12-22T22:04:56.3734Z"}
{"id":"Repos-033","title":"Review playpen-* and one-off repos","design":"Remaining items needing decisions:\n\n| Item | Question |\n|------|----------|\n| playpen-browsermcp | Keep as canonical heavy-MCP workspace, or rename? |\n| linkedin-analytics | One-off project - archive or keep? |\n| CLAUDE.md at ~/Repos root | Why here? Move to project or delete? |\n\nAlso: Should playpen-* become the standard prefix for experimental workspaces?","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T23:22:20.144814Z","updated_at":"2025-12-29T09:49:14.747514Z","closed_at":"2025-12-29T09:49:14.747514Z","close_reason":"Reviewed: playpen-browsermcp kept as canonical heavy-MCP workspace. linkedin-analytics renamed to itv-linkedin-analytics. ~/Repos/CLAUDE.md kept (useful container context). Other playpen repos already cleaned up in prior session.","dependencies":[{"issue_id":"Repos-033","depends_on_id":"Repos-5by","type":"parent-child","created_at":"2025-12-28T23:22:46.820356Z","created_by":"modha","metadata":"{}"}]}
{"id":"Repos-1vw","title":"Build toy models for Eric's marketing measurement questions","description":"Questions from Eric Seufert's VP Marketing screening questionnaire. Build working examples that demonstrate the answers, not just explain them.","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-22T21:51:45.904135Z","updated_at":"2025-12-25T21:02:20.979655Z","dependencies":[{"issue_id":"Repos-1vw","depends_on_id":"Repos-eq5","type":"parent-child","created_at":"2025-12-30T18:57:52.868079Z","created_by":"modha","metadata":"{}"}]}
{"id":"Repos-2u2","title":"Rename MCP repos to mcp-* prefix","design":"Part of naming convention cleanup. Pattern established: skill-* for skills, mcp-* for MCP servers.\n\nRepos to rename:\n- infra-mcp-workspace → mcp-workspace (Google Workspace MCP server)\n- myitv-search-mcp → mcp-myitv-search (ITV intranet search)\n- infra-html-tool-executor → mcp-html-executor (HTML tools via JSDOM)\n\nAfter rename: update any references in CLAUDE.md, .mcp.json files, symlinks.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T22:03:10.740896Z","updated_at":"2025-12-28T22:35:43.411609Z","closed_at":"2025-12-28T22:35:43.411609Z","close_reason":"Renamed 3 MCP repos (local + GitHub), updated symlink and all config references. User will handle MCP re-registration separately.","dependencies":[{"issue_id":"Repos-2u2","depends_on_id":"Repos-5by","type":"parent-child","created_at":"2025-12-28T22:04:46.342125Z","created_by":"modha","metadata":"{}"}]}
{"id":"Repos-4ey","title":"Improve session-closing to capture work-in-progress","design":"Gap identified: close ritual asks about git/learnings but doesn't check for incomplete work.\n\nShould add: 'TodoWrite has N items, M beads created. Capture outstanding work as beads before closing?'\n\nThis prevents context loss when sessions end with pending tasks.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T22:04:07.089022Z","updated_at":"2025-12-29T09:19:40.014154Z","closed_at":"2025-12-29T09:19:40.014154Z","close_reason":"Added TodoWrite state check to session-closing skill: Phase 1 checks incomplete items, Phase 2 offers to capture as beads, Phase 3 creates beads with discovered-from links","dependencies":[{"issue_id":"Repos-4ey","depends_on_id":"Repos-5by","type":"parent-child","created_at":"2025-12-28T22:05:06.723827Z","created_by":"modha","metadata":"{}"}]}
{"id":"Repos-4qs","title":"Push shareable skills public (own repos or multi-skill repo)","description":"Skills ready for public sharing after privacy/quality review. Options: (1) Push each as standalone repo, (2) Create multi-skill monorepo. Skills: skill-beads, skill-browser-driving, skill-checker, skill-collaborating, skill-diagramming, skill-filing, skill-github-cleanup, skill-image-generation, skill-listen, skill-screenshotting, skill-server-maintenance, skill-session-management, skill-sharing-scanner, skill-todoist-gtd. Excluded: skill-itv-styling (company-specific), mcp-google-workspace (needs remediation).","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-01T09:16:28.62394Z","updated_at":"2026-01-01T09:16:28.62394Z"}
{"id":"Repos-5by","title":"Repo Redux: Skill migration cleanup","design":"Cleanup work after major skill migration session (2025-12-28).\n\n## Scope\n- Verify migration integrity (symlinks, cross-refs)\n- MCP repo renames (mcp-* prefix)\n- GitHub remote updates\n- Playpen cleanup\n- Skill trigger improvements\n\n## Quick Wins First\n1. Cross-reference check (grep for old names)\n2. Symlink verification (ls -la)\n\n## Then Infrastructure\n3. MCP renames\n4. GitHub remotes\n5. Playpen cleanup\n6. Workspace-fluency extraction\n\n## Then Polish\n7-9. Skill trigger improvements","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-28T22:02:34.553663Z","updated_at":"2025-12-29T10:04:49.892542Z","closed_at":"2025-12-29T10:04:49.892542Z","close_reason":"Epic complete: Skills migrated to independent repos, naming rationalized (claude-*, infra-*, itv-*, mcp-*, skill-*), obsolete repos archived. Follow-on skill improvements tracked separately."}
{"id":"Repos-5x5","title":"Extract workspace-fluency to separate skill repo","design":"Currently lives inside mcp-workspace repo at skills/workspace-fluency/. \n\nDecision made: skills should be decoupled from MCPs for visibility (ls ~/Repos | grep skill- shows the set).\n\nSteps:\n1. Create ~/Repos/skill-workspace-fluency/\n2. Copy content from mcp-workspace/skills/workspace-fluency/\n3. Update symlink ~/.claude/skills/workspace-fluency → new location\n4. Remove skills/ folder from mcp-workspace repo\n5. Update any cross-references","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T22:03:41.512137Z","updated_at":"2025-12-29T09:27:23.472357Z","closed_at":"2025-12-29T09:27:23.472357Z","close_reason":"Won't extract: skill-google-workspace stays inside mcp-google-workspace as they work as a pair. Not all skills should be standalone repos — MCP-coupled skills belong with their parent.","dependencies":[{"issue_id":"Repos-5x5","depends_on_id":"Repos-5by","type":"parent-child","created_at":"2025-12-28T22:05:01.625357Z","created_by":"modha","metadata":"{}"}]}
{"id":"Repos-64p","title":"Test rules/ directory loading","description":"Verify ~/.claude/rules/*.md files load based on path context. Created but untested.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-02T21:56:29.524903Z","updated_at":"2026-01-02T21:56:29.524903Z"}
{"id":"Repos-67r","title":"Set up Syncthing between laptop and kube.lan","description":"Sync ~/Repos bidirectionally so claude-code-web setup and local dev stay in sync. Depends on claude-modus migration completing first so the structure is clean before syncing.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-02T22:48:23.991348Z","updated_at":"2026-01-02T22:49:18.874133Z","closed_at":"2026-01-02T22:49:18.874133Z","close_reason":"Created in wrong repo, moving to claude-code-web","dependencies":[{"issue_id":"Repos-67r","depends_on_id":"Repos-mkk","type":"blocked-by","created_at":"2026-01-02T22:48:23.9927Z","created_by":"modha","metadata":"{}"}]}
{"id":"Repos-6rm","title":"Build Kaplan-Meier survival curve explainer","description":"Biostatistics educational project - survival analysis fundamentals.","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-22T21:58:10.094139Z","updated_at":"2025-12-25T21:01:49.940266Z","dependencies":[{"issue_id":"Repos-6rm","depends_on_id":"Repos-eq5","type":"parent-child","created_at":"2025-12-30T18:57:37.588219Z","created_by":"modha","metadata":"{}"}]}
{"id":"Repos-73x","title":"Improve screenshotting skill proactive triggers","design":"Issue: Proactive use ('verify state after uncertain CLI operations') doesn't fire reliably.\n\nOptions:\n1. Add BEFORE/MANDATORY pattern to description\n2. Move proactive behavior to CLAUDE.md as baseline behavior\n3. Add specific trigger phrases: 'did that work?', 'check if it ran'\n\nTest with adversarial prompts to verify trigger reliability.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T22:04:19.761541Z","updated_at":"2025-12-29T10:07:06.040608Z","closed_at":"2025-12-29T10:07:06.040608Z","close_reason":"Added specific trigger phrases ('check the screen', 'did that work', 'verify it worked', 'what happened') and AFTER pattern for uncertain CLI operations.","dependencies":[{"issue_id":"Repos-73x","depends_on_id":"Repos-5by","type":"parent-child","created_at":"2025-12-28T22:05:16.911596Z","created_by":"modha","metadata":"{}"}]}
{"id":"Repos-7e2","title":"Verify all skill symlinks resolve correctly","design":"After skill migration, verify symlinks work:\n\nls -la ~/.claude/skills/*/SKILL.md\n\nShould show resolved paths, not broken symlinks. Also test that skills load in new Claude session.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T22:03:04.379603Z","updated_at":"2025-12-28T22:10:28.36792Z","closed_at":"2025-12-28T22:10:28.36792Z","close_reason":"Verified all 24 skill symlinks resolve correctly - no broken links","dependencies":[{"issue_id":"Repos-7e2","depends_on_id":"Repos-5by","type":"parent-child","created_at":"2025-12-28T22:04:41.243012Z","created_by":"modha","metadata":"{}"}]}
{"id":"Repos-8r3","title":"Explore TrailBase as SQLite backend","description":"Curiosity-driven exploration. See if it's worth adopting for any current projects.","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-22T21:54:12.292279Z","updated_at":"2025-12-25T21:02:10.631355Z","dependencies":[{"issue_id":"Repos-8r3","depends_on_id":"Repos-eq5","type":"parent-child","created_at":"2025-12-30T18:57:47.775135Z","created_by":"modha","metadata":"{}"}]}
{"id":"Repos-9fn","title":"Explore Apple Private Cloud Compute","description":"Haven't looked at docs yet. Pure curiosity.","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-22T21:55:32.274935Z","updated_at":"2025-12-25T21:02:00.281762Z","dependencies":[{"issue_id":"Repos-9fn","depends_on_id":"Repos-eq5","type":"parent-child","created_at":"2025-12-30T18:57:42.683186Z","created_by":"modha","metadata":"{}"}]}
{"id":"Repos-9s5","title":"Push unpushed skill repos","description":"12 repos committed but not pushed from earlier sessions. Risk of divergence.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-02T21:56:36.855856Z","updated_at":"2026-01-02T21:56:36.855856Z"}
{"id":"Repos-d0c","title":"Update GitHub remotes to match renamed repos","design":"All skill repos were renamed locally but GitHub remotes not updated.\n\nPattern: gh repo rename NEW-NAME --repo OWNER/OLD-NAME\n\nRepos needing GitHub rename (check which have remotes first):\n- skill-todoist-gtd, skill-collaborating, skill-screenshotting, skill-session-closing, skill-session-opening, skill-diagramming, skill-filing, skill-beads, skill-server-maintenance, skill-itv-styling, skill-checker, skill-cleanup-github, skill-browser-driving\n\nSome may be local-only (no remote yet). For those, just create new GitHub repo with correct name.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T22:03:28.087341Z","updated_at":"2025-12-28T23:12:01.874006Z","closed_at":"2025-12-28T23:12:01.874006Z","close_reason":"Created GitHub repos for all 13 skill repos. All pushed to spm1001/skill-* private repos.","dependencies":[{"issue_id":"Repos-d0c","depends_on_id":"Repos-5by","type":"parent-child","created_at":"2025-12-28T22:04:51.435533Z","created_by":"modha","metadata":"{}"}]}
{"id":"Repos-eq5","title":"Exploration Backlog","description":"Curiosity-driven exploration tasks - low urgency, pick up when interested. Topics: survival curves, Apple PCC, TrailBase, marketing measurement, Gmail automation.","status":"open","priority":2,"issue_type":"epic","created_at":"2025-12-30T18:57:08.997991Z","updated_at":"2025-12-30T18:57:08.997991Z"}
{"id":"Repos-h9o","title":"Meta: Create Playwright sandbox","design":"Master epic pointing to claude-playwright-env repo work. See claude-playwright-env-2zf.","notes":"Done but not tested in real use.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-14T19:30:28.471236Z","updated_at":"2025-12-22T21:05:56.063938Z","closed_at":"2025-12-22T21:05:56.063951Z"}
{"id":"Repos-i0p","title":"Rationalize claude-* repos naming","design":"7 repos with claude-* prefix need review:\n\n| Repo | Current Purpose | Decision Needed |\n|------|-----------------|-----------------|\n| claude-config | ~/.claude tracked in git | Keep as-is? |\n| claude-config-public | Public version of config | Merge, delete, or rename? |\n| claude-data-sync | Unknown | Investigate and decide |\n| claude-journal | Journal/blog content | Rename to blog-* or journal-*? |\n| claude-memory | Memory feature work | Keep or consolidate with feature-test? |\n| claude-memory-feature-test | Testing memory | Keep, archive, or merge? |\n| claude-web-playground | Web experiments | Rename to playpen-web or keep? |\n\nPattern question: Should claude-* be reserved for Claude Code tooling only?","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T23:22:13.519714Z","updated_at":"2025-12-29T09:46:28.95652Z","closed_at":"2025-12-29T09:46:28.95652Z","close_reason":"Reviewed claude-* repos: prefix is coherent — represents 'Claude Code ecosystem' (config, data sync, memory, journal). Keep as-is. Delegated claude-memory-feature-test cleanup to claude-memory work. claude-web-playground stays (or moves to playpen-* later).","dependencies":[{"issue_id":"Repos-i0p","depends_on_id":"Repos-5by","type":"parent-child","created_at":"2025-12-28T23:22:41.707154Z","created_by":"modha","metadata":"{}"}]}
{"id":"Repos-ie6","title":"Meta: Gmail AppScript for meeting notes","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"open","priority":2,"issue_type":"epic","created_at":"2025-12-14T19:30:33.722323Z","updated_at":"2025-12-25T21:02:31.321481Z","dependencies":[{"issue_id":"Repos-ie6","depends_on_id":"Repos-eq5","type":"parent-child","created_at":"2025-12-30T18:57:57.961867Z","created_by":"modha","metadata":"{}"}]}
{"id":"Repos-kci","title":"Clean up web playground repos","design":"Four repos identified, most redundant:\n\nKEEP:\n- claude-web-playground - Has actual code (browser-vs-fetch experiment), good docs\n- playpen-browsermcp - Has local .mcp.json for BrowserMCP, use as canonical 'heavy MCP' workspace\n\nDELETE:\n- playpen-playwright - Empty skeleton, no code, no setup done\n- claude-playwright-env - Already deleted this session\n\nAfter cleanup: update ~/Repos/CLAUDE.md if it references these","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T22:03:35.14803Z","updated_at":"2025-12-28T23:19:22.18636Z","closed_at":"2025-12-28T23:19:22.18636Z","close_reason":"Deleted playpen-playwright (empty). Kept playpen-browsermcp as BrowserMCP workspace.","dependencies":[{"issue_id":"Repos-kci","depends_on_id":"Repos-5by","type":"parent-child","created_at":"2025-12-28T22:04:56.528935Z","created_by":"modha","metadata":"{}"}]}
{"id":"Repos-kv6","title":"Verify cross-references after skill rename","design":"After major skill rename session (2025-12-28), grep for old names that might still be referenced.\n\nOld → New:\n- working-together → collaborating\n- looking → screenshotting\n- close-session → session-closing\n- svg-dataviz → diagramming\n- maintaining-linux-servers → server-maintenance\n- itv-brand → itv-styling\n- skill-quality-gate → skill-checker\n- driving-browser-skill → browser-driving\n\nCheck: CLAUDE.md (global + project), other skills, commands, any .md files in ~/.claude","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T22:02:57.22025Z","updated_at":"2025-12-28T22:10:22.017448Z","closed_at":"2025-12-28T22:10:22.017448Z","close_reason":"Fixed stale references in CLAUDE.md (2), settings.json (1), .gitignore (1), and rewrote skills/README.md to match current symlinks","dependencies":[{"issue_id":"Repos-kv6","depends_on_id":"Repos-5by","type":"parent-child","created_at":"2025-12-28T22:04:36.145984Z","created_by":"modha","metadata":"{}"}]}
{"id":"Repos-mkk","title":"Create claude-modus repo","description":"Agreed structure:\n- llms.txt (agent entry point)\n- README.md (minimal wayfinding, not a pitch)\n- CLAUDE.md (philosophy as config, scaffold = template)\n- skills/core/ (session-opening, session-grounding, session-closing, beads, memory, todoist-gtd)\n- skills/utilities/ (diagramming, filing, docx, pptx, xlsx, pdf, screenshotting, github-cleanup)\n\nOption B: skills live in claude-modus, symlinks point INTO it from ~/.claude/skills/\nReplaces 12+ individual skill repos.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-02T19:49:39.0681Z","updated_at":"2026-01-02T19:49:39.0681Z"}
{"id":"Repos-rwx","title":"CLAUDE.md full structural pass","description":"Discussed structure with opinionated headings:\n- Philosophy (at top)\n- Behavioral Style  \n- Session Lifecycle\n- Infrastructure (grouped)\n- Context\n\nCurrently only added Deliberate Overrides section. Full reorganization deferred.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-02T19:49:24.528255Z","updated_at":"2026-01-02T21:23:42.951277Z","closed_at":"2026-01-02T21:23:42.951277Z","close_reason":"Reorganized CLAUDE.md: Philosophy → Behavioral Style → Vocabulary → Session Lifecycle → Infrastructure → Context. Moved side quests and communication patterns to Philosophy, grouped all env/config under Infrastructure, created Context section for MIT Team and Two Claude Configs."}
{"id":"Repos-sd2","title":"Improve collaborating skill triggers","design":"Issues identified:\n1. Vague trigger 'when noticing drift from stated principles' doesn't fire reliably\n2. Side quests philosophy duplicated in both CLAUDE.md and skill\n3. Need sharper MANDATORY/BEFORE language in description\n\nImprovements needed:\n- Add specific trigger phrases that will actually fire\n- Dedupe side quests content (keep in CLAUDE.md, reference from skill)\n- Consider BEFORE pattern: 'BEFORE adding to plate, check overcommitment'\n- Test trigger reliability with adversarial prompts","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T22:04:13.374321Z","updated_at":"2025-12-29T10:07:00.92925Z","closed_at":"2025-12-29T10:07:00.92925Z","close_reason":"Added specific trigger phrases ('should I take this on', 'I said yes to', 'another meeting', 'they asked me to', 'this grew into') and BEFORE pattern for proactive detection.","dependencies":[{"issue_id":"Repos-sd2","depends_on_id":"Repos-5by","type":"parent-child","created_at":"2025-12-28T22:05:11.820269Z","created_by":"modha","metadata":"{}"}]}
{"id":"Repos-zie","title":"Review infra-* and itv-* naming consistency","design":"Check if these follow consistent patterns:\n\ninfra-* (6):\n- infra-gcp-discovery-engine\n- infra-linux-servers\n- infra-mac-setup\n- infra-openwrt\n- infra-signboard\n- infra-todoist-sync\n\nitv-* (3):\n- itv-appscript-deploy\n- itv-google-auth\n- itv-slides-formatter\n\nQuestions:\n- Is infra-todoist-sync infrastructure or tooling?\n- Should itv-google-auth be itv-* or shared infra?","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T23:22:26.461765Z","updated_at":"2025-12-29T10:01:43.7223Z","closed_at":"2025-12-29T10:01:43.7223Z","close_reason":"Reviewed infra-* and itv-* naming. Actions: infra-todoist-sync archived+deleted (obsolete, replaced by Todoist MCP). infra-gcp-discovery-engine → itv-gemini-searchability (it's ITV/MIT work). Other infra-* repos correct (personal infrastructure). itv-* repos correct.","dependencies":[{"issue_id":"Repos-zie","depends_on_id":"Repos-5by","type":"parent-child","created_at":"2025-12-28T23:22:51.92736Z","created_by":"modha","metadata":"{}"}]}
{"id":"ccw-065","title":"Set up Syncthing between laptop and kube.lan","description":"Sync ~/Repos bidirectionally so claude-code-web setup and local dev stay in sync. Depends on claude-modus migration (Repos-mkk) completing first so structure is clean.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-02T22:49:24.590482Z","updated_at":"2026-01-02T22:49:24.590482Z"}
{"id":"ccw-5yq","title":"Configure MCP servers on kube.lan","description":"Set up workspace MCP and other MCP servers on kube.lan so Claude Code Web has full capability.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-02T22:49:31.412123Z","updated_at":"2026-01-02T22:49:31.412123Z","dependencies":[{"issue_id":"ccw-5yq","depends_on_id":"ccw-065","type":"blocked-by","created_at":"2026-01-02T22:49:31.414059Z","created_by":"modha","metadata":"{}"}]}
{"id":"ccw-cdr","title":"Add monitoring for ttyd service","description":"Set up alerting if claude-web service goes down. Currently fails silently.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-02T22:53:05.629806Z","updated_at":"2026-01-02T22:53:05.629806Z"}
{"id":"ccw-g7l","title":"Enable HTTPS for ttyd via Tailscale certs","description":"Use 'tailscale cert' to get valid certs for kube.atlas-cloud.ts.net, configure ttyd with --ssl-cert/--ssl-key. Belt-and-suspenders over Tailscale's WireGuard encryption.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-02T22:54:20.112091Z","updated_at":"2026-01-02T22:54:20.112091Z"}
{"id":"ccw-jy6","title":"Test full handoff workflow","description":"Verify: close laptop mid-session → open browser to kube.lan → claude -c continues. Check sync timing, context preservation.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-02T22:53:06.568636Z","updated_at":"2026-01-02T22:53:06.568636Z"}
{"id":"cds-7fq","title":"Implement CloudSessionsClient for API calls","design":"## Implementation\n\nCreate `CloudSessionsClient` class that uses KeychainAuthClient:\n\n```python\nclass CloudSessionsClient:\n    BASE_URL = \"https://api.anthropic.com/v1\"\n    \n    def __init__(self, auth: KeychainAuthClient):\n        self.auth = auth\n        self.session = requests.Session()\n        self.session.headers.update(auth.get_headers())\n    \n    def list_sessions(self) -\u003e list[dict]:\n        \"\"\"GET /v1/sessions → list of session metadata\"\"\"\n        response = self.session.get(f\"{self.BASE_URL}/sessions\")\n        response.raise_for_status()\n        return response.json()[\"data\"]\n    \n    def get_session(self, session_id: str) -\u003e dict:\n        \"\"\"GET /v1/session_ingress/session/{id} → full session with loglines\"\"\"\n        response = self.session.get(\n            f\"{self.BASE_URL}/session_ingress/session/{session_id}\"\n        )\n        response.raise_for_status()\n        return response.json()\n```\n\n## Rate Limiting\n\n- Same 1 req/sec as web sync\n- Same retry logic for 429/5xx\n\n## Error Handling\n\n- 401 → Token expired, prompt re-login to Claude Code\n- 404 → Session not found (may have been deleted)","acceptance_criteria":"- [ ] CloudSessionsClient class implemented\n- [ ] list_sessions() returns session metadata\n- [ ] get_session() returns full session with loglines\n- [ ] Rate limiting (1 req/sec) applied\n- [ ] Retry logic for transient errors\n- [ ] Proper error handling for 401/404","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-28T09:27:16.682555Z","updated_at":"2025-12-28T09:32:29.883486Z","closed_at":"2025-12-28T09:32:29.883486Z","close_reason":"Implemented and tested. list_sessions() returns 64 sessions, get_session() returns full loglines.","dependencies":[{"issue_id":"cds-7fq","depends_on_id":"cds-8fe","type":"blocks","created_at":"2025-12-28T09:27:29.269398Z","created_by":"daemon","metadata":"{}"}]}
{"id":"cds-8fe","title":"Add KeychainAuthClient for OAuth token extraction","design":"## Implementation\n\nCreate a new class `KeychainAuthClient` that:\n1. Extracts OAuth token from Keychain using `security find-generic-password`\n2. Gets org UUID from `~/.claude.json`\n3. Provides headers for Anthropic API requests\n\n```python\nclass KeychainAuthClient:\n    def __init__(self):\n        self.access_token = self._get_token_from_keychain()\n        self.org_uuid = self._get_org_uuid()\n    \n    def _get_token_from_keychain(self) -\u003e str:\n        # Run: security find-generic-password -a \"$USER\" -w -s \"Claude Code-credentials\"\n        # Parse JSON, extract .claudeAiOauth.accessToken\n        \n    def _get_org_uuid(self) -\u003e str:\n        # Read ~/.claude.json\n        # Extract .oauthAccount.organizationUuid\n        \n    def get_headers(self) -\u003e dict:\n        return {\n            \"Authorization\": f\"Bearer {self.access_token}\",\n            \"anthropic-version\": \"2023-06-01\",\n            \"Content-Type\": \"application/json\",\n            \"x-organization-uuid\": self.org_uuid\n        }\n```\n\n## Error Handling\n\n- Keychain item not found → Clear error message about Claude Code login\n- Invalid JSON → Clear error message\n- Token expired → Need to investigate refresh mechanism (or prompt re-login)\n\n## Testing\n\n```bash\npython -c \"from claude_ai_sync import KeychainAuthClient; c = KeychainAuthClient(); print(c.get_headers())\"\n```","acceptance_criteria":"- [ ] KeychainAuthClient class implemented\n- [ ] Token extracted from Keychain successfully\n- [ ] Org UUID extracted from ~/.claude.json\n- [ ] Proper headers returned for API requests\n- [ ] Clear error messages for missing credentials","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-28T09:27:15.376426Z","updated_at":"2025-12-28T09:31:09.915524Z","closed_at":"2025-12-28T09:31:09.915524Z","close_reason":"Implemented and tested. Token extraction from Keychain works, org UUID from ~/.claude.json works."}
{"id":"cds-e5y","title":"Add cloud Claude Code session sync via OAuth","design":"## Context\n\nSimon Willison discovered Claude Code stores OAuth credentials in macOS Keychain:\n```bash\nsecurity find-generic-password -a \"$USER\" -w -s \"Claude Code-credentials\" | jq -r .claudeAiOauth.accessToken\n```\n\nThis provides access to cloud-based Claude Code sessions that don't exist locally:\n- claude.ai/code (web-based Claude Code)\n- GitHub integration sessions\n- Any cloud environment sessions\n\n## Data Model\n\n**API Endpoints:**\n- `GET /v1/sessions` — List all sessions (returns metadata)\n- `GET /v1/session_ingress/session/{id}` — Full session with loglines\n\n**Session structure:**\n```json\n{\n  \"id\": \"session_01AyMF...\",\n  \"title\": \"...\",\n  \"environment_id\": \"env_011C...\",\n  \"session_context\": {\n    \"model\": \"claude-opus-4-5-20251101\",\n    \"sources\": [{\"type\": \"git_repository\", \"url\": \"...\"}],\n    \"outcomes\": [{\"type\": \"git_repository\", \"git_info\": {...}}]\n  },\n  \"session_status\": \"idle|archived\"\n}\n```\n\n**Loglines structure:**\n```json\n{\n  \"loglines\": [\n    {\n      \"uuid\": \"...\",\n      \"cwd\": \"/home/user/...\",\n      \"gitBranch\": \"...\",\n      \"message\": {\"content\": \"...\", \"role\": \"user|assistant\"},\n      \"type\": \"user|assistant\"\n    }\n  ]\n}\n```\n\n## Key Differences from Web Sync\n\n| Aspect | Web (cookie) | Cloud (OAuth) |\n|--------|-------------|---------------|\n| Auth | Browser cookie (expires) | Keychain OAuth (managed) |\n| Endpoint | claude.ai/api | api.anthropic.com |\n| Headers | Cookie header | Authorization: Bearer |\n| Content | chat_messages[] | loglines[] |\n| Thinking | Not available | Included (signed) |\n| Context | None | Git repo, branch, cwd |\n\n## Storage\n\nSave to: `~/.claude/claude-ai/cache/sessions/{session_id}.json`\nUpdate manifest with session metadata for incremental sync.","acceptance_criteria":"- [ ] OAuth token extracted from Keychain automatically\n- [ ] Sessions listed via /v1/sessions endpoint\n- [ ] Session content fetched via /v1/session_ingress\n- [ ] Sessions saved to cache/sessions/ directory\n- [ ] Manifest tracks session sync state for incremental updates\n- [ ] --code-sessions CLI flag works\n- [ ] Existing conversation sync unaffected","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-28T09:26:32.728688Z","updated_at":"2025-12-28T09:37:19.469847Z","closed_at":"2025-12-28T09:37:19.469847Z","close_reason":"Epic complete. Cloud Claude Code session sync implemented with KeychainAuthClient, CloudSessionsClient, sync_code_sessions, and CLI integration."}
{"id":"cds-kbc","title":"Add --single-session flag for fetching individual cloud sessions","design":"## Implementation\n\nAdd `--single-session SESSION_ID` flag parallel to `--single UUID` for conversations:\n\n```python\nparser.add_argument('--single-session', metavar='SESSION_ID',\n                    help='Fetch single cloud session by ID (e.g., session_01AyMF...)')\n```\n\nUpdate sync_code_sessions to accept optional single_id parameter.\n\n## Behavior\n\n- `--single-session session_01AyMF...` → fetch only that session\n- Skip listing, go straight to get_session()\n- Still use incremental logic (check manifest)","acceptance_criteria":"- [ ] --single-session flag added\n- [ ] Fetches single session without listing all\n- [ ] Works with --dry-run","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T09:44:34.537696Z","updated_at":"2025-12-28T09:50:26.25859Z","closed_at":"2025-12-28T09:50:26.25859Z","close_reason":"Added --single-session flag for fetching individual cloud sessions. Works with dry-run."}
{"id":"cds-qpd","title":"Add tests for cloud sessions sync","design":"## Test Philosophy\n\nTests as specs with \"When X, it should Y\" comments. Focus on what would be really annoying if it broke.\n\n## KeychainAuthClient Tests\n\n```python\n# When Keychain has no Claude Code credentials, it should raise KeychainAuthError with helpful message\n# When credentials JSON is malformed, it should raise KeychainAuthError not crash\n# When ~/.claude.json is missing, it should raise KeychainAuthError with path\n# When ~/.claude.json has no organizationUuid, it should raise KeychainAuthError\n# When credentials are valid, it should return proper headers with Bearer token\n```\n\n## CloudSessionsClient Tests\n\n```python\n# When API returns 401, it should raise KeychainAuthError about expired token\n# When API returns 429, it should retry after delay (mock time.sleep)\n# When API returns 404 for session, it should return None not raise\n# When API returns 5xx, it should retry then return response\n# When list_sessions succeeds, it should return data array\n```\n\n## sync_code_sessions Tests\n\n```python\n# When manifest has session with matching updated_at, it should skip that session\n# When manifest is empty, it should fetch all sessions\n# When dry_run=True, it should not write any files\n# When one session fetch fails, it should continue with remaining sessions\n# When sessions directory doesn't exist, it should create it\n```\n\n## CLI Integration Tests\n\n```python\n# When --code-sessions passed without cookie file, it should succeed\n# When --conversations-only passed, it should not call sync_code_sessions\n# When Keychain auth fails during full sync, it should warn but continue\n```\n\n## Test Infrastructure\n\n- Use pytest\n- Mock subprocess.run for Keychain tests\n- Mock requests.Session for API tests\n- Use tmp_path fixture for file system tests","acceptance_criteria":"- [ ] KeychainAuthClient error cases tested\n- [ ] CloudSessionsClient retry logic tested\n- [ ] sync_code_sessions incremental logic tested\n- [ ] CLI flag combinations tested\n- [ ] All tests pass","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T09:44:35.966262Z","updated_at":"2025-12-28T09:50:25.194615Z","closed_at":"2025-12-28T09:50:25.194615Z","close_reason":"20 tests covering KeychainAuthClient, CloudSessionsClient, sync_code_sessions, and CLI integration. All pass."}
{"id":"cds-uh3","title":"Export artifact content from Claude.ai conversations","description":"Claude.ai conversations can contain artifacts (code, SVGs, documents, research reports) created during the conversation. These appear in a side panel and persist with the conversation.\n\nCurrently, claude-data-sync exports the conversation messages but NOT the artifact content. The exported JSON shows placeholder text where artifacts were rendered:\n- \"This block is not supported on your current device yet\"\n- \"Viewing artifacts created via the Analysis Tool web feature preview isn't yet supported on mobile\"\n\nThis means downstream consumers (like claude-memory) can find conversations that REFERENCE artifacts but cannot search the artifact CONTENT itself.","design":"## Current State\n\nConversation JSON structure (from cache/conversations/*.json):\n- chat_messages[].text — contains message text with artifact placeholders\n- chat_messages[].attachments — empty array (not used for artifacts)\n- chat_messages[].files / files_v2 — empty arrays\n\nArtifacts are likely stored server-side with references in the message, but the current sync doesn't retrieve them.\n\n## Investigation Needed\n\n1. Check Claude.ai web app network requests when viewing artifacts\n2. Identify API endpoint for artifact content retrieval\n3. Determine if artifacts have UUIDs linked to messages\n4. Check if artifacts require separate authentication\n\n## Potential Approaches\n\nA) **Inline extraction** — If artifact content is available via API, fetch during conversation sync and embed in JSON\nB) **Separate storage** — Store artifacts in cache/artifacts/{uuid}.{ext} with references in conversation JSON\nC) **On-demand fetch** — Add `--include-artifacts` flag that fetches artifact content separately\n\n## Considerations\n\n- Artifact types: code (various languages), SVG, markdown documents, HTML\n- Size: Some artifacts (research reports) can be substantial\n- Rate limiting: May need to batch artifact fetches\n- Authentication: Likely needs same auth as conversation sync","acceptance_criteria":"- [ ] Artifacts are exported alongside conversations\n- [ ] Artifact content is searchable by downstream tools\n- [ ] Existing sync workflow not broken (artifacts optional or automatic)\n- [ ] Artifact metadata preserved (type, language, title if any)","status":"open","priority":2,"issue_type":"epic","created_at":"2025-12-27T22:59:50.793553Z","updated_at":"2025-12-27T22:59:50.793553Z"}
{"id":"cds-vkx","title":"Add --code-sessions CLI flag and integration","design":"## CLI Changes\n\nAdd new argument:\n```python\nparser.add_argument('--code-sessions', action='store_true',\n                    help='Sync cloud Claude Code sessions (uses Keychain OAuth)')\n```\n\nUpdate main() logic:\n```python\n# Handle --code-sessions mode\nif args.code_sessions or not (args.conversations_only or args.skills_only):\n    try:\n        auth = KeychainAuthClient()\n        cloud_client = CloudSessionsClient(auth)\n        session_fetched, session_failed = sync_code_sessions(\n            cloud_client, manifest, dry_run=args.dry_run\n        )\n    except KeychainAuthError as e:\n        log.warning(f\"Cloud sessions unavailable: {e}\")\n        # Non-fatal - continue with other sync operations\n```\n\n## Behavior\n\n- `python claude_ai_sync.py` → Sync ALL (conversations + skills + code sessions)\n- `python claude_ai_sync.py --code-sessions` → Only code sessions\n- `python claude_ai_sync.py --conversations-only` → Only web conversations (no code sessions)\n\n## Documentation\n\nUpdate module docstring and README with:\n- New flag description\n- Auth requirements (Claude Code must be logged in)\n- What data is captured (cloud sessions with thinking blocks)","acceptance_criteria":"- [ ] --code-sessions flag added to argparse\n- [ ] Default behavior includes code sessions\n- [ ] --conversations-only excludes code sessions\n- [ ] Graceful degradation if Keychain auth fails\n- [ ] Help text explains the feature\n- [ ] CLAUDE.md updated with new workflow","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-28T09:27:19.790585Z","updated_at":"2025-12-28T09:37:12.48557Z","closed_at":"2025-12-28T09:37:12.48557Z","close_reason":"CLI integration complete. --code-sessions flag works, help updated, CLAUDE.md documented.","dependencies":[{"issue_id":"cds-vkx","depends_on_id":"cds-xhu","type":"blocks","created_at":"2025-12-28T09:27:29.359794Z","created_by":"daemon","metadata":"{}"}]}
{"id":"cds-xhu","title":"Add sync_code_sessions function with storage","design":"## Implementation\n\nAdd `sync_code_sessions()` function following same pattern as `sync_conversations()`:\n\n```python\nSESSIONS_DIR = CACHE_DIR / \"sessions\"\n\ndef sync_code_sessions(client: CloudSessionsClient, manifest: dict, \n                       dry_run: bool = False) -\u003e tuple[int, int]:\n    \"\"\"Sync cloud Claude Code sessions.\"\"\"\n    \n    SESSIONS_DIR.mkdir(parents=True, exist_ok=True)\n    \n    # List all sessions\n    sessions = client.list_sessions()\n    \n    # Determine what to fetch (incremental based on updated_at)\n    to_fetch = []\n    for session in sessions:\n        session_id = session[\"id\"]\n        updated_at = session[\"updated_at\"]\n        \n        existing = manifest.get(\"code_sessions\", {}).get(session_id)\n        if existing and existing.get(\"updated_at\") == updated_at:\n            continue  # Already synced, unchanged\n        \n        to_fetch.append(session)\n    \n    # Fetch and save each session\n    for session in to_fetch:\n        data = client.get_session(session[\"id\"])\n        \n        # Atomic write\n        output_path = SESSIONS_DIR / f\"{session['id']}.json\"\n        # ... same atomic write pattern as conversations\n        \n        # Update manifest\n        manifest.setdefault(\"code_sessions\", {})[session[\"id\"]] = {\n            \"title\": session[\"title\"],\n            \"updated_at\": session[\"updated_at\"],\n            \"fetched_at\": datetime.now(timezone.utc).isoformat(),\n            \"logline_count\": len(data.get(\"loglines\", []))\n        }\n```\n\n## Storage\n\nFiles saved to: `~/.claude/claude-ai/cache/sessions/{session_id}.json`\n\nEach file contains:\n- Full session metadata (id, title, environment_id, session_context)\n- All loglines with messages and thinking blocks","acceptance_criteria":"- [ ] sync_code_sessions() function implemented\n- [ ] Sessions saved to cache/sessions/ directory\n- [ ] Atomic writes (temp file + rename)\n- [ ] Manifest updated with code_sessions section\n- [ ] Incremental sync based on updated_at\n- [ ] Dry-run mode shows what would be fetched","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-28T09:27:18.365783Z","updated_at":"2025-12-28T09:34:21.795904Z","closed_at":"2025-12-28T09:34:21.795904Z","close_reason":"Implemented and tested. Sessions saved to ~/.claude/claude-ai/cache/sessions/ with full loglines including thinking blocks.","dependencies":[{"issue_id":"cds-xhu","depends_on_id":"cds-7fq","type":"blocks","created_at":"2025-12-28T09:27:29.31501Z","created_by":"daemon","metadata":"{}"}]}
{"id":"claude-go-0nc","title":"Mobile polish","description":"Mobile-first CSS refinements. Large buttons, pull-to-refresh, swipe gestures.","acceptance_criteria":"Touch-friendly (48px tap targets), responsive breakpoints, expandable input area.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-06T21:58:13.117535Z","created_by":"modha","updated_at":"2026-01-06T21:58:13.117535Z","dependencies":[{"issue_id":"claude-go-0nc","depends_on_id":"claude-go-tvd","type":"parent","created_at":"2026-01-06T21:58:13.118704Z","created_by":"modha"},{"issue_id":"claude-go-0nc","depends_on_id":"claude-go-r7t","type":"blocks","created_at":"2026-01-06T21:58:13.119693Z","created_by":"modha"}]}
{"id":"claude-go-20z","title":"Session manager (tmux wrapper)","description":"lib/sessions.js: Wrap tmux commands for session lifecycle. Create claude session in detached tmux, send-keys for input, poll for session health.","acceptance_criteria":"Can list, create, kill tmux sessions via API. Sessions persist when browser disconnects.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-06T21:57:15.529496Z","created_by":"modha","updated_at":"2026-01-06T22:04:12.40437Z","closed_at":"2026-01-06T22:04:12.40437Z","close_reason":"Implemented tmux wrapper in lib/sessions.js","dependencies":[{"issue_id":"claude-go-20z","depends_on_id":"claude-go-tvd","type":"parent","created_at":"2026-01-06T21:57:15.530573Z","created_by":"modha"},{"issue_id":"claude-go-20z","depends_on_id":"claude-go-j5z","type":"blocks","created_at":"2026-01-06T21:57:15.531097Z","created_by":"modha"}]}
{"id":"claude-go-23q","title":"Device handoff (lease model)","description":"Heartbeat every 5s, lease expires after 15s. New device can take over after expiry. WebSocket notification to old device.","acceptance_criteria":"Switch devices without session locked errors. Old device shows takeover banner.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-06T21:57:45.92638Z","created_by":"modha","updated_at":"2026-01-06T21:57:45.92638Z","dependencies":[{"issue_id":"claude-go-23q","depends_on_id":"claude-go-tvd","type":"parent","created_at":"2026-01-06T21:57:45.927568Z","created_by":"modha"},{"issue_id":"claude-go-23q","depends_on_id":"claude-go-iiw","type":"blocks","created_at":"2026-01-06T21:58:13.021425Z","created_by":"modha"}]}
{"id":"claude-go-279","title":"Drop zone for file uploads","description":"mkdir ~/dropzone on kube.lan. Files arrive via Tailscale/SCP/SFTP. Claude references ~/dropzone/filename. Optional: UI panel listing files with timestamps.","acceptance_criteria":"Files in /home/modha/dropzone/ visible to all Claude sessions. Optional UI panel shows files.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-06T21:58:13.224111Z","created_by":"modha","updated_at":"2026-01-06T21:58:13.224111Z","dependencies":[{"issue_id":"claude-go-279","depends_on_id":"claude-go-tvd","type":"parent","created_at":"2026-01-06T21:58:13.225347Z","created_by":"modha"}]}
{"id":"claude-go-419","title":"Add debug affordances for raw JSON inspection","description":"Currently tracing JSONL requires SSH + grep. Need UI affordances: copy-as-JSON button on messages, raw view toggle, peek at underlying data structure. Reduces friction when debugging rendering issues.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-07T00:17:04.847342Z","created_by":"modha","updated_at":"2026-01-07T00:17:04.847342Z"}
{"id":"claude-go-5o5","title":"JSONL tailer + parser","description":"lib/jsonl.js: Watch ~/.claude/projects/-home-modha-Repos/*.jsonl with chokidar. Line-buffered reader for partial write safety. Parse message types, accumulate streaming content, emit to WebSocket subscribers.","acceptance_criteria":"Streams parsed messages via WebSocket as file updates. Handles partial writes during streaming.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-06T21:57:23.809109Z","created_by":"modha","updated_at":"2026-01-06T22:04:12.462714Z","closed_at":"2026-01-06T22:04:12.462714Z","close_reason":"Implemented JSONL parser and watcher in lib/jsonl.js","dependencies":[{"issue_id":"claude-go-5o5","depends_on_id":"claude-go-tvd","type":"parent","created_at":"2026-01-06T21:57:23.810208Z","created_by":"modha"},{"issue_id":"claude-go-5o5","depends_on_id":"claude-go-j5z","type":"blocks","created_at":"2026-01-06T21:57:23.810693Z","created_by":"modha"}]}
{"id":"claude-go-6b2","title":"Working directory anchoring","description":"Users often want Claude anchored in a specific subfolder of Repos. Current architecture assumes ~/Repos but JSONL path encoding depends on cwd. Need to think about: session-specific cwd, path encoding handling, UI for choosing starting folder.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-06T22:10:57.030861Z","created_by":"modha","updated_at":"2026-01-06T22:10:57.030861Z","dependencies":[{"issue_id":"claude-go-6b2","depends_on_id":"claude-go-tvd","type":"parent","created_at":"2026-01-06T22:10:57.032513Z","created_by":"modha"}]}
{"id":"claude-go-6kz","title":"Session naming from Claude slugs","description":"Capture human-friendly session names like 'prancy-sleeping-hamming' from Claude output. Currently showing just UUIDs which are hard to distinguish.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-06T22:10:51.850943Z","created_by":"modha","updated_at":"2026-01-06T22:10:51.850943Z","dependencies":[{"issue_id":"claude-go-6kz","depends_on_id":"claude-go-tvd","type":"parent","created_at":"2026-01-06T22:10:51.852006Z","created_by":"modha"}]}
{"id":"claude-go-6vf","title":"Investigate mystery conversation label source","description":"\"Web UI renders Claude Code JSON conversations\" appears in the UI but we don't know where it's coming from in the JSONL. Track down the source.","status":"open","priority":2,"issue_type":"bug","created_at":"2026-01-07T00:17:04.051784Z","created_by":"modha","updated_at":"2026-01-07T00:17:04.051784Z"}
{"id":"claude-go-csl","title":"Refactor app.js into ES modules","description":"Current monolithic app.js mixes rendering, state, API, handlers. Split into modules for maintainability. Consider: render.js (message formatting), state.js (single source of truth), api.js (WebSocket + HTTP), handlers.js (event handling). Simple state store pattern, no framework yet.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-07T00:17:53.467641Z","created_by":"modha","updated_at":"2026-01-07T00:17:53.467641Z"}
{"id":"claude-go-dt5","title":"Systemd deployment","description":"claude-go.service unit file. Bind to 100.110.220.64 (Tailscale IP). Environment variables for production.","acceptance_criteria":"Service runs on kube.lan port 7682, survives reboot, Tailscale-only binding.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-06T21:58:13.32243Z","created_by":"modha","updated_at":"2026-01-06T21:58:13.32243Z","dependencies":[{"issue_id":"claude-go-dt5","depends_on_id":"claude-go-tvd","type":"parent","created_at":"2026-01-06T21:58:13.323496Z","created_by":"modha"},{"issue_id":"claude-go-dt5","depends_on_id":"claude-go-j5z","type":"blocks","created_at":"2026-01-06T21:58:13.323969Z","created_by":"modha"}],"comments":[{"id":3,"issue_id":"claude-go-dt5","author":"modha","text":"Before deploying: stop and disable claude-web.service (ttyd) on kube.lan. Commands: sudo systemctl stop claude-web \u0026\u0026 sudo systemctl disable claude-web","created_at":"2026-01-06T22:05:55Z"},{"id":4,"issue_id":"claude-go-dt5","author":"modha","text":"Verify tmux is installed on kube.lan: which tmux","created_at":"2026-01-06T22:10:41Z"}]}
{"id":"claude-go-ero","title":"Push notifications (ntfy.sh)","description":"lib/notify.js: Detect idle state from JSONL, push to ntfy.sh topic. Phone setup: install ntfy app, subscribe to topic.","acceptance_criteria":"Phone buzzes when Claude waiting for input (assistant + end_turn + 2s debounce).","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-06T21:57:45.832688Z","created_by":"modha","updated_at":"2026-01-06T22:10:36.351249Z","dependencies":[{"issue_id":"claude-go-ero","depends_on_id":"claude-go-tvd","type":"parent","created_at":"2026-01-06T21:57:45.833883Z","created_by":"modha"},{"issue_id":"claude-go-ero","depends_on_id":"claude-go-5o5","type":"blocks","created_at":"2026-01-06T21:57:45.83441Z","created_by":"modha"}]}
{"id":"claude-go-iiw","title":"Input handling","description":"Wire up input textarea to tmux send-keys. Quick action buttons for common operations.","acceptance_criteria":"Can send messages, Ctrl+C interrupt, approve/reject buttons work via tmux send-keys.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-06T21:57:45.74197Z","created_by":"modha","updated_at":"2026-01-06T21:57:45.74197Z","dependencies":[{"issue_id":"claude-go-iiw","depends_on_id":"claude-go-tvd","type":"parent","created_at":"2026-01-06T21:57:45.743328Z","created_by":"modha"},{"issue_id":"claude-go-iiw","depends_on_id":"claude-go-20z","type":"blocks","created_at":"2026-01-06T21:57:45.743859Z","created_by":"modha"},{"issue_id":"claude-go-iiw","depends_on_id":"claude-go-r7t","type":"blocks","created_at":"2026-01-06T21:57:45.745472Z","created_by":"modha"}]}
{"id":"claude-go-j5z","title":"Set up Node.js project structure","description":"Express + ws server scaffold. Create package.json, server.js, public/ directory structure.","acceptance_criteria":"npm start runs server on port 7682, serves static HTML at /","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-06T21:57:05.890336Z","created_by":"modha","updated_at":"2026-01-06T22:04:12.347652Z","closed_at":"2026-01-06T22:04:12.347652Z","close_reason":"Created package.json, server.js, lib/sessions.js, lib/jsonl.js, public/* files","dependencies":[{"issue_id":"claude-go-j5z","depends_on_id":"claude-go-tvd","type":"parent","created_at":"2026-01-06T21:57:05.891395Z","created_by":"modha"}]}
{"id":"claude-go-nbo","title":"Permission detection in JSONL parser","description":"Distinguish tool approval prompts from regular user input waiting. The JSONL has different patterns for these - need to surface 'needs permission' vs 'ready for message' in the UI.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-06T22:10:46.68177Z","created_by":"modha","updated_at":"2026-01-06T22:10:46.68177Z","dependencies":[{"issue_id":"claude-go-nbo","depends_on_id":"claude-go-tvd","type":"parent","created_at":"2026-01-06T22:10:46.683071Z","created_by":"modha"}]}
{"id":"claude-go-r7t","title":"Chat UI (client rendering)","description":"public/app.js + style.css: Render JSONL messages as chat bubbles. Markdown rendering, code block syntax highlighting, copy buttons. Mobile-first CSS.","acceptance_criteria":"Conversation renders with markdown, syntax-highlighted code blocks, copy buttons per block.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-06T21:57:33.259813Z","created_by":"modha","updated_at":"2026-01-06T21:57:33.259813Z","dependencies":[{"issue_id":"claude-go-r7t","depends_on_id":"claude-go-tvd","type":"parent","created_at":"2026-01-06T21:57:33.261008Z","created_by":"modha"},{"issue_id":"claude-go-r7t","depends_on_id":"claude-go-5o5","type":"blocks","created_at":"2026-01-06T21:57:33.261577Z","created_by":"modha"}]}
{"id":"claude-go-s2t","title":"Session persistence debugging","description":"tmux session died during service restart deploy. Need to understand why and make sessions more resilient.","design":"## Observed\n- User in active session\n- Deployed fix, service restarted\n- User's message stuck at pending (italics)\n- After refresh, session list empty\n- tmux list-sessions shows no claude- sessions\n\n## Questions\n1. Did the message reach tmux before WebSocket died?\n2. Why did the tmux session exit?\n3. Should we persist session IDs to reconnect to orphaned tmux sessions?\n\n## Possible fixes\n- Log tmux session lifecycle events\n- Check if claude process exited (and why)\n- Add session recovery on startup (scan for existing claude- tmux sessions)","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-06T23:05:12.635215Z","created_by":"modha","updated_at":"2026-01-06T23:15:04.650597Z","closed_at":"2026-01-06T23:15:04.650597Z","close_reason":"Fixed: KillMode=process in systemd service preserves tmux sessions across restarts"}
{"id":"claude-go-tvd","title":"Claude Go: Self-hosted Claude Code web client","description":"Can start Claude tasks on any device, close browser, get notified when attention needed, continue seamlessly from any other device.","acceptance_criteria":"1. Can start a Claude session from phone\n2. Can close browser, Claude keeps working\n3. Get push notification when Claude needs attention\n4. Can continue from desktop without losing context\n5. Device handoff works cleanly","status":"open","priority":1,"issue_type":"epic","created_at":"2026-01-06T21:56:57.672681Z","created_by":"modha","updated_at":"2026-01-06T21:56:57.672681Z"}
{"id":"claude-go-tvd.1","title":"Health check endpoint","description":"Add GET /health endpoint for monitoring. Should verify tmux is callable.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-06T23:18:51.627596Z","created_by":"modha","updated_at":"2026-01-06T23:18:51.627596Z","dependencies":[{"issue_id":"claude-go-tvd.1","depends_on_id":"claude-go-tvd","type":"parent-child","created_at":"2026-01-06T23:18:51.628164Z","created_by":"modha"}]}
{"id":"claude-go-tvd.10","title":"Actionable push notifications via ntfy.sh","description":"Instead of just 'tap to open app', let users respond directly from the notification. ntfy.sh supports action buttons that can POST to endpoints. Approve/Deny buttons could POST to /hook/respond without opening Claude Go.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-07T12:15:23.940011Z","created_by":"modha","updated_at":"2026-01-07T12:15:23.940011Z","dependencies":[{"issue_id":"claude-go-tvd.10","depends_on_id":"claude-go-tvd","type":"parent-child","created_at":"2026-01-07T12:15:23.940564Z","created_by":"modha"}]}
{"id":"claude-go-tvd.11","title":"Test ExitPlanMode UI","description":"ExitPlanMode rendering was built but not tested. Trigger plan mode in a session, verify the plan card renders with Approve/Reject buttons, test both paths.","status":"in_progress","priority":2,"issue_type":"task","created_at":"2026-01-07T12:15:25.610887Z","created_by":"modha","updated_at":"2026-01-07T12:23:21.483466Z","dependencies":[{"issue_id":"claude-go-tvd.11","depends_on_id":"claude-go-tvd","type":"parent-child","created_at":"2026-01-07T12:15:25.611358Z","created_by":"modha"}]}
{"id":"claude-go-tvd.12","title":"Wire up Notification and Stop hooks","description":"Server endpoints exist (/hook/notification, /hook/stop) but the actual hook scripts aren't created or registered in ~/.claude/settings.json. Create hooks/claude-go-notification.sh and hooks/claude-go-stop.sh, register on kube.lan.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-07T12:15:28.674704Z","created_by":"modha","updated_at":"2026-01-07T12:15:28.674704Z","dependencies":[{"issue_id":"claude-go-tvd.12","depends_on_id":"claude-go-tvd","type":"parent-child","created_at":"2026-01-07T12:15:28.675209Z","created_by":"modha"}]}
{"id":"claude-go-tvd.2","title":"Session history view","description":"Show dead sessions (JSONL exists, tmux gone) in session picker with grey dot. Allows viewing historical conversations.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-06T23:18:52.852716Z","created_by":"modha","updated_at":"2026-01-06T23:18:52.852716Z","dependencies":[{"issue_id":"claude-go-tvd.2","depends_on_id":"claude-go-tvd","type":"parent-child","created_at":"2026-01-06T23:18:52.853197Z","created_by":"modha"}]}
{"id":"claude-go-tvd.3","title":"WebSocket reconnection","description":"Handle browser sleep/wake gracefully. Currently WebSocket dies and doesn't reconnect. Should auto-reconnect and resync state.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-06T23:18:54.537514Z","created_by":"modha","updated_at":"2026-01-06T23:18:54.537514Z","dependencies":[{"issue_id":"claude-go-tvd.3","depends_on_id":"claude-go-tvd","type":"parent-child","created_at":"2026-01-06T23:18:54.53799Z","created_by":"modha"}]}
{"id":"claude-go-tvd.4","title":"Multi-line input entry","description":"Input box should handle multi-line text better. Currently single line feels cramped for longer prompts.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-06T23:22:12.568011Z","created_by":"modha","updated_at":"2026-01-06T23:22:12.568011Z","dependencies":[{"issue_id":"claude-go-tvd.4","depends_on_id":"claude-go-tvd","type":"parent-child","created_at":"2026-01-06T23:22:12.568486Z","created_by":"modha"}]}
{"id":"claude-go-tvd.5","title":"Markdown preview in input","description":"Preview markdown formatting in input box as user types. Or at minimum, visual hint that markdown is supported.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-06T23:22:13.29767Z","created_by":"modha","updated_at":"2026-01-06T23:22:13.29767Z","dependencies":[{"issue_id":"claude-go-tvd.5","depends_on_id":"claude-go-tvd","type":"parent-child","created_at":"2026-01-06T23:22:13.298144Z","created_by":"modha"}]}
{"id":"claude-go-tvd.6","title":"Copy button per message block","description":"Add copy button to each message bubble (not just code blocks). Makes it easy to grab Claude responses.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-06T23:22:14.403318Z","created_by":"modha","updated_at":"2026-01-06T23:22:14.403318Z","dependencies":[{"issue_id":"claude-go-tvd.6","depends_on_id":"claude-go-tvd","type":"parent-child","created_at":"2026-01-06T23:22:14.403806Z","created_by":"modha"}]}
{"id":"claude-go-tvd.7","title":"Push notifications via ntfy.sh","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-07T11:27:53.442571Z","created_by":"modha","updated_at":"2026-01-07T11:27:53.442571Z","dependencies":[{"issue_id":"claude-go-tvd.7","depends_on_id":"claude-go-tvd","type":"parent-child","created_at":"2026-01-07T11:27:53.443036Z","created_by":"modha"}]}
{"id":"claude-go-tvd.8","title":"End-to-end test on kube.lan","description":"Deploy and test permission flow: hook fires, server receives, mobile UI shows card, approve sends keystroke, Claude proceeds","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-07T11:28:02.278704Z","created_by":"modha","updated_at":"2026-01-07T11:28:02.278704Z","dependencies":[{"issue_id":"claude-go-tvd.8","depends_on_id":"claude-go-tvd","type":"parent-child","created_at":"2026-01-07T11:28:02.279218Z","created_by":"modha"}]}
{"id":"claude-go-tvd.9","title":"Refactor data-action magic strings to constants","description":"Extract 'select', 'toggle', 'submit-multi', 'approve', 'deny', 'copy' to named constants. Document the vocabulary.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-07T11:28:09.523738Z","created_by":"modha","updated_at":"2026-01-07T11:28:09.523738Z","dependencies":[{"issue_id":"claude-go-tvd.9","depends_on_id":"claude-go-tvd","type":"parent-child","created_at":"2026-01-07T11:28:09.524265Z","created_by":"modha"}]}
{"id":"claude-journal-7wi","title":"Claude Journal: Remaining setup and content","design":"Multi-session work for the claude-journal blog:\n\nDONE (Day 1):\n- Blog skeleton with ultra-clean TIL format\n- First post: Auditing the ~/.claude empire\n- GitHub Pages deployment\n- ~/.claude cleanup (debug logs, plugin cache)\n- Conversation retention extended to 99999 days\n\nREMAINING:\n- Skills investigation: Read superpowers skills, assess fit with working style\n- Conversation archive scripts (archive-conversations.sh, extract-conversations.py)\n- Second post: Giving Claude eyes (looking skill)\n- Third post: Auto-update hooks\n- Config documentation for claude-config-public\n- Public repo sync with redactions","notes":"## Blog Post: Looking Skill (\"Giving Claude Eyes\")\nBLOCKED BY:\n- Improvements to looking skill itself\n- Distill to public repo (~/Repos/claude-config-public)\n- Write setup steps including Screen Recording permissions for terminal app\n- Add Claude's perspective on what it 'feels' like (playful conceit)\n\n## Blog Post: Auto-Update Hooks\nSEPARATE POST (not combined with looking skill)\nBLOCKED BY: Public repo tidy-up\n\n## Blocker: Public Repo Sync\n~/Repos/claude-config-public needs updating before either post can be written.\nThis is the prerequisite for both posts.","status":"open","priority":2,"issue_type":"epic","created_at":"2025-12-19T21:02:18.684717Z","updated_at":"2025-12-19T22:21:45.998794Z"}
{"id":"claude-memory-0hp","title":"Add decision tree: memory vs session-grounding skill selection","description":"Add clear guidance for when to use memory skill vs session-grounding skill","design":"## Location\nCould go in:\n- memory SKILL.md (When to Use section)\n- session-grounding SKILL.md\n- Global CLAUDE.md\n- All three with cross-references\n\n## Decision Tree Draft\n- \"What's drifted THIS session?\" → session-grounding (/ground)\n- \"What did PAST sessions learn?\" → memory\n- \"I'm lost but context is current\" → session-grounding first, then memory if needed\n- \"I'm lost about historical context\" → memory directly\n\n## Acceptance\n- [ ] Decision tree exists somewhere prominent\n- [ ] Both skills reference each other appropriately","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T22:37:08.354867Z","updated_at":"2025-12-31T13:20:58.458162Z","closed_at":"2025-12-31T13:20:58.458162Z","close_reason":"Decision tree added to memory SKILL.md, cross-reference added to session-grounding SKILL.md"}
{"id":"claude-memory-19x","title":"Add project_path as filterable field in search","description":"Allow filtering search results by project path, enabling 'show me sessions about THIS project' queries.","design":"## Interface\nmem search \"query\" --project PATH\nmem search \"query\" --project .  # current directory\n\n## Implementation\n- project_path already exists in sources table for claude_code type\n- Add to search query as WHERE clause\n- Normalize paths for matching (resolve ~, handle trailing slashes)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T14:37:11.323405Z","updated_at":"2025-12-30T09:14:21.558168Z","closed_at":"2025-12-30T09:14:21.558168Z","close_reason":"Added --project filter to search. Supports '.' for current git repo or explicit paths. Converts to encoded format for database matching.","dependencies":[{"issue_id":"claude-memory-19x","depends_on_id":"claude-memory-4oe","type":"parent-child","created_at":"2025-12-29T14:37:19.196694Z","created_by":"daemon","metadata":"{}"}]}
{"id":"claude-memory-1e8","title":"Fix drill command and FTS5 edge cases","description":"Issues discovered during handoff adapter implementation:\n\n1. **drill --full broken for non-Claude-Code sources** — hardcoded to use ClaudeCodeSource.from_file() at cli.py:332-333. Fails silently for handoff and claude_ai sources.\n\n2. **Unquoted hyphens crash FTS5** — searching `draw-down` causes SQL error (\"no such column: down\"). Must quote: `\"draw-down\"`. Should either document or handle gracefully.","design":"## drill fix\nDispatch based on source_type:\n- claude_code → ClaudeCodeSource.from_file()\n- claude_ai → ClaudeAISource.from_file() \n- handoff → just cat the file (it's already readable markdown)\n\n## FTS5 fix\nOptions:\nA) Document in CLAUDE.md that hyphens need quoting\nB) Pre-process queries to quote hyphenated words\nC) Catch the SQL error and suggest quoted syntax","acceptance_criteria":"- [ ] drill --full works for all 3 source types\n- [ ] Hyphenated searches don't crash (either handled or documented)\n- [ ] Tests added for drill with each source type","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T23:16:44.984087Z","updated_at":"2025-12-28T10:27:01.99618Z","closed_at":"2025-12-28T10:27:01.99618Z","close_reason":"Fixed both issues:\n\n1. drill --full now dispatches by source_type:\n   - handoff: displays raw markdown\n   - claude_ai: parses JSON and shows messages (with virtual path resolution)\n   - cloud_session: parses JSON and shows messages\n   - claude_code: existing behavior preserved\n\n2. FTS5 hyphenated search errors now caught and suggest quoting:\n   - Detects 'no such column' errors\n   - Suggests: mem search '\"draw-down\"'\n\nAdded test_cli_drill.py with 6 tests covering all drill source types and hyphen handling."}
{"id":"claude-memory-23l","title":"Clean extraction pollution from test corpus","description":"Old hook spawned Claude subprocesses that created 'extraction sessions'. These are indexed and could corrupt test results.","design":"Approach:\n1. Identify extraction sessions: title LIKE '%Entity Extraction%' OR title LIKE '#%'\n2. Either:\n   a) Delete from sources table, OR\n   b) Add is_extraction_session flag and filter in queries\n   \nOption (a) is cleaner - these sessions have no value.\n\nAlso check test_corpus.yaml doesn't include any.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-28T16:48:35.018984Z","updated_at":"2025-12-28T22:15:07.494023Z","closed_at":"2025-12-28T22:15:07.494023Z","close_reason":"Deleted 5 hook-spawned extraction sessions (title LIKE '# Entity Extraction Task%'). Kept 2 legitimate dev sessions (400+ lines). Test corpus was clean."}
{"id":"claude-memory-25a","title":"Import migrated handoffs to searchable database","description":"73 handoffs migrated to new folder structure (~/.claude/handoffs/-{path}/). Need to import them into claude-memory's searchable index so 'mem' commands can find historical session context.","design":"Handoffs are now in ~/.claude/handoffs/-Users-modha-Repos-*/*.md format. Scan all folders, extract content, add to database with project metadata.","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-29T22:35:12.17591Z","updated_at":"2025-12-30T09:09:59.818045Z","closed_at":"2025-12-30T09:09:59.818045Z","close_reason":"Handoffs rescanned with new adapter. 74 handoffs now indexed with correct project_name and project_path derived from parent directory."}
{"id":"claude-memory-27c","title":"Fix title extraction for compacted Claude Code conversations","design":"Look for type:summary entries first, skip isMeta messages, filter warmup sessions. Fixes noisy titles like 'Context: This summary will be shown...'","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-28T09:24:57.891796Z","updated_at":"2025-12-28T09:36:54.833986Z","closed_at":"2025-12-28T09:36:54.833986Z","close_reason":"Fixed title extraction: type:summary entries, isMeta skip, warmup filter, \u003csummary\u003e tag extraction. Zero noisy titles (was 392)."}
{"id":"claude-memory-2kh","title":"Add handoff files adapter for ~/.claude/handoffs/*.md","description":"Index session handoffs as a source type. Already distilled summaries with date, done/learned/interesting/next structure. Include validation that reflections section is present (bidirectional learning capture).","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T22:32:31.633903Z","updated_at":"2025-12-27T23:13:17.748592Z","closed_at":"2025-12-27T23:13:17.748592Z","close_reason":"Handoff adapter complete. 23 files indexed with full section content (Done, Learned, Interesting, Next, Reflection). Searchable with --type handoff filter."}
{"id":"claude-memory-2ln","title":"Fix 37 glossary key/name misalignments","description":"Run mem glossary-check and fix entities where key differs from name","design":"## Context\nmem glossary-check found 37 entities where key (e.g., household_lift) differs from name (e.g., Household:Lift) and key is not in aliases.\n\n## Fix Options\n1. Add key as alias to each entity\n2. Rename keys to match names (breaking if anything references by key)\n3. Script to auto-add keys as aliases\n\n## Acceptance\n- [ ] mem glossary-check shows 0 key/name misalignments","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-31T15:42:46.254018Z","updated_at":"2025-12-31T16:21:36.420542Z","closed_at":"2025-12-31T16:21:36.420542Z","close_reason":"Added all 37 snake_case keys as aliases - glossary-check now passes"}
{"id":"claude-memory-2sa","title":"Write prompts/hybrid.md with final prompt design","description":"Codify the hybrid prompt that combines B+C into prompts/hybrid.md","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-28T21:35:01.296938Z","updated_at":"2025-12-28T21:39:34.793517Z","closed_at":"2025-12-28T21:39:34.793517Z","close_reason":"Written: prompts/hybrid.md with full design rationale, chunking approach, and usage examples"}
{"id":"claude-memory-30j","title":"Implement Phase 4: Google Sources","description":"Google auth, Docs/Sheets adapters, Gmail (narrow scope). See spec.md ## Implementation Order \u003e Phase 4. Blocked by Phase 3.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-27T19:40:21.433031Z","updated_at":"2025-12-28T23:06:50.340612Z","closed_at":"2025-12-28T23:06:50.340612Z","close_reason":"Deferred: Google sources don't serve the 5 benchmark questions. Workspace MCP already provides Google Docs access. Revisit if memory system proves valuable for Claude sessions first.","dependencies":[{"issue_id":"claude-memory-30j","depends_on_id":"claude-memory-jag","type":"blocks","created_at":"2025-12-27T19:40:30.31721Z","created_by":"daemon","metadata":"{}"}]}
{"id":"claude-memory-3iy","title":"Add mtime-based change detection for local_md rescan","description":"Currently mem scan --source local_md rescans all 2316 files. Add mtime comparison to skip unchanged files.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-31T17:33:35.286672Z","updated_at":"2025-12-31T17:54:41.107957Z","closed_at":"2025-12-31T17:54:41.107957Z","close_reason":"mtime-based change detection: stores mtime as content_hash, compares before processing, skips unchanged files. 2316 files scan now 0.16s."}
{"id":"claude-memory-3qt","title":"Optimize extraction fallback in mem recent","description":"get_display_title() queries database per-row for extraction summary. Slow for large result sets.","design":"## Problem\nWhen mem recent returns 100+ rows, it does 100+ individual queries for extraction fallback.\n\n## Fix\nBatch fetch extractions for all source IDs in one query, populate cache upfront.\n\n## Acceptance\n- [ ] Single query fetches all needed extractions\n- [ ] Performance acceptable for 100+ row results","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-31T13:00:39.000342Z","updated_at":"2025-12-31T16:18:55.695057Z","closed_at":"2025-12-31T16:18:55.695057Z","close_reason":"Batch prefetch extractions in mem recent - 72ms for 100 rows (was N+1 queries)"}
{"id":"claude-memory-3v7","title":"Add in-context extraction path for /close integration","description":"Current extraction requires ANTHROPIC_API_KEY. When invoked from /close, we're already inside Claude Code (Max subscription) — should use that context instead of separate API call.","design":"## Problem\n`mem process` calls the Anthropic API for extraction. When invoked from /close:\n- ✅ Indexing works (no LLM needed)\n- ❌ Extraction fails (no API key in that context)\n\n## Solution: Split extraction for in-context use\n\n**New commands:**\n\n1. `mem extract-prompt \u003csession-id\u003e`\n   - Reads session content from DB/file\n   - Outputs the extraction prompt + content to stdout\n   - Claude Code can pipe this to itself\n\n2. `mem store-extraction \u003csession-id\u003e`\n   - Reads extraction JSON from stdin\n   - Writes to extractions table\n   - Triggers FTS sync (already implemented)\n\n**Usage from /close:**\n```bash\n# Phase 0: Index only (already works)\nuv run mem process session.jsonl --no-hybrid --no-extract\n\n# Phase 1: Claude reads prompt, generates extraction inline\nPROMPT=$(uv run mem extract-prompt claude_code:abc123)\n# Claude generates extraction from prompt...\n# Then writes results:\necho '$EXTRACTION_JSON' | uv run mem store-extraction claude_code:abc123\n```\n\n## Why this works\n- Indexing: No LLM needed, works now\n- Extraction LLM call: Happens in Claude Code context (Max subscription)\n- Storage: mem CLI handles DB writes, FTS sync\n\n## Alternative considered\nOption A (subagent pattern) — spawns Task agent to do extraction. Works but adds complexity. Option B keeps extraction logic in claude-memory.","acceptance_criteria":"- [ ] `mem extract-prompt \u003cid\u003e` outputs extraction prompt + session content\n- [ ] `mem store-extraction \u003cid\u003e` reads JSON from stdin, writes to DB\n- [ ] FTS sync happens automatically on store\n- [ ] /close can use this path without API key\n- [ ] Test: index → extract-prompt → manual extraction → store → search finds it","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-29T11:41:20.33029Z","updated_at":"2025-12-29T11:45:44.457073Z","closed_at":"2025-12-29T11:45:44.457073Z","close_reason":"Implemented extract-prompt and store-extraction commands. /close can now: 1) Index with process --no-hybrid --no-extract, 2) Get prompt via extract-prompt, 3) Generate extraction in Claude Code context, 4) Store via store-extraction. FTS sync automatic."}
{"id":"claude-memory-4f9","title":"Implement Phase 5: Polish","description":"Claude Desktop adapter, MCP server, mem digest, mem relocate, quality scoring. See spec.md ## Implementation Order \u003e Phase 5. Blocked by Phase 4.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-27T19:40:21.475429Z","updated_at":"2025-12-28T23:06:51.50884Z","closed_at":"2025-12-28T23:06:51.50884Z","close_reason":"Deferred: Polish phase premature. Focus on hybrid integration first. MCP server, quality scoring, etc. can wait until core extraction value is proven.","dependencies":[{"issue_id":"claude-memory-4f9","depends_on_id":"claude-memory-30j","type":"blocks","created_at":"2025-12-27T19:40:30.349231Z","created_by":"daemon","metadata":"{}"}]}
{"id":"claude-memory-4jz","title":"Add mem glossary-check command","design":"Audit glossary for common issues:\n1. Entities where key differs from name and key not in aliases (e.g., csp vs CS\u0026P)\n2. Duplicate aliases across entities\n3. Orphaned auto_mappings that could graduate to full entities\n\nOutput: list of suggested fixes","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T18:21:25.145924Z","updated_at":"2025-12-31T14:21:50.702338Z","closed_at":"2025-12-31T14:21:50.702338Z","close_reason":"Added mem glossary-check command. Finds: key/name misalignment (37 found), duplicate aliases, orphaned auto_mappings."}
{"id":"claude-memory-4oe","title":"Phase 4: Access Interfaces","description":"Make memory system accessible beyond CLI — MCP server for Claude Desktop, CLI polish.","design":"## Scope\nExpose memory search to other interfaces, primarily Claude Desktop via MCP.\n\n## Deliverables\n1. MCP server with memory_search, memory_recent, memory_drill tools\n2. CLI polish — `mem recent`, better error messages, help text\n3. Quality scoring for sources (flag thin summaries)\n\n## Acceptance Criteria\n- [ ] MCP server runs and responds to tool calls\n- [ ] Claude Desktop can search memory without leaving chat\n- [ ] `mem recent --days 7` shows activity summary\n- [ ] Sources with thin extractions flagged for re-processing","notes":"SESSION: 2025-12-29\n\nPIVOT: Original design was MCP server for Claude Desktop. Pivoted to skill-based approach since user lives in Claude Code. Much simpler, zero infrastructure.\n\nCOMPLETED:\n- Created grounding skill (~/Repos/claude-memory/skill-grounding/)\n- Symlinked to ~/.claude/skills/grounding\n- Implemented mem recent command with project detection and handoff matching\n- Tested grounding skill live — synthesized 7 themes from 10+ ancestral sessions (~2500 tokens)\n- Closed mem recent bead (claude-memory-830)\n\nKEY DISCOVERY:\n- Handoff folder structure should match Claude Code sessions (same project_path format)\n- Filed ssm-2fd in session-management, claude-memory-hsx here with cross-project dependency\n\nREMAINING:\n- CLI polish (error messages, help text)\n- Quality scoring for sources (flag thin summaries)\n- Hyphen handling (claude-memory-zdn)\n- Project filter for search (claude-memory-19x)\n- Handoff adapter update (blocked by ssm-2fd)\n\nNEXT SESSION:\n- Could close this epic (core objective met: grounding skill works)\n- Or continue with CLI polish tasks\n- Or work on ssm-2fd to unblock handoff structure fix","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-29T13:12:44.646054Z","updated_at":"2025-12-31T13:15:56.43495Z","closed_at":"2025-12-31T13:15:56.43495Z","close_reason":"Core objective achieved: grounding skill works, mem recent implemented, all children closed. CLI polish tasks can be separate if needed."}
{"id":"claude-memory-53l","title":"Show transparent truncation info in drill output","description":"User feedback: \"Truncation opaque — output said ... (truncated) but didn't indicate how much\"\n\nCurrently just shows \"... (truncated)\". User can't tell if they're missing 10% or 50%.\n\nSuggestion: Show (showing 2000 of 6000 chars) or similar.","design":"Simple fix in drill output loop:\n- Track total content length\n- When truncating: f\"... (showing {displayed} of {total} chars)\"","status":"closed","priority":3,"issue_type":"feature","created_at":"2025-12-28T10:29:53.061099Z","updated_at":"2025-12-28T10:37:14.584595Z","closed_at":"2025-12-28T10:37:14.584595Z","close_reason":"Truncation now shows 'showing 2000 of 6543 chars' instead of just '(truncated)'."}
{"id":"claude-memory-5ei","title":"Run sync-fts after backfill completes","design":"Backfill is running in background (ba90539). When complete:\n1. Check coverage: should be ~95%+ for claude_code\n2. Run: uv run mem sync-fts\n3. Verify: mem search for a recent learning should work\n\nThis ensures newly extracted learnings are FTS-indexed.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-30T09:59:43.300014Z","updated_at":"2025-12-30T10:50:00.231653Z","closed_at":"2025-12-30T10:50:00.231653Z","close_reason":"Synced 219 new FTS entries with rich extraction content (learnings, builds, friction).","dependencies":[{"issue_id":"claude-memory-5ei","depends_on_id":"claude-memory-m1f","type":"blocks","created_at":"2025-12-30T10:03:10.058749Z","created_by":"daemon","metadata":"{}"}]}
{"id":"claude-memory-5z2","title":"Index bead notes in memory system","description":"Enable mem search to find content from bead notes, design fields, and closed issues. Beads and memory become searchable together.","design":"## Vision\nWhen resuming work after weeks:\n- mem search finds relevant past sessions\n- mem search ALSO finds bead notes with design decisions\n- Field reports surface as institutional knowledge\n\n## Approach\nAdd BeadsAdapter to claude-memory that indexes .beads/issues.jsonl content.\n\n## Scope\n- Index open AND closed beads (closed contain valuable decisions)\n- Extract: title, description, design, notes, acceptance_criteria\n- Source type: `beads`\n- Track last_updated to avoid re-indexing\n\n## Origin\nMoved from skill-beads repo — work lives where it happens.","status":"closed","priority":1,"issue_type":"epic","created_at":"2026-01-01T23:08:51.834226Z","updated_at":"2026-01-02T20:54:53.653895Z","closed_at":"2026-01-02T20:54:53.653895Z","close_reason":"Beads adapter implemented: 405 beads indexed across 8 projects. Discovery via registry + fallback glob. updated_at change detection. Pre-summarized content indexed (title, description, design, notes, acceptance_criteria, close_reason). Search finds bead content alongside sessions."}
{"id":"claude-memory-6dm","title":"Beads adapter: Harden registry fallback for dormant projects","description":"Registry.json only tracks running daemons. If a project's daemon isn't running and isn't in fallback_paths, its beads won't be discovered. Consider scanning ~/Repos/*/.beads/ by default or tracking known beads locations.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-02T21:14:52.538219Z","updated_at":"2026-01-02T21:14:52.538219Z"}
{"id":"claude-memory-6sd","title":"Improve drill default output (show summary without --full)","description":"User feedback: \"drill without --full was nearly useless — just returned title/date/path\"\n\nCurrently drill shows only metadata. User had to discover --full was needed.\n\nSuggestion: Show at least a summary or first exchange by default. Consider --full as default with --brief as the option.","design":"Options:\n1. Show summary text (from summaries table) by default\n2. Show first user message + first assistant response\n3. Flip defaults: --full is default, --brief shows metadata only\n\nOption 1 is simplest — summary already exists in DB, just display it.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-28T10:29:52.937215Z","updated_at":"2025-12-28T10:35:35.239673Z","closed_at":"2025-12-28T10:35:35.239673Z","close_reason":"drill now shows summary by default. Only --full shows the full conversation content."}
{"id":"claude-memory-765","title":"Implement Phase 2: Entity Pipeline","description":"LLM integration, extraction prompts, interactive entity resolution, glossary management. See spec.md ## Implementation Order \u003e Phase 2. Blocked by Phase 1.","notes":"PHASE 2 PROGRESS (2025-12-28):\n\nCOMPLETED:\n- LLM client module (src/mem/llm.py) - Anthropic API\n- Entity tables: source_entities, pending_entities\n- CLI commands: mem extract, mem resolve, mem process\n- SessionEnd hook working\n- 46 tests passing\n\nEXTRACTION EVALUATION (cn2):\n- Tested variants A, B, C on 10+ sessions\n- Converged on hybrid prompt (B+C combined)\n- Chunking approach validated for large sessions\n- Benchmark questions Q2 and Q3 answerable\n\nEXIT CRITERION STATUS:\nThe 5 benchmark questions:\n1. /open /close ritual improvement? - C's patterns field captures this\n2. Big builds and learnings? - ✓ ANSWERED with hybrid prompt\n3. TIL blog post candidates? - ✓ ANSWERED with aggregation + synthesis\n4. Claude.ai vs Code differences? - Needs cross-session aggregation (testable)\n5. Skill usage patterns? - Needs metadata queries (testable)\n\n3/5 confirmed answerable, 2/5 need verification but approach is sound.\n\nNEXT:\n- Implement hybrid prompt in pipeline\n- Add chunking for large sessions\n- Haiku downgrade test\n- Verify Q1, Q4, Q5","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-27T19:40:21.347743Z","updated_at":"2025-12-28T22:28:49.185527Z","closed_at":"2025-12-28T22:28:49.185527Z","close_reason":"Phase 2 Entity Pipeline complete:\n- Hybrid extraction prompt designed and validated (prompts/hybrid.md)\n- Model choice: Sonnet (Haiku quality insufficient)\n- Benchmark validation: Q1-Q3 answerable, Q4-Q5 need Phase 3\n- Chunking approach documented (rarely needed)\n- Hook error handling added\n\nReady for Phase 3: Full Source Coverage","dependencies":[{"issue_id":"claude-memory-765","depends_on_id":"claude-memory-rs8","type":"blocks","created_at":"2025-12-27T19:40:30.249243Z","created_by":"daemon","metadata":"{}"}]}
{"id":"claude-memory-765.1","title":"Validate Phase 2: extraction serves benchmark questions","description":"Validation gate for Phase 2: Does extraction actually support the 5 benchmark questions?\n\nThis is the explicit pause to check purpose-correctness before closing 765 and moving to Phase 3.","design":"## Validation Test\n\nAfter cn2 evaluation completes, verify winning extraction approach:\n\n1. How can we improve /open /close ritual?\n2. What were the big builds and learnings recently?\n3. Top 5 TIL blog post candidates?\n4. Claude.ai vs Claude Code interaction differences?\n5. Top skills used + improvement patterns?\n\n## Pass Criteria\n\n- At least 3/5 questions answerable with reasonable completeness\n- Data retrieval is feasible (queryable, not buried)\n- No major entity categories missing\n\n## If Fails\n\n- Iterate on prompt/model before closing 765\n- Document what's missing\n- Adjust approach\n\n## Dependency\n\nThis blocks closing 765 (Phase 2) and unblocks jag (Phase 3).","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-28T16:58:36.234123Z","updated_at":"2025-12-28T22:16:52.246521Z","closed_at":"2025-12-28T22:16:52.246521Z","close_reason":"Validated during cn2 evaluation. Hybrid prompt answers Q1-Q3. Q4-Q5 need cross-session aggregation (Phase 3). See docs/haiku_downgrade_test.md and prompts/hybrid.md for details.","dependencies":[{"issue_id":"claude-memory-765.1","depends_on_id":"claude-memory-765","type":"parent-child","created_at":"2025-12-28T16:58:36.234583Z","created_by":"daemon","metadata":"{}"},{"issue_id":"claude-memory-765.1","depends_on_id":"claude-memory-cn2.6","type":"blocks","created_at":"2025-12-28T16:58:46.474135Z","created_by":"daemon","metadata":"{}"}]}
{"id":"claude-memory-830","title":"Implement mem recent command","description":"Show recent activity, optionally scoped to current project. Essential for 'what happened lately' orientation at session start.","design":"## Interface\nmem recent [--days N] [--all] [--type TYPE]\n\n## Behavior\n- Default: current project if in git repo, else all sources\n- --all: override, show everything regardless of location\n- --days N: lookback period (default 7)\n- --type TYPE: filter by source type\n\n## Output\nGroup by day, match search output format:\n```\nRecent activity (last 7 days):\n\nYesterday:\n  [claude_code] Fixed extraction bug...\n  [handoff] claude-memory handoff...\n\nDec 27:\n  [claude_code] Phase 1 complete...\n```\n\n## Implementation\n1. Detect if in git repo (git rev-parse --show-toplevel)\n2. Convert repo path to project_path format (/ → -)\n3. Query sources by updated_at, optionally filter by project_path LIKE\n4. Group results by date, format like search output","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-29T14:37:08.729595Z","updated_at":"2025-12-29T15:14:14.647952Z","closed_at":"2025-12-29T15:14:14.647952Z","close_reason":"Implemented mem recent with --days, --all, --type flags. Auto-detects current project from git repo. Groups output by day. Includes matching handoffs for project context.","dependencies":[{"issue_id":"claude-memory-830","depends_on_id":"claude-memory-4oe","type":"parent-child","created_at":"2025-12-29T14:37:19.169466Z","created_by":"daemon","metadata":"{}"}]}
{"id":"claude-memory-991","title":"Test session-end hook fix end-to-end","description":"Verify the transcript_path fix prevents extraction race condition","design":"## Context\nFixed dz4 by reading transcript_path from stdin JSON instead of guessing with ls -t.\n\n## Test Plan\n1. Run a session with /close\n2. Check extraction log for correct session ID\n3. Verify extraction content matches actual session (not a prior one)\n\n## Acceptance\n- [ ] Extraction log shows transcript_path was used (not fallback)\n- [ ] Extracted content matches session that just closed","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-31T15:42:59.16134Z","updated_at":"2025-12-31T18:11:43.792863Z","closed_at":"2025-12-31T18:11:43.792863Z","close_reason":"Verified: 10 recent logs all show matching session IDs, extraction content matches actual session work (tested 30dd12e2), no failed extractions. transcript_path fix working correctly."}
{"id":"claude-memory-aq3","title":"Add progressive disclosure to drill command","description":"The 'thumbnail vs full document' problem: search finds a relevant conversation via its summary, but drill --full dumps the entire conversation — potentially 100k+ tokens. Unlike skills (SKILL.md → references/*.md), conversations have no progressive disclosure.\n\nCurrent crude mitigation: 2000-char truncation per message. This is arbitrary damage, not intelligent selection.\n\nThe carrot metaphor: pulling up a small carrot top and finding a ginormous carrot underneath.","design":"## Options considered\n\n1. **Pre-chunk at index time** — Each chunk gets own DB row. But FTS5 returns fragments (\"chunk 47 matched\") — disorienting.\n\n2. **Hierarchical summaries** — Multiple levels (one-liner → paragraph → detailed → full). Expensive (LLM per level).\n\n3. **On-demand structure at drill time** — Show \"table of contents\" first, user picks sections.\n\n4. **Pagination** — `drill --full --page 2` — simple but blind.\n\n## Recommended approach\n\nLeverage conversation's natural structure (turns):\n\n```\ndrill abc123           → metadata + summary (current)\ndrill abc123 --outline → message index with snippets  \ndrill abc123 --turn 15 → specific turn in full\n```\n\nSearch finds conversation → outline shows where interesting part is → pull just that section.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-28T10:16:48.363898Z","updated_at":"2025-12-29T09:31:37.195524Z","closed_at":"2025-12-29T09:31:37.195524Z","close_reason":"Implemented --outline and --turn flags for progressive disclosure. Flow: search → outline (numbered turns with snippets) → turn N (full content). Tool use messages show raw JSON but core functionality works.","dependencies":[{"issue_id":"claude-memory-aq3","depends_on_id":"claude-memory-4f9","type":"parent-child","created_at":"2025-12-28T10:16:53.914838Z","created_by":"daemon","metadata":"{}"},{"issue_id":"claude-memory-aq3","depends_on_id":"claude-memory-dkt","type":"related","created_at":"2025-12-28T23:07:16.014867Z","created_by":"daemon","metadata":"{}"}]}
{"id":"claude-memory-as2","title":"Improve mem recent for daily recap use case","description":"mem recent failed to give complete picture of yesterday's work. User had to prompt for missing sessions. Need better defaults and grouping.","design":"## Problems Identified\n1. `--all` not default — missed cross-project work\n2. Flat chronological list — no grouping by project\n3. No session counts — couldn't see \"infra-openwrt had 4 sessions\"\n4. Calendar date boundaries — late night work (00:12) showed as \"today\" not \"last night\"\n\n## Approach\n1. Add `--group-by project` option (default for multi-project view)\n2. Show session counts per project in grouped view\n3. Consider natural day boundaries (configurable? 4am default?)\n4. Better title extraction — many showing \"(untitled)\"\n\n## Acceptance Criteria\n- [ ] `mem recent --all` groups by project with counts\n- [ ] Output shows \"infra-openwrt (4 sessions)\" style summary\n- [ ] Can drill into project to see individual sessions\n- [ ] Untitled sessions show first user message snippet instead","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-31T11:49:20.148858Z","updated_at":"2025-12-31T11:52:29.9548Z","closed_at":"2025-12-31T11:52:29.9548Z","close_reason":"Implemented --by-project grouping with session counts, extraction summary fallback for untitled sessions. Fixed def list shadowing Python builtin."}
{"id":"claude-memory-axq","title":"Field Report: Recent sessions not searchable, fell back to grep","description":"Session from 40 mins ago wasn't findable via mem search. Had to grep raw JSONL in ~/.claude/projects/ instead.","design":"## Context\nUser asked me to find a previous discussion about \"exoskeleton\" from a session that ended ~40 minutes earlier. The handoff referenced session ID 4d51318d-98d5-458e-86a9-b989769b27ad.\n\n## Observation\n`mem search` returned no results for multiple queries:\n- \"CLAUDE.md structure Philosophy Infrastructure Context sections\" (FTS5 syntax error on the period)\n- \"CLAUDE structure Philosophy sections reorganization\" (no results)\n- \"claude-modus sharing modus operandi\" (no results)\n- \"Deliberate Overrides\" (no results)\n\n`mem recent --all --days 1` showed 10 sessions but the specific session wasn't appearing in search results.\n\n**Workaround:** Grepped the raw session JSONL directly:\n```bash\ngrep -i \"exoskeleton\" ~/.claude/projects/-Users-modha-Repos/4d51318d-*.jsonl\n```\nThis worked and found the content.\n\n## Why This Matters\nThe gap between session-end and searchability creates a blind spot. For /open workflows that resume recent work, the most relevant session (the one that just ended) is often unsearchable. This forces either:\n1. Relying solely on handoff (which may not capture everything)\n2. Manual grep of raw session files (breaks the abstraction)\n\n## Suggestion\nConsider:\n- Documenting the indexing delay in the skill (\"recent sessions may not be indexed yet\")\n- Adding a `mem grep \u003csession-id\u003e` command that searches raw JSONL as fallback\n- Or: index on session close rather than batch scan","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-02T20:56:36.739551Z","updated_at":"2026-01-02T21:03:09.795368Z","closed_at":"2026-01-02T21:03:09.795368Z","close_reason":"Fixed: mem process now syncs extraction content to FTS immediately after hybrid extraction. Sessions are searchable as soon as hook completes (~30-60s). The gap was that extraction builds/learnings weren't synced to FTS until manual sync-fts.","labels":["field-report"]}
{"id":"claude-memory-b1i","title":"Add tool/skill metadata extraction to Claude Code adapter","design":"Store raw facts (tool_calls, files_touched, skills_used, git_commits) at parse time. JSON blob in sources.metadata column. Query-time interpretation for flexibility.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-28T09:24:58.907619Z","updated_at":"2025-12-28T09:36:54.885953Z","closed_at":"2025-12-28T09:36:54.885953Z","close_reason":"Metadata extraction: tool_calls, files_touched, skills_used stored. Schema migrated. 35 tests passing."}
{"id":"claude-memory-bs4","title":"Add session extraction to /close skill","description":"Integrate hybrid extraction into the /close ritual so sessions get indexed automatically. Currently extraction runs via a separate hook or manual backfill — embedding it in /close ensures every session gets processed while the context is fresh.","design":"## Goal\nTrigger extraction at the START of /close so it runs in parallel with wrap-up dialogue.\n\n## Approach\n1. Modify session-closing skill to call extraction early in the sequence\n2. Use Claude Code session (via Max subscription) instead of pay-as-you-go API\n3. The \"last bit\" of conversation goes into .handoff anyway — structured, not raw\n\n## Open question: Handoff → Session linking\nCurrently handoffs are named `{project}-{date}-{time}.md` with no session UUID.\nIf we could embed session ID in handoff (filename or content), retrieval could trace back to source conversation.\n\nNeed to check: Is session UUID knowable during /close?\n\n## Constraints\n- Extraction must not block the /close flow (fire-and-forget or background)\n- Should fail gracefully if extraction service unavailable","acceptance_criteria":"- [ ] Extraction fires at start of /close sequence\n- [ ] Runs via Claude Code session (Max) not pay-as-you-go API\n- [ ] Does not block /close completion\n- [ ] Graceful failure if extraction unavailable\n- [ ] Optional: Handoff includes session UUID for traceability","status":"tombstone","priority":1,"issue_type":"feature","created_at":"2025-12-29T09:19:30.064087Z","updated_at":"2025-12-29T09:21:17.235864Z","deleted_at":"2025-12-29T09:21:17.235864Z","deleted_by":"daemon","delete_reason":"delete","original_type":"feature"}
{"id":"claude-memory-bwy","title":"Hook stdout not indexed — raw file inspection needed for some research","description":"When researching patterns in /open flows (git status noise), mem search found discussions *about* the topic but not the raw hook output. Extractions summarize sessions; they don't index stdin/stdout from hooks. For this kind of research, raw file inspection works better than mem search.","design":"## Observation\n\nSearched for: 'session start git status uncommitted', 'GIT_DIRTY', etc.\nFound: Discussions about git distraction, not actual git status output from sessions.\n\n## Why\n\n- Extractions are LLM summaries of session transcripts\n- Hook stdout (open-context.sh output) appears in transcript but gets summarized away\n- Specific patterns like file lists aren't preserved\n\n## Implications\n\n- mem search: good for 'what did we learn about X' or 'have we done Y before'\n- mem search: weak for 'show me examples of X happening'\n- Raw file inspection: needed for pattern analysis on session artifacts\n\n## Potential fixes (someday)\n\n1. Index hook output separately (new source type)\n2. Preserve more detail in extractions\n3. Accept limitation — different tools for different queries","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-03T16:20:54.428111Z","updated_at":"2026-01-03T16:21:04.128358Z","labels":["field-report"]}
{"id":"claude-memory-cm3","title":"memory: field report from beads prioritization session","description":"Usage feedback from real search workflow: finding context for 7 P1 beads across 4 projects","design":"## Session Context\nTask: Find context about P1 beads using memory search\nWorkflow: 6 searches, 2 drills → rich context for 7 beads\n\n## What Worked Well\n- Progressive disclosure pattern worked naturally (search → triage → drill)\n- Extraction summaries were genuinely sufficient; only drilled twice\n- Arc/Builds/Learnings structure provided excellent decision support\n- \"Why it matters\" annotations on learnings particularly useful\n- Cross-session synthesis worked (traced skill-beads items to pain points in earlier sessions)\n\n## Friction Points\n\n### Query sensitivity (enhancement candidate)\n- \"diagramming fluency\" → no results\n- \"diagramming practice\" → no results\n- \"iterative diagram\" → 5 good hits\nContent existed but exact phrase matching missed semantic equivalents.\n→ Consider: fuzzy/semantic search, or synonym expansion via glossary\n\n### No compound queries\nCouldn't search \"skill-beads AND alignment\" — had to run separate searches and mentally correlate.\n→ Consider: basic boolean operators in FTS5 query\n\n### Source type discovery\nWasn't obvious which --type values available without checking docs.\n→ Consider: `mem search --help` showing available types, or `mem types` command\n\n## Observations\n- Extractions eliminated most drilling — \"unfolding label\" concept worked in practice\n- Open threads section didn't surface naturally in workflow (might need prompting)\n\n## Suggestions\n1. Fuzzy/semantic search to reduce query sensitivity\n2. \"Related sessions\" linking — if sessions reference same beads/files, surface connection\n3. `mem search --explain` — show why results matched (which field, which terms)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T23:43:59.266338Z","updated_at":"2025-12-31T14:19:56.650918Z","closed_at":"2025-12-31T14:19:56.650918Z","close_reason":"Field report documented in bead design field — query sensitivity, compound queries, source type discovery friction captured. Feeds knz pattern tracking.","dependencies":[{"issue_id":"claude-memory-cm3","depends_on_id":"claude-memory-knz","type":"parent-child","created_at":"2025-12-30T23:44:08.864108Z","created_by":"daemon","metadata":"{}"}]}
{"id":"claude-memory-cn2","title":"Evaluate extraction quality: prompt × model matrix","description":"Test extraction approaches against 5 real-world questions:\n1. How can we improve /open /close ritual?\n2. What were the big builds and learnings recently?\n3. Top 5 TIL blog post candidates (Claude's picks)\n4. Claude.ai vs Claude Code interaction differences\n5. Top skills used + improvement patterns\n\nThese questions require more than entity extraction — they need events, outcomes, patterns, narrative.","design":"## Approach: Sonnet-first prompt iteration\n\n1. Pick 10-20 diverse sessions (coding, planning, research, voice)\n2. Design 3 prompt variants:\n   - A: Current (entities only)\n   - B: Entities + outcomes/decisions/learnings\n   - C: Narrative digest (events, breakthroughs, friction)\n3. Run all variants with Sonnet\n4. For each corpus, attempt to answer the 5 questions\n5. Score: which variant best supports the questions?\n6. Downgrade test: run winning prompt with Haiku, compare quality loss\n\n## Prompt variants to test\n\n**Variant A (current):** Entity extraction only\n- People, Products, Projects, Organizations, Concepts\n- Canonical matching, confidence scoring\n\n**Variant B (entities + outcomes):** Add structured fields:\n- Key decisions made\n- Things built/created\n- Learnings/discoveries\n- Friction points / what was hard\n\n**Variant C (narrative digest):** Event-focused:\n- What happened (narrative summary)\n- Breakthrough moments\n- Patterns observed\n- Questions raised\n\n## Reference prompts\n\n- Current: src/mem/llm.py EXTRACTION_PROMPT\n- Old battle-tested: ~/Repos/claude-memory-feature-test/prompts/subagent_processing_template.md\n\n## Storage for variants\n\nTag extractions by variant:\n- Add extraction_variant column to source_entities\n- Or separate tables per variant\n- Need to query each corpus separately for evaluation\n\n## Evaluation rubric (per question)\n\nFor each of the 5 questions:\n- Can the question be answered from this corpus? (Y/N)\n- Completeness: 1-5 (how much of the answer is supported?)\n- Accuracy: 1-5 (are the extracted facts correct?)\n- Retrieval ease: 1-5 (how hard to find the relevant data?)","acceptance_criteria":"- [ ] 10-20 diverse sessions selected for testing\n- [ ] 3 prompt variants defined and implemented\n- [ ] All variants run with Sonnet on test corpus\n- [ ] Each of 5 questions attempted with each corpus\n- [ ] Evaluation scores documented\n- [ ] Winning prompt identified\n- [ ] Haiku downgrade test completed\n- [ ] Recommendation documented (prompt + model choice)","notes":"EVALUATION COMPLETE (2025-12-28):\n\n## Prompt Testing\n- Variant A (entities only): Insufficient - can't answer outcome questions\n- Variant B (entities + outcomes): Good structured lists, aggregation-friendly\n- Variant C (narrative digest): Good \"why it matters\", captures story\n- **Hybrid B+C: WINNER** - one prompt captures everything\n\n## Model Testing (cn2.7)\n- Tested Haiku vs Sonnet on 3 sessions (3k, 132k, 19k chars)\n- Haiku captures only 60-65% of learnings/builds\n- why_it_matters averages 35-50% shorter with Haiku\n- Schema adherence issues with Haiku\n- **RECOMMENDATION: Use Sonnet** - quality loss unacceptable for memory system\n\n## Key Files\n- Hybrid prompt: prompts/hybrid.md\n- Haiku test results: docs/haiku_downgrade_test.md\n- Test script: scripts/haiku_test.py\n\n## Benchmark Questions Status\n- Q1 (/open /close improvement): Answerable via patterns, friction\n- Q2 (builds/learnings): Answerable ✓\n- Q3 (TIL blog posts): Answerable via learnings.why_it_matters ✓\n- Q4 (Claude.ai vs Code): Needs cross-session aggregation\n- Q5 (skill usage patterns): Needs metadata + patterns\n\n## DONE - Ready to close epic\nAll acceptance criteria met. Hybrid prompt + Sonnet is the recommendation.","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-28T16:35:06.502274Z","updated_at":"2025-12-28T22:08:12.9997Z","closed_at":"2025-12-28T22:08:12.9997Z","close_reason":"Extraction quality evaluation complete.\n\nWINNER: Hybrid prompt (B+C combination) with Sonnet.\n\nKey deliverables:\n- prompts/hybrid.md: Final prompt design\n- docs/haiku_downgrade_test.md: Model comparison results\n- scripts/haiku_test.py: Test harness\n- test_results/: JSON outputs from all tests\n\nModel decision: Sonnet (not Haiku)\n- Haiku loses 40% of learnings and builds\n- why_it_matters quality significantly worse\n- Cost difference acceptable ($0.01-0.10/session)\n\nBenchmark questions answerable:\n- Q2 (builds/learnings): Yes\n- Q3 (TIL blog posts): Yes via why_it_matters\n- Q1, Q4, Q5: Need cross-session aggregation (Phase 3)"}
{"id":"claude-memory-cn2.1","title":"Select 10-20 diverse test sessions","description":"Pick sessions covering: coding, planning, research, voice, different projects. Need variety to test prompt robustness.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-28T16:40:43.781647Z","updated_at":"2025-12-28T16:43:19.957966Z","closed_at":"2025-12-28T16:43:19.957966Z","close_reason":"17 diverse sessions selected, saved to test_corpus.yaml","dependencies":[{"issue_id":"claude-memory-cn2.1","depends_on_id":"claude-memory-cn2","type":"parent-child","created_at":"2025-12-28T16:40:43.782068Z","created_by":"daemon","metadata":"{}"}]}
{"id":"claude-memory-cn2.2","title":"Design prompt variant B (entities + outcomes)","description":"Extend current prompt to also extract: key decisions, things built, learnings, friction points.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-28T16:40:43.815819Z","updated_at":"2025-12-28T16:44:02.823713Z","closed_at":"2025-12-28T16:44:02.823713Z","close_reason":"Prompt designed and saved to prompts/variant_b_entities_outcomes.md. Adds outcomes (decisions, builds, learnings, friction) to entity extraction.","dependencies":[{"issue_id":"claude-memory-cn2.2","depends_on_id":"claude-memory-cn2","type":"parent-child","created_at":"2025-12-28T16:40:43.816231Z","created_by":"daemon","metadata":"{}"}]}
{"id":"claude-memory-cn2.3","title":"Design prompt variant C (narrative digest)","description":"Event-focused extraction: what happened, breakthroughs, patterns, questions raised.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-28T16:40:43.849575Z","updated_at":"2025-12-28T16:45:20.876003Z","closed_at":"2025-12-28T16:45:20.876003Z","close_reason":"Prompt designed and saved to prompts/variant_c_narrative_digest.md. Narrative/event focused: arc, breakthroughs, friction, patterns, open threads.","dependencies":[{"issue_id":"claude-memory-cn2.3","depends_on_id":"claude-memory-cn2","type":"parent-child","created_at":"2025-12-28T16:40:43.850005Z","created_by":"daemon","metadata":"{}"}]}
{"id":"claude-memory-cn2.4","title":"Build multi-variant extraction runner","description":"CLI support for --prompt-variant and --model flags. Store results tagged by variant for comparison.","design":"## Original Scope (obsolete)\nMulti-variant runner with --prompt-variant and --model flags\n\n## Revised Scope\nSingle hybrid prompt + chunking logic:\n1. If session \u003c 150k chars → single extraction\n2. If session ≥ 150k chars → chunk (140k with 5k overlap) → extract each → merge\n\n## Implementation\n- Add chunking logic to mem extract command\n- Use hybrid prompt (prompts/hybrid.md)\n- Merge step deduplicates and synthesizes\n\n## Files\n- src/mem/extraction.py - add chunk_session() and merge_extractions()\n- prompts/hybrid.md - the winning prompt","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T16:40:43.883718Z","updated_at":"2025-12-28T22:28:23.462301Z","closed_at":"2025-12-28T22:28:23.462301Z","close_reason":"Obsolete. Variant evaluation complete: hybrid prompt won. haiku_test.py provides comparison tooling. No need for multi-variant CLI flags.","dependencies":[{"issue_id":"claude-memory-cn2.4","depends_on_id":"claude-memory-cn2","type":"parent-child","created_at":"2025-12-28T16:40:43.884096Z","created_by":"daemon","metadata":"{}"},{"issue_id":"claude-memory-cn2.4","depends_on_id":"claude-memory-q6f","type":"blocks","created_at":"2025-12-28T21:35:01.331128Z","created_by":"daemon","metadata":"{}"}]}
{"id":"claude-memory-cn2.5","title":"Run Sonnet matrix on test corpus","description":"Run all 3 prompt variants with Sonnet on the selected sessions.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T16:40:43.918193Z","updated_at":"2025-12-28T21:34:12.300787Z","closed_at":"2025-12-28T21:34:12.300787Z","close_reason":"Completed manually: tested A, B, C variants on 10+ sessions, discovered hybrid approach","dependencies":[{"issue_id":"claude-memory-cn2.5","depends_on_id":"claude-memory-cn2","type":"parent-child","created_at":"2025-12-28T16:40:43.918622Z","created_by":"daemon","metadata":"{}"},{"issue_id":"claude-memory-cn2.5","depends_on_id":"claude-memory-cn2.1","type":"blocks","created_at":"2025-12-28T16:40:55.282974Z","created_by":"daemon","metadata":"{}"},{"issue_id":"claude-memory-cn2.5","depends_on_id":"claude-memory-cn2.2","type":"blocks","created_at":"2025-12-28T16:40:55.305653Z","created_by":"daemon","metadata":"{}"},{"issue_id":"claude-memory-cn2.5","depends_on_id":"claude-memory-cn2.3","type":"blocks","created_at":"2025-12-28T16:40:55.32914Z","created_by":"daemon","metadata":"{}"},{"issue_id":"claude-memory-cn2.5","depends_on_id":"claude-memory-cn2.4","type":"blocks","created_at":"2025-12-28T16:40:55.351621Z","created_by":"daemon","metadata":"{}"},{"issue_id":"claude-memory-cn2.5","depends_on_id":"claude-memory-cn2.8","type":"blocks","created_at":"2025-12-28T16:48:35.073981Z","created_by":"daemon","metadata":"{}"}]}
{"id":"claude-memory-cn2.6","title":"Evaluate variants against 5 questions","description":"For each variant corpus, attempt to answer the 5 benchmark questions. Score completeness, accuracy, retrieval ease.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T16:40:43.952868Z","updated_at":"2025-12-28T21:34:12.334887Z","closed_at":"2025-12-28T21:34:12.334887Z","close_reason":"Completed: evaluated against Q2 (builds/learnings) and Q3 (TIL posts), both answerable with hybrid prompt","dependencies":[{"issue_id":"claude-memory-cn2.6","depends_on_id":"claude-memory-cn2","type":"parent-child","created_at":"2025-12-28T16:40:43.953254Z","created_by":"daemon","metadata":"{}"},{"issue_id":"claude-memory-cn2.6","depends_on_id":"claude-memory-cn2.5","type":"blocks","created_at":"2025-12-28T16:40:55.373569Z","created_by":"daemon","metadata":"{}"}]}
{"id":"claude-memory-cn2.7","title":"Haiku downgrade test","description":"Run winning prompt with Haiku. Compare quality loss to determine cost/quality tradeoff.","notes":"FIRST TASK FOR NEXT SESSION\n\nTest hybrid prompt with Haiku instead of Sonnet:\n- Same prompt, cheaper model\n- Compare quality on 2-3 sessions\n- If quality holds: significant cost savings\n- If quality drops: document what's lost\n\nTest sessions to use:\n- One small (3k chars) - Conceptual Charts review\n- One medium (175k chars) - Close session skill  \n- One large with chunking (311k chars) - Slides migration\n\nSuccess criteria:\n- Learnings still have meaningful \"why_it_matters\"\n- Arc captures key turns\n- No major hallucinations in builds","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-28T16:40:43.98785Z","updated_at":"2025-12-28T22:07:20.359013Z","closed_at":"2025-12-28T22:07:20.359013Z","close_reason":"Tested hybrid prompt with Haiku vs Sonnet on 3 sessions.\n\nRESULTS:\n- Haiku captures only 60-65% of learnings/builds\n- why_it_matters averages 35-50% shorter\n- Schema adherence issues (used wrong field names)\n- Insights are surface-level, missing nuance\n\nRECOMMENDATION: Use Sonnet.\nCost difference is ~10x but absolute cost is low ($0.01-0.10/session).\nQuality loss with Haiku undermines the memory system's core value proposition.\n\nDocumented in docs/haiku_downgrade_test.md","dependencies":[{"issue_id":"claude-memory-cn2.7","depends_on_id":"claude-memory-cn2","type":"parent-child","created_at":"2025-12-28T16:40:43.988253Z","created_by":"daemon","metadata":"{}"},{"issue_id":"claude-memory-cn2.7","depends_on_id":"claude-memory-cn2.6","type":"blocks","created_at":"2025-12-28T16:40:55.395704Z","created_by":"daemon","metadata":"{}"}]}
{"id":"claude-memory-cn2.8","title":"Add extraction variant storage schema","description":"Need to store which prompt/model produced each extraction so we can compare results across variants.","design":"Options:\nA) Add columns to source_entities: extraction_variant, extraction_model\nB) Separate tables: source_entities_a, source_entities_b, source_entities_c\nC) JSON metadata blob with variant info\n\nRecommend A - simplest, queryable:\nALTER TABLE source_entities ADD COLUMN extraction_variant TEXT;\nALTER TABLE source_entities ADD COLUMN extraction_model TEXT;\n\nThen query: SELECT * FROM source_entities WHERE extraction_variant = 'b' AND extraction_model = 'sonnet'","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-28T16:48:34.983542Z","updated_at":"2025-12-28T21:34:12.365586Z","closed_at":"2025-12-28T21:34:12.365586Z","close_reason":"No longer needed: converged on single hybrid prompt, no variant tagging required","dependencies":[{"issue_id":"claude-memory-cn2.8","depends_on_id":"claude-memory-cn2","type":"parent-child","created_at":"2025-12-28T16:48:34.983931Z","created_by":"daemon","metadata":"{}"}]}
{"id":"claude-memory-dkt","title":"Wire hybrid extraction into pipeline","description":"Phase 2 validated the hybrid extraction prompt (builds, learnings, patterns, etc.) but it's not wired into the actual pipeline. src/mem/llm.py still runs the old entity-only extraction.\n\nThis epic integrates the validated approach:\n1. Add schema for 7 structured fields (summary, arc, builds, learnings, friction, patterns, open_threads)\n2. Wire prompts/hybrid.md into extraction pipeline\n3. Backfill existing 1500+ sessions\n\nThe extraction output serves as \"the label that unfolds\" — decision support for whether to drill into a conversation, not a replacement for the source. Progressive disclosure: scan structured extractions → decide relevance → drill only when needed.","design":"## Architecture\n\nExtraction layer sits between search and source:\n1. Title/search hit — \"there's a conversation here\"\n2. Structured extraction — label unfolds with builds, learnings, patterns\n3. Full source — load conversation when extraction confirms relevance\n\n## Schema additions\n\nNew table `extractions`:\n- source_id (FK)\n- summary, arc TEXT\n- builds, learnings, friction, patterns, open_threads JSONB\n- model_used, extracted_at\n\n## Implementation order\n\n1. Add schema migration\n2. Update llm.py to use hybrid prompt\n3. Update process command to store structured output\n4. Add backfill command for existing sources\n5. Update search/drill to surface extraction fields\n\n## Acceptance criteria\n\n- [ ] Hybrid prompt integrated into extraction pipeline\n- [ ] New sessions get structured extractions on session-end\n- [ ] Existing 1500 sessions backfilled\n- [ ] `mem search` surfaces extraction fields (builds, learnings)\n- [ ] Benchmark questions answerable from extraction layer","notes":"SESSION: 2025-12-28\n\nCOMPLETED:\n- Added extractions table to schema\n- Added extract_hybrid() function using validated hybrid prompt\n- Updated process command to run hybrid extraction\n- Added backfill command for existing sources\n- Updated search to show extraction summaries\n- Updated drill to show full \"unfolding label\"\n- Started full backfill (1403 claude_code sources, running in background via nohup)\n\nKEY INSIGHT:\nExtraction layer is \"the label that unfolds\" — decision support for whether to drill, not replacement for source. Progressive disclosure like SKILL.md references.\n\nBACKFILL STATUS:\nRunning in background: tail -f ~/.claude/memory/backfill.log\nCheck count: sqlite3 ~/.claude/memory/memory.db \"SELECT COUNT(*) FROM extractions\"\nMachine must stay awake (use caffeinate if needed)\n\nNEXT SESSION:\n- Verify backfill completed\n- Test benchmark questions against extraction data\n- Close epic if backfill successful","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-28T23:07:08.422384Z","updated_at":"2025-12-29T10:23:23.978481Z","closed_at":"2025-12-29T10:23:23.978481Z","close_reason":"Complete: hybrid extraction wired into pipeline, 1297 sessions backfilled, FTS indexing fixed. Search now works across all extraction summaries."}
{"id":"claude-memory-dz4","title":"memory: extraction agent extracted wrong session content","description":"Background extraction agent produced content from a prior session instead of the current one","design":"## Session\nSource ID: claude_code:5ef2f75d-c165-4d13-839c-efb2ee3f1237\n\n## Expected (This Session)\n- Beads prioritization triage across ~/Repos\n- Skeleton cleanup (chucking 5 beads)\n- Signboard prefix rename (infra-signboard-claude- → sb-)\n- Todoist MCP re-setup\n- Memory skill test (6 searches, 2 drills for P1 context)\n- Filed field report as claude-memory-cm3\n\n## Actual (What Was Extracted)\n- \"Created a new memory skill\"\n- \"Pivoted from Phase 3 Entity Resolution to skill creation\"\n- \"Resolved naming confusion between grounding and session-grounding\"\n- \"Folding grounding skill into memory skill\"\n\nThis describes a PRIOR session where the memory skill was built — not the current one.\n\n## Hypotheses\n1. **Timing issue** — Session JSONL not fully flushed when extract-prompt read it\n2. **Source ID collision** — ID mapped to wrong file\n3. **Caching** — extract-prompt returned stale content\n4. **Agent confusion** — Generated plausible but wrong extraction\n\n## Reproduction Context\n- Extraction spawned ~30 seconds into /close ritual\n- Session still active (user still interacting)\n- Agent ran in background while main session continued\n\n## Investigation\nCheck if extract-prompt reads from file still being written, or race condition between Claude Code flushing JSONL and extraction pipeline reading it.","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-30T23:55:43.376029Z","updated_at":"2025-12-31T15:12:40.154576Z","closed_at":"2025-12-31T15:12:40.154576Z","close_reason":"Root cause: hook used ls -t to guess session file (race condition). Fix: read transcript_path from stdin JSON input. Fallback to ls -t kept for defensive coding."}
{"id":"claude-memory-esy","title":"mem digest command for reviewing auto-mappings","description":"Periodic review of auto-resolved entity mappings. Show what got auto-mapped so user can spot errors.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-31T18:25:54.136675Z","updated_at":"2025-12-31T18:25:54.136675Z","dependencies":[{"issue_id":"claude-memory-esy","depends_on_id":"claude-memory-q3q","type":"parent-child","created_at":"2025-12-31T18:26:00.816846Z","created_by":"modha","metadata":"{}"}]}
{"id":"claude-memory-g56","title":"Update mem commands for new handoff folder structure","description":"ssm-2fd changed handoff storage from flat files to folder structure. mem recent and other commands that read handoffs need updating to find ~/.claude/handoffs/-{path}/*.md instead of ~/.claude/handoffs/*.md","design":"Update handoff discovery in mem commands to scan subdirectories matching the encoded path pattern.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-29T23:01:15.638324Z","updated_at":"2025-12-30T09:09:58.541182Z","closed_at":"2025-12-30T09:09:58.541182Z","close_reason":"Added --source filter to mem scan command. Instinctive CLI ergonomics - Claude naturally reached for this option."}
{"id":"claude-memory-hsx","title":"Update handoffs adapter for new folder structure","description":"Support handoffs organized by project_path folder (matching Claude Code session structure).","design":"## Context\n\nDepends on ssm-2fd in skill-session-management which changes /close to write handoffs to:\n```\n~/.claude/handoffs/{project_path}/{timestamp}.md\n```\n\nThis bead updates the adapter to read from that structure.\n\n## Changes Required\n\n### 1. Update discover_handoffs() glob pattern\n\nFile: src/mem/adapters/handoffs.py\n\n```python\n# OLD\nfor file in path.glob('*.md'):\n\n# NEW - recursive glob for subdirectories\nfor file in path.glob('**/*.md'):\n```\n\n### 2. Extract project_path from folder name\n\n```python\ndef from_file(cls, path: Path) -\u003e 'HandoffSource':\n    # ...existing parsing...\n    \n    # NEW: Extract project_path from parent folder\n    # path = ~/.claude/handoffs/-Users-modha-Repos-foo/2025-12-29.md\n    parent = path.parent.name\n    if parent != 'handoffs':\n        # Subfolder = project_path\n        project_path = parent\n    else:\n        # Flat file (legacy) - no project_path\n        project_path = None\n    \n    return cls(\n        # ...existing fields...\n        project_path=project_path,  # NEW\n    )\n```\n\n### 3. Add project_path field to HandoffSource dataclass\n\n```python\n@dataclass\nclass HandoffSource:\n    source_id: str\n    title: str\n    date: datetime\n    path: Path\n    content: str\n    project_path: str | None = None  # NEW\n```\n\n### 4. Store project_path in database\n\nUpdate scan command to pass project_path:\n```python\ndb.upsert_source(\n    source_id=source.source_id,\n    source_type='handoff',\n    title=source.title,\n    path=str(source.path),\n    created_at=source.date,\n    updated_at=source.date,\n    project_path=source.project_path,  # NEW\n)\n```\n\n### 5. Simplify mem recent query\n\nRemove fuzzy title matching fallback:\n```python\n# OLD\nsql += \" AND (s.project_path LIKE ? OR (s.source_type = 'handoff' AND (s.title LIKE ? OR s.id LIKE ?)))\"\n\n# NEW\nsql += \" AND s.project_path LIKE ?\"\n```\n\n## Backwards Compatibility\n\n- Flat files in ~/.claude/handoffs/*.md still discovered\n- They just won't have project_path populated\n- Over time, new handoffs will all have project_path\n\n## Acceptance Criteria\n\n- [ ] Adapter globs **/*.md (recursive)\n- [ ] project_path extracted from parent folder when present\n- [ ] project_path stored in database for handoff sources\n- [ ] `mem recent` finds handoffs by project_path (no fuzzy matching)\n- [ ] Legacy flat handoffs still indexed (project_path = NULL)\n\n## Testing\n\n```bash\n# Create test handoff in new structure\nmkdir -p ~/.claude/handoffs/-Users-modha-Repos-test-project\necho \"# Test handoff\" \u003e ~/.claude/handoffs/-Users-modha-Repos-test-project/2025-12-29-test.md\n\n# Rescan and verify\nuv run mem scan\nsqlite3 ~/.claude/memory/memory.db \"SELECT id, project_path FROM sources WHERE source_type='handoff' AND project_path IS NOT NULL\"\n```","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-29T15:27:57.863956Z","updated_at":"2025-12-30T09:09:57.520145Z","closed_at":"2025-12-30T09:09:57.520145Z","close_reason":"Adapter updated: recursive glob for subdirectories, decode_parent_dir() extracts project info from parent dir name, uses Path.home() for portability. Tests added.","dependencies":[{"issue_id":"claude-memory-hsx","depends_on_id":"external:skill-session-management:ssm-2fd","type":"blocks","created_at":"2025-12-29T15:28:13.179643Z","created_by":"daemon","metadata":"{}"}]}
{"id":"claude-memory-i9b","title":"Handle OR queries in FTS5 search","description":"User testing revealed: `mem search \"mid session\" OR \"replan\"` fails.\n\nFTS5 syntax requires unquoted OR between terms, but shell quoting makes this awkward.\n\nOptions:\n1. Document proper syntax: mem search 'mid session OR replan'\n2. Preprocess: detect OR in query and restructure\n3. Support multiple --query flags that get OR'd together","design":"Option 2 (preprocess) is probably cleanest:\n- Detect pattern: \"term1\" OR \"term2\"\n- Convert to FTS5: \"term1\" OR \"term2\" (strip outer quotes)\n\nOr simpler: just document that OR works without outer quotes.","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-28T10:29:25.364976Z","updated_at":"2025-12-28T10:34:39.235758Z","closed_at":"2025-12-28T10:34:39.235758Z","close_reason":"Changed query arg to nargs=-1, joins multiple args. Now 'mem search term1 OR term2' works. Added help text with examples."}
{"id":"claude-memory-j5q","title":"Index extraction summaries in FTS for search","description":"Extraction summaries are stored in extractions table but FTS index only contains original scan summaries (often just titles). This means search can't find content from the rich hybrid extractions — defeating the purpose of the extraction pipeline.","design":"## The problem\n- `summaries` table: thin data from initial scan (title, first message snippet)\n- `extractions` table: rich summaries, builds, learnings from LLM\n- `summaries_fts`: FTS5 index built from summaries table only\n\nSearch queries hit the FTS index → miss all extraction content.\n\n## Fix options\n1. **Update FTS on extraction** — When extract runs, update summaries.summary_text with extraction summary, rebuild FTS entry\n2. **Separate extraction FTS** — New FTS table for extractions, search both\n3. **Composite view** — COALESCE extraction summary over original summary in FTS\n\nOption 1 seems cleanest — one source of truth, extraction replaces thin summary.","acceptance_criteria":"- [ ] Search finds content from extraction summaries\n- [ ] Existing \"playground\" search finds the session\n- [ ] Backfill updates FTS for already-extracted sources","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-29T09:43:36.604405Z","updated_at":"2025-12-29T09:51:17.887871Z","closed_at":"2025-12-29T09:51:17.887871Z","close_reason":"Fixed: extraction summaries now update summaries table (triggers FTS sync). Added sync-fts command for backfill. Tested: 'playground repos' now finds the session."}
{"id":"claude-memory-jag","title":"Implement Phase 3: Full Source Coverage","description":"Claude Code adapter (needs LLM summary), local markdown, mem process command. See spec.md ## Implementation Order \u003e Phase 3. Blocked by Phase 2.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-27T19:40:21.390144Z","updated_at":"2025-12-28T23:06:39.911909Z","closed_at":"2025-12-28T23:06:39.911909Z","close_reason":"Reframed after critical review (2025-12-28).\n\nOriginal scope (\"Full Source Coverage\") assumed:\n- Claude Code needed LLM summaries\n- Entity extraction was the core value\n- Google/Desktop sources were priorities\n\nLearnings from Phase 2 validation changed this:\n- Hybrid extraction (builds, learnings, patterns) is what answers benchmark questions\n- The validated hybrid prompt isn't wired into the pipeline — that's the actual gap\n- Google/Desktop don't serve the benchmark questions\n\nReplaced by new epic: \"Hybrid Integration\" — wire the validated prompt, add schema for structured output, backfill existing sessions.","dependencies":[{"issue_id":"claude-memory-jag","depends_on_id":"claude-memory-765","type":"blocks","created_at":"2025-12-27T19:40:30.283414Z","created_by":"daemon","metadata":"{}"},{"issue_id":"claude-memory-jag","depends_on_id":"claude-memory-765.1","type":"blocks","created_at":"2025-12-28T16:58:46.496413Z","created_by":"daemon","metadata":"{}"}]}
{"id":"claude-memory-knz","title":"Track memory skill refinements from usage feedback","description":"Collect feedback from Claudes using the memory skill and refine based on patterns","design":"## Purpose\nTrack issues filed by Claudes using the memory skill. Consolidate patterns and improve.\n\n## Workflow\n1. Watch for beads with \"memory:\" prefix\n2. After 10-20 issues, consolidate patterns\n3. Update TROUBLESHOOTING.md with common issues\n4. Improve SKILL.md triggers if discovery failing\n5. Consider GitHub issue migration when patterns stabilize\n\n## Acceptance Criteria\n- [ ] 10+ feedback beads collected\n- [ ] TROUBLESHOOTING.md updated with new patterns\n- [ ] Skill description refined if discovery issues found\n- [ ] Migration path to GitHub issues documented if ready","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T22:09:56.116777Z","updated_at":"2025-12-31T15:09:00.747309Z","closed_at":"2025-12-31T15:09:00.747309Z","close_reason":"Convention established: 'memory:' prefix for feedback beads. cm3 serves as field report example. Templates exist for bugs in SKILL.md. No additional templating needed."}
{"id":"claude-memory-ksz","title":"Glossary data quality pass","design":"Systematic cleanup of glossary.yaml:\n\n1. Add missing abbreviation aliases (CSP, CTC, GA4 done; audit rest)\n2. Review 147 pending entities — bulk resolve obvious ones (ITV, Claude, OpenWRT)\n3. Graduate auto_mappings to full entities where appropriate\n4. Add common misspellings/variants as aliases\n\nThis is data work, not code work. Could be done incrementally across sessions.\n\nRelated: 4jz (glossary-check command to automate detection)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T18:22:59.276851Z","updated_at":"2025-12-31T12:52:09.942748Z","closed_at":"2025-12-31T12:52:09.942748Z","close_reason":"Resolved 154 entities, rejected 58. Added 11 new glossary entries: anthropic, claude, claude_code, claude_haiku, claude_sonnet, itv, channel_4, sky, github, google_workspace, beads, openwrt, unifi, tailscale."}
{"id":"claude-memory-lm7","title":"Add cloud sessions adapter for Claude Code web sessions","description":"New data source from claude-data-sync: ~/.claude/claude-ai/cache/sessions/*.json. Format very similar to local Claude Code JSONL - same loglines structure with type/message.role/message.content, but JSON array instead of JSONL and includes cwd/gitBranch git context. Session IDs prefixed session_01*.","design":"Extend discover_claude_code() or create parallel adapter. Key differences: (1) JSON not JSONL, (2) loglines[] array, (3) session_01* IDs, (4) cwd/gitBranch context. Can reuse ClaudeCodeSource dataclass with minor tweaks.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-28T09:45:29.491861Z","updated_at":"2025-12-28T09:48:06.875143Z","closed_at":"2025-12-28T09:48:06.875143Z","close_reason":"Cloud sessions adapter complete. 32 sessions indexed with metadata (tool_calls, git_branch). All 35 tests passing."}
{"id":"claude-memory-m1f","title":"Complete claude_code backfill (ba90539)","design":"Background task restarted (b0250f2). ~193 sources remaining. Check with: tail /tmp/claude/-Users-modha-Repos-claude-memory/tasks/b0250f2.output","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-30T10:03:04.08699Z","updated_at":"2025-12-30T10:49:49.975362Z","closed_at":"2025-12-30T10:49:49.975362Z","close_reason":"Backfill complete: 94% claude_code coverage (1573/1668). Some skipped due to short content."}
{"id":"claude-memory-m2k","title":"Test memory skill discovery in fresh session","description":"Verify memory skill triggers correctly on expected phrases","design":"## Test Phrases\nTry each in a fresh session and verify memory skill invokes:\n- \"search memory for X\"\n- \"what did we learn about X\"\n- \"have we done this before\"\n- \"what did we decide about X\"\n- \"I'm lost\"\n- \"where were we\"\n\n## Expected\nMemory skill should invoke and provide search/drill guidance.\n\n## If Fails\nUpdate description field with missing trigger phrases.\n\n## Acceptance\n- [ ] All test phrases trigger skill\n- [ ] Description refined if gaps found","notes":"TESTED: 2025-12-31\nRESULT: Failed to invoke skill\n\nUser asked: \"remind myself the major things I worked on yesterday\"\nExpected: Invoke memory skill\nActual: Manually searched handoffs using Bash/Read tools\n\nROOT CAUSE: Claude had memory system context already loaded (CLAUDE.md, beads skill). \nReached for tools directly rather than recognizing skill trigger.\n\nINSIGHT: Skill invocation competes with direct tool use. When Claude knows HOW to do \nsomething, it may skip the skill even when triggers match. This is a discoverability \nproblem at the harness level, not just description quality.\n\nNEXT: Consider if skill should be invoked automatically by harness based on triggers,\nor if current \"Claude decides\" model is sufficient with better prompting.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T22:37:26.518221Z","updated_at":"2025-12-31T12:22:18.431583Z","closed_at":"2025-12-31T12:22:18.431583Z","close_reason":"Test completed: skill NOT invoked. Claude used direct tools instead. Root cause: skill invocation competes with direct knowledge. Filed insight in notes."}
{"id":"claude-memory-mka","title":"Add tests for local_md adapter","description":"local_md.py adapter has no test coverage. Add tests for title extraction, date parsing, discover_local_md.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-31T17:33:36.22342Z","updated_at":"2025-12-31T17:54:41.13998Z","closed_at":"2025-12-31T17:54:41.13998Z","close_reason":"16 tests covering title extraction, date parsing, mtime tracking, source ID, and discover_local_md function"}
{"id":"claude-memory-mwh","title":"Proposed: File-based search index","description":"Add an FTS5 index for file paths to enable queries like \"what conversations touched server.py?\"\n\nCurrently files_touched is captured in metadata but not indexed for search.","design":"## Problem\n\nExtraction captures `files_touched` in metadata, but there's no way to search by file path.\n\n## Spike Findings (2025-12-31)\n\n**FTS5 handles paths surprisingly well with default tokenizer:**\n\n| Query | Works? | Notes |\n|-------|--------|-------|\n| `server` | ✓ | Finds server.py |\n| `cli` | ✓ | Finds cli.py |\n| `\"claude-memory\"` | ✓ | Quoted hyphenated paths work |\n| `server.py` | ✗ | \".\" is FTS5 operator |\n| `\"server.py\"` | ✓ | Quoting fixes it! |\n| `server AND py` | ✓ | Works but clunky |\n\n**Conclusion:** No custom tokenizer needed. Just auto-quote patterns containing \".\" before FTS5 search.\n\n## Recommended Implementation\n\n1. **Schema** — simple, single-table:\n```sql\nCREATE TABLE file_mentions (\n  id INTEGER PRIMARY KEY,\n  source_id TEXT NOT NULL,\n  file_path TEXT NOT NULL,\n  operation TEXT,  -- 'read', 'edit', 'write'\n  FOREIGN KEY (source_id) REFERENCES sources(id)\n);\n\nCREATE VIRTUAL TABLE files_fts USING fts5(\n  file_path,\n  content='file_mentions',\n  content_rowid='id'\n);\n```\n\n2. **CLI** — auto-quote file patterns:\n```bash\nmem files server.py      # Auto-quoted to \"server.py\"\nmem files cli            # Works as-is\nmem files \"mcp-*\"        # Glob-like patterns won't work (FTS5 isn't grep)\n```\n\n3. **Population** — from extractions:\n```python\n# During extraction or backfill\nfor file in metadata.get('files_touched', []):\n    db.add_file_mention(source_id, file, operation='unknown')\n```\n\n4. **Search preprocessing**:\n```python\ndef quote_file_pattern(query):\n    # Quote terms containing dots (file extensions)\n    if '.' in query and not query.startswith('\"'):\n        return f'\"{query}\"'\n    return query\n```\n\n## Effort Estimate (revised)\n- Schema + migration: 1 hr\n- CLI command: 30 min\n- Backfill: 1 hr\n- Total: ~2.5 hr (down from 6 hr)\n\n## Open Questions\n1. Store full path or basename? Recommend full path (more context), but index both\n2. Normalize paths? ~/Repos/x vs /Users/modha/Repos/x — probably store as-is, let FTS5 match substrings","notes":"SPIKE COMPLETE: Path tokenization is not a problem\n\nKEY FINDING: FTS5 default tokenizer + auto-quoting of dotted terms = simple solution\nNo custom tokenizer needed. Effort estimate reduced from 6hr to 2.5hr.\n\nReady to implement when prioritized.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-31T16:01:53.411286Z","updated_at":"2025-12-31T16:34:16.375642Z","closed_at":"2025-12-31T16:34:16.375642Z","close_reason":"File-based search implemented: mem files command + backfill-files, 5537 files indexed"}
{"id":"claude-memory-q03","title":"Add error handling to session-end hook","description":"Hook currently fails silently if mem process errors. Should log failures visibly.","design":"Current: errors go to log file but no alerting\n\nOptions:\n1. Check exit code, append FAILED to log filename\n2. Write to separate error log (~/.claude/extraction-errors.log)\n3. Desktop notification on failure (osascript)\n\nRecommend: Option 1 + 2\n- Rename log to *.FAILED.log on non-zero exit\n- Append to extraction-errors.log with timestamp\n\nEasy to spot failures: ls ~/.claude/extraction-logs/*.FAILED.log","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T16:48:35.053455Z","updated_at":"2025-12-28T22:27:53.16713Z","closed_at":"2025-12-28T22:27:53.16713Z","close_reason":"Added error handling to session-end hook:\n- Captures exit code from mem process\n- On failure: renames log to *.FAILED.log for easy spotting\n- Appends to ~/.claude/extraction-errors.log with timestamp\n\nEasy to spot failures: ls ~/.claude/extraction-logs/*.FAILED.log"}
{"id":"claude-memory-q3q","title":"Phase 3: Entity Resolution","description":"Interactive workflow for building and maintaining the glossary. Make 'GeoX' and 'Region:Lift' recognized as the same thing.","design":"## Scope\nInteractive entity resolution workflow — the glossary exists, extraction captures entities, but the workflow for resolving pending entities and expanding aliases in search is incomplete.\n\n## Deliverables\n1. `mem resolve` — Interactive resolution of pending entities\n2. Alias expansion in search queries (search \"GeoX\" finds \"Region:Lift\" content)\n3. `mem digest` — Periodic review of auto-resolved mappings\n4. Glossary quality metrics (optional)\n\n## Acceptance Criteria\n- [ ] `mem resolve` walks through pending entities with accept/reject/rename options\n- [ ] Search for alias term returns results containing canonical term\n- [ ] `mem digest` shows auto-mappings for review\n- [ ] 94 pending entities reduced to \u003c20 after initial pass","notes":"COMPLETED (conversationally):\n- Pending entities: 26 → 0 (7 rejected, 4 mapped to stefan_hoejmose, 15 added to glossary)\n- Decided NOT to build `mem resolve` command — conversational triage with Claude is simpler for small batches\n\nREMAINING (as child beads):\n- v2g: Alias expansion in search (check if already works, then implement if needed)\n- esy: mem digest for reviewing auto-mappings (P3, nice-to-have)\n\nDECISION: `mem resolve` not needed — conversational approach works fine. Revisit if entity volume grows significantly.","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-29T13:12:41.326447Z","updated_at":"2025-12-31T18:28:26.679136Z","closed_at":"2025-12-31T18:28:26.679136Z","close_reason":"Phase 3 complete: 26 pending entities resolved to 0, alias expansion already works, decided not to build mem resolve (conversational triage sufficient). Only esy (mem digest) remains as standalone P3."}
{"id":"claude-memory-q6f","title":"Implement session chunking for large conversations","description":"Sessions \u003e150k chars exceed Sonnet's 200k token limit. Need chunking with overlap and merge step.","design":"## Approach\n1. Detect session size before extraction\n2. If \u003e150k chars, split into chunks (~140k each, 5k overlap)\n3. Extract from each chunk with \"chunk N of M\" context\n4. Merge results: deduplicate builds/learnings, synthesize arc\n\n## Tested approach (worked)\n- 4 chunks of 140k chars\n- Extraction prompt per chunk\n- Final merge prompt combines all chunk outputs\n\n## Files\n- src/mem/extraction.py","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-28T21:34:27.656265Z","updated_at":"2025-12-28T22:18:28.71468Z","closed_at":"2025-12-28T22:18:28.71468Z","close_reason":"Approach documented and tested, implementation deferred.\n\nFINDINGS:\n- Even 100MB JSONL files produce \u003c100k chars content (tool outputs stripped)\n- Chunking rarely needed in practice\n\nAVAILABLE:\n- Chunk/merge prompts in prompts/hybrid.md\n- Working extract_chunked() in scripts/haiku_test.py\n\nNEXT: Integrate when hybrid extraction joins main pipeline (src/mem/extraction.py still uses old entity-only prompt)."}
{"id":"claude-memory-q7e","title":"Proposed: Memory decay / recency weighting in search","description":"Add recency weighting to search results so recent conversations rank higher than old ones.\n\nDiscovered from claude-self-reflect (https://github.com/ramakay/claude-self-reflect) which uses\na 90-day half-life for memory decay, improving search relevance for current work.","design":"## Problem\n\nCurrent FTS5 search ranks purely by text relevance. A perfect keyword match from 6 months ago\nranks equally with a match from yesterday, even though recent context is usually more relevant.\n\n## Proposed Solution\n\nModify `db.search()` to incorporate `updated_at` into ranking.\n\n### Decay Formula\n```python\n# Half-life of 90 days\ndecay_factor = 0.5 ** (days_old / 90)\nfinal_score = fts_score * decay_factor\n```\n\n| Age | Decay Factor |\n|-----|--------------|\n| 0 days | 1.0 |\n| 30 days | 0.79 |\n| 90 days | 0.5 |\n| 180 days | 0.25 |\n| 365 days | 0.06 |\n\n### Implementation Options\n\n**Option A: Post-query reranking**\n- Run FTS5 query as normal\n- Fetch timestamps for results\n- Multiply scores by decay factor\n- Re-sort\n\nPros: No schema change, easy to implement\nCons: Can't use LIMIT in FTS query (need all results to rerank)\n\n**Option B: SQL-level scoring**\n```sql\nSELECT *, \n  bm25(fts) * (0.5 ** ((julianday('now') - julianday(updated_at)) / 90)) as score\nFROM conversations_fts\nWHERE conversations_fts MATCH ?\nORDER BY score DESC\nLIMIT 20\n```\n\nPros: Efficient, uses database\nCons: More complex query, decay params hardcoded in SQL\n\n**Option C: Configurable via search flags**\n```bash\nmem search \"OAuth\" --recency-weight 0.5  # Half-life 90 days\nmem search \"OAuth\" --no-recency          # Pure FTS ranking\nmem search \"OAuth\" --recent-only 30      # Only last 30 days\n```\n\n### Recommended: Option C\n\nKeep current behavior as default, add `--recency-weight` flag for decay scoring.\nThis is additive, doesn't break existing workflows.\n\n## Considerations\n\n1. **Half-life tuning**: 90 days is arbitrary. Might want shorter (30 days) for fast-moving work.\n2. **Per-source decay**: Maybe handoffs decay slower than conversations?\n3. **Explicit freshness boost**: \"Recent things about X\" vs \"Everything about X\"\n\n## Effort Estimate\n- Option A: Low (1 hr)\n- Option B: Medium (2 hr)  \n- Option C: Medium (2 hr + tests)\n\n## Alternative: Skip This\n\nCurrent search works. Power users can filter by date manually:\n```bash\nmem search \"OAuth\" | grep \"2025-12\"\n```\n\n**Verdict**: Nice-to-have, not urgent. Consider when search quality becomes a pain point.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-31T16:01:52.142777Z","updated_at":"2025-12-31T16:27:56.698141Z","closed_at":"2025-12-31T16:27:56.698141Z","close_reason":"Added --recency flag to mem search - post-query rerank with configurable half-life"}
{"id":"claude-memory-rs8","title":"Implement Phase 1: Core Loop","design":"Get something working end-to-end: discover → index → search.\n\nReference: spec.md ## Implementation Order \u003e Phase 1\n\nAcceptance criteria:\n- [ ] Config loading from ~/.config/conversation-memory/config.yaml\n- [ ] SQLite database initialized from schema.sql\n- [ ] Claude.ai conversations discovered and indexed\n- [ ] `mem search` returns matching conversations\n- [ ] `mem drill` loads full conversation content","notes":"COMPLETED:\n- Config loading (rs8.1) - ~/.claude/memory/config.yaml\n- Glossary loading - 55 entities with hierarchy, alias resolution\n- SQLite + FTS5 schema (rs8.2)\n- Claude Code adapter → database wiring\n- Basic summaries (title + first messages, no LLM yet)\n- mem scan: 1386 conversations indexed\n- mem search: FTS5 with glossary expansion\n- mem drill: metadata + full content\n\nREMAINING:\n- rs8.3: Claude.ai adapter (has pre-summaries, should be easier)\n\nISSUES FOUND:\n- Compacted conversations have noisy \"Context: This summary...\" titles\n- Need to detect \u003csummary\u003e tags from episodic compaction\n- Project path mismatch (claude-journal indexed under parent dir)","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-27T19:39:56.80178Z","updated_at":"2025-12-27T23:10:51.459781Z","closed_at":"2025-12-27T23:10:51.459781Z","close_reason":"Phase 1 complete: config loading, SQLite + FTS5, Claude Code + Claude.ai adapters, search/drill commands. 1458 sources indexed (1388 Code, 70 AI)."}
{"id":"claude-memory-rs8.1","title":"Wire config loading (YAML → dict)","description":"Load config.yaml, expand paths, validate required fields. See config.yaml.template for structure.","design":"Create config and glossary loading modules.\n\n## Files to create\n- src/mem/config.py - load_config(), get_memory_dir(), defaults\n- src/mem/glossary.py - load_glossary(), lookup helpers\n\n## Behavior\n- Config path: ~/.claude/memory/config.yaml (create if missing from template)\n- Glossary path: ~/.claude/memory/glossary.yaml\n- Expand ~ in all paths\n- CLI wires config into click context for commands to use\n\n## Reference\n- Adapters already take config dict (see discover_claude_ai, discover_claude_code)\n- config.yaml.template in repo root","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T19:40:10.489577Z","updated_at":"2025-12-27T21:28:08.462787Z","closed_at":"2025-12-27T21:28:08.462787Z","close_reason":"Config and glossary loading complete. mem scan and mem status working. Glossary resolves aliases, navigates hierarchy.","dependencies":[{"issue_id":"claude-memory-rs8.1","depends_on_id":"claude-memory-rs8","type":"parent-child","created_at":"2025-12-27T19:40:10.491348Z","created_by":"daemon","metadata":"{}"}]}
{"id":"claude-memory-rs8.2","title":"Initialize SQLite from schema.sql","description":"Create database helper: init from schema, connection management, basic CRUD for sources/summaries tables.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T19:40:10.535826Z","updated_at":"2025-12-27T21:37:54.847536Z","closed_at":"2025-12-27T21:37:54.847536Z","close_reason":"SQLite database with FTS5 working. Schema includes sources, summaries, triggers.","dependencies":[{"issue_id":"claude-memory-rs8.2","depends_on_id":"claude-memory-rs8","type":"parent-child","created_at":"2025-12-27T19:40:10.536233Z","created_by":"daemon","metadata":"{}"},{"issue_id":"claude-memory-rs8.2","depends_on_id":"claude-memory-rs8.1","type":"blocks","created_at":"2025-12-27T19:40:38.550929Z","created_by":"daemon","metadata":"{}"}]}
{"id":"claude-memory-rs8.3","title":"Connect Claude.ai adapter to database","description":"Wire discover_claude_ai() to database: upsert sources, store summaries with has_presummary=True.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T19:40:10.581648Z","updated_at":"2025-12-27T22:41:45.959867Z","closed_at":"2025-12-27T22:41:45.959867Z","close_reason":"Claude.ai adapter wired to database. 70 conversations indexed with pre-generated summaries. Search and status commands show both source types.","dependencies":[{"issue_id":"claude-memory-rs8.3","depends_on_id":"claude-memory-rs8","type":"parent-child","created_at":"2025-12-27T19:40:10.582026Z","created_by":"daemon","metadata":"{}"},{"issue_id":"claude-memory-rs8.3","depends_on_id":"claude-memory-rs8.2","type":"blocks","created_at":"2025-12-27T19:40:38.583853Z","created_by":"daemon","metadata":"{}"}]}
{"id":"claude-memory-rs8.4","title":"Implement mem scan command","description":"CLI command that discovers sources, shows counts by type, stores in database with status=pending.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T19:40:10.62662Z","updated_at":"2025-12-27T21:55:42.085494Z","closed_at":"2025-12-27T21:55:42.085494Z","close_reason":"mem scan working: discovers Claude Code conversations, stores in DB, creates basic summaries, indexes in FTS5. 1386 conversations indexed.","dependencies":[{"issue_id":"claude-memory-rs8.4","depends_on_id":"claude-memory-rs8","type":"parent-child","created_at":"2025-12-27T19:40:10.627Z","created_by":"daemon","metadata":"{}"},{"issue_id":"claude-memory-rs8.4","depends_on_id":"claude-memory-rs8.3","type":"blocks","created_at":"2025-12-27T19:40:38.616557Z","created_by":"daemon","metadata":"{}"}]}
{"id":"claude-memory-rs8.5","title":"Implement mem search command","description":"BM25 search over summaries_fts, display results with title/snippet/date. Include query alias expansion.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T19:40:10.673024Z","updated_at":"2025-12-27T21:55:42.780602Z","closed_at":"2025-12-27T21:55:42.780602Z","close_reason":"mem search working: FTS5 search with glossary expansion (GeoX → Region:Lift aliases), mem drill shows metadata + full content.","dependencies":[{"issue_id":"claude-memory-rs8.5","depends_on_id":"claude-memory-rs8","type":"parent-child","created_at":"2025-12-27T19:40:10.673396Z","created_by":"daemon","metadata":"{}"},{"issue_id":"claude-memory-rs8.5","depends_on_id":"claude-memory-rs8.4","type":"blocks","created_at":"2025-12-27T19:40:38.648744Z","created_by":"daemon","metadata":"{}"}]}
{"id":"claude-memory-s71","title":"Filter XML command tags from titles","description":"User testing revealed: Some titles contain raw XML like \u003ccommand-message\u003eopen\u003c/command-message\u003e.\n\nThis leaks internal markup into user-visible search results. Should strip these at parse/title extraction time.","design":"In title extraction (claude_code adapter):\n- Strip \u003ccommand-*\u003e...\u003c/command-*\u003e tags\n- Strip other internal markup patterns\n\nSimple regex: re.sub(r'\u003ccommand-\\w+\u003e.*?\u003c/command-\\w+\u003e', '', title)","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-28T10:29:34.612974Z","updated_at":"2025-12-28T10:33:21.938512Z","closed_at":"2025-12-28T10:33:21.938512Z","close_reason":"Added clean_title() helper to strip \u003ccommand-*\u003e tags. Applied in both claude_code and cloud_sessions adapters. Added test."}
{"id":"claude-memory-ser","title":"Index extraction learnings/builds in FTS for search","design":"## Problem\nHybrid extraction produces rich structured data (learnings, builds, friction, patterns) but only the summary field is FTS-indexed. Users can't search for specific insights.\n\n## Solution\nFlatten extraction JSON fields into searchable text and add to FTS index.\n\n## Implementation\n1. Modify sync-fts to also flatten and index:\n   - learnings[].insight + learnings[].why_it_matters\n   - builds[].what + builds[].outcome  \n   - friction[].problem\n   - patterns[]\n\n2. Update FTS schema or append to summary_text\n\n3. Re-sync all sources with extractions\n\n## Acceptance\n- `mem search \"theatre\"` finds the AskUserQuestion learning\n- `mem search \"genuine engagement\"` returns results\n- Learnings surfaced in search results","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-30T09:54:22.457408Z","updated_at":"2025-12-30T09:58:45.356665Z","closed_at":"2025-12-30T09:58:45.356665Z","close_reason":"Flattened learnings/builds/friction into FTS index via enhanced sync-fts. Search now finds 'theatre of ticking box' and similar insights."}
{"id":"claude-memory-ufn","title":"Proposed: PostToolUse hook for automatic metadata capture","description":"Add automatic tool call logging during sessions to capture what files/tools were touched,\nwithout requiring /close to trigger extraction.\n\nDiscovered from analyzing claude-mem (https://github.com/thedotmack/claude-mem) which uses\nlifecycle hooks (SessionStart, PostToolUse, Stop, SessionEnd) to capture context automatically.","design":"## Problem\n\nCurrent claude-memory extraction happens at /close (opt-in ritual). This means:\n- Mid-session context is lost if session crashes\n- Tool usage patterns not captured until session ends\n- No incremental building of session metadata\n\n## Proposed Solution\n\nAdd a PostToolUse hook that logs tool calls to a session metadata file.\n\n### Hook Location\n`~/.claude/hooks/PostToolUse/capture-tool-metadata.py`\n\n### What to Capture\n```json\n{\n  \"timestamp\": \"2025-12-31T15:30:00Z\",\n  \"tool\": \"Edit\",\n  \"file_path\": \"/Users/modha/Repos/mcp-google-workspace/server.py\",\n  \"operation\": \"edit\"  // derived from tool type\n}\n```\n\nFor file operations:\n- Read → file_path, lines read\n- Edit → file_path, old_string preview, new_string preview  \n- Write → file_path, size\n- Bash → command (sanitized), working directory\n\n### Storage\nAppend-only JSONL file per session:\n`~/.claude/session-metadata/\u003csession-id\u003e.jsonl`\n\n### Integration with Extraction\nAt /close, the extraction script reads session metadata to:\n1. Populate `files_touched` more accurately\n2. Identify tools used most\n3. Provide richer context for LLM extraction\n\n### Benefits\n- **Crash recovery**: Partial session data survives\n- **Richer extraction**: More accurate file lists\n- **Usage patterns**: See which tools are used most\n- **Debugging**: Trace what happened in a session\n\n### Effort Estimate\n- Hook implementation: Low (30 min)\n- Integration with extraction: Medium (2 hr)\n- Testing: Medium (1 hr)\n\n## Considerations\n\n1. **Token cost**: Hook runs on every tool call. Must be fast, minimal output.\n2. **Privacy**: Command args might contain secrets. Sanitize or skip sensitive tools.\n3. **Storage**: JSONL files grow. Need cleanup strategy.\n4. **Race conditions**: Multiple tool calls in parallel → file locking needed.\n\n## Alternative: Skip This\n\nThe current /close-based extraction works. This adds complexity for:\n- Marginal improvement in file tracking accuracy\n- Crash recovery (how often do sessions crash?)\n- Usage analytics (do we care?)\n\n**Verdict**: Low priority. Worth doing eventually, not blocking other work.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-31T16:01:49.511077Z","updated_at":"2025-12-31T16:25:17.333034Z","closed_at":"2025-12-31T16:25:17.333034Z","close_reason":"Won't do - solving theoretical problem, current /close extraction works"}
{"id":"claude-memory-v2g","title":"Alias expansion in search queries","description":"Search for alias term should return results containing canonical term. e.g. search 'GeoX' finds 'Region:Lift' content.","design":"Check if glossary expansion already works in mem search. If not, expand query terms via glossary aliases before FTS5 query.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-31T18:25:54.098021Z","updated_at":"2025-12-31T18:27:28.127847Z","closed_at":"2025-12-31T18:27:28.127847Z","close_reason":"Already implemented — search expands aliases via glossary. Tested GeoX→Region:Lift and Auction Boost→Region:Lift, both work.","dependencies":[{"issue_id":"claude-memory-v2g","depends_on_id":"claude-memory-q3q","type":"parent-child","created_at":"2025-12-31T18:26:00.789547Z","created_by":"modha","metadata":"{}"}]}
{"id":"claude-memory-vo2","title":"Add drill support for local_md source type","description":"mem drill shows 'Unknown source type' for local_md. Need to add handler in cli.py drill command.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-31T17:33:34.522603Z","updated_at":"2025-12-31T18:17:01.744749Z","closed_at":"2025-12-31T18:17:01.744749Z","close_reason":"Added local_md to handoff handler - same pattern since both are human-readable markdown. Tested with meeting notes, both basic and --full modes work."}
{"id":"claude-memory-wtc","title":"Phase 6: Local Sources","description":"Expand beyond conversations — local markdown files, PDFs, personal notes searchable.","design":"## Scope\nAdd adapters for local file sources. Depends on Phase 5 (Processing Infrastructure) for sanity with bulk operations.\n\n## Deliverables\n1. Local markdown adapter (~/Documents, PARA structure)\n2. Local PDF adapter (content extraction)\n3. Change detection (mtime-based rescan)\n4. Config for which directories to scan\n\n## Acceptance Criteria\n- [ ] Markdown files from configured paths indexed and searchable\n- [ ] PDFs have text extracted and indexed\n- [ ] Re-running scan picks up new/modified files only\n- [ ] Search results include local files alongside conversations","notes":"COMPLETED: Local markdown adapter for Meeting Notes\n\n- Created local_md.py adapter with title/date extraction from filename\n- Indexed 2316 meeting notes from ~/Drive/Work/Meeting Notes (2015-2025)\n- Full content indexed for FTS search\n- Glossary expansion working (Region:Lift → GeoX, Auction Boost finds notes)\n\nREMAINING FOR PHASE 6:\n- PDF adapter (content extraction)\n- Change detection (mtime-based rescan)\n- LLM summarization for richer search (optional, expensive)\n\nDatabase now: 4181 sources (1865 conversations + 2316 meeting notes)","status":"open","priority":2,"issue_type":"epic","created_at":"2025-12-29T13:12:46.959315Z","updated_at":"2025-12-31T16:51:17.896386Z","dependencies":[{"issue_id":"claude-memory-wtc","depends_on_id":"claude-memory-xji","type":"blocks","created_at":"2025-12-29T13:12:56.440847Z","created_by":"daemon","metadata":"{}"}]}
{"id":"claude-memory-xji","title":"Phase 5: Processing Infrastructure","description":"Support bulk ingestion and ongoing maintenance — backfill command, progress tracking, resumability.","design":"## Scope\nBefore adding new source types (markdown, PDFs), need infrastructure for processing hundreds of files without manual babysitting.\n\n## Deliverables\n1. `mem backfill` command with progress tracking and resume\n2. `mem status --pending` showing processing queue by source type\n3. Rate limiting and error recovery for API-heavy operations\n4. (Future) `mem watch` daemon for file change detection\n\n## Acceptance Criteria\n- [ ] `mem backfill --source local_md --limit 100` processes files with progress output\n- [ ] Interrupted backfill can resume from where it stopped\n- [ ] `mem status --pending` shows counts by source type\n- [ ] API errors don't crash backfill, just log and continue","status":"open","priority":2,"issue_type":"epic","created_at":"2025-12-29T13:12:45.918295Z","updated_at":"2025-12-29T13:12:45.918295Z"}
{"id":"claude-memory-zdn","title":"Handle hyphenated search terms gracefully","description":"FTS5 interprets hyphens as operators, causing searches for 'claude-memory' to fail. Either auto-quote hyphenated terms or provide clearer error with suggested fix.","design":"Options: (1) detect hyphens in query and auto-wrap in quotes, (2) improve error message to suggest quoting, (3) both. Start with better error message, consider auto-quote if it doesn't break other use cases.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T14:37:07.317449Z","updated_at":"2025-12-30T09:14:19.306595Z","closed_at":"2025-12-30T09:14:19.306595Z","close_reason":"Auto-quote hyphenated terms in search. _auto_quote_hyphenated() wraps terms like 'claude-memory' before FTS5 query.","dependencies":[{"issue_id":"claude-memory-zdn","depends_on_id":"claude-memory-4oe","type":"parent-child","created_at":"2025-12-29T14:37:19.140955Z","created_by":"daemon","metadata":"{}"}]}
{"id":"claude-memory-zhp","title":"Add date/age to search result display","description":"User feedback: \"Date not prominent in search results — I had to look carefully to see when the conversation happened\"\n\nMemory is temporal. Surfacing \"3 weeks ago\" or \"Dec 5\" in search result lines would help triage.","design":"In search output, add relative or absolute date:\n- \"3 weeks ago\" for recent\n- \"Dec 5\" for older\n\nUse created_at from source, format with humanize or similar.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-28T10:29:54.313253Z","updated_at":"2025-12-28T10:36:23.489075Z","closed_at":"2025-12-28T10:36:23.489075Z","close_reason":"Added relative date formatting to search results (13h ago, 2w ago, yesterday, Dec 5). Helps triage temporal context."}
{"id":"claude-modus-1mx","title":"Handoff collision when multiple sessions /close in same folder","description":"When running parallel Claude sessions in the same folder (e.g., multiple workstreams in ~/Work), handoffs overwrite each other. Session A writes handoff, Session B overwrites, Session C does /open and gets wrong context.\n\nDiscovered during orchestration session with 3 Claudes in Work folder (contracts, RFI, filing).\n\n## Current behavior\n- Handoff writes to fixed location per folder\n- Last /close wins\n- /open picks up whatever is there\n\n## Expected behavior\n- Handoffs should be distinguishable by workstream/purpose\n- /open should be able to target specific handoff","design":"## Possible approaches\n\n1. **Named handoffs** — handoff-{purpose}.md, /close asks for name, /open lists available\n2. **Session ID in filename** — handoff-{session-id}.md, /open shows recent and lets user pick\n3. **Subfolder convention** — encourage workstream subfolders, one handoff per subfolder\n4. **Handoff registry** — metadata file listing active handoffs with timestamps and summaries\n\nOption 1 (named) feels most ergonomic for knowledge work where purposes are meaningful.","notes":"## COMPLETED 2026-01-04\n\n### Changes Made\n1. **Path canonicalization** — `pwd -P` in open-context.sh and close-context.sh resolves symlinks for consistent encoding\n2. **Multi-handoff picker** — open-context.sh now lists all handoffs with purpose (first Done bullet) when multiple exist\n3. **Session ID filename** — session-closing SKILL.md updated to use `{session_id_short}.md` pattern\n4. **Purpose header** — handoffs now include `purpose:` line for picker display\n5. **Migration script** — scripts/migrate-handoffs.sh consolidates fragmented Google Drive handoff folders\n\n### Related\n- Filed claude-modus-8lt for path fragmentation bug (discovered during investigation)\n- Ran migration to consolidate Work folder handoffs (4 files from 2 variant folders → 1 canonical folder)\n\n### Testing\n- Verified picker works with 4 handoffs in Work folder\n- Fixed space-in-path bug in for loop (while read instead)","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-04T19:10:52.27283Z","updated_at":"2026-01-04T22:22:26.999417Z","closed_at":"2026-01-04T22:22:26.999417Z","close_reason":"Fixed with path canonicalization, multi-handoff picker, and session_id filename pattern in skill docs. Migration script provided for existing fragmented folders."}
{"id":"claude-modus-3lg","title":"Handoff path encoding inconsistent between Claudes","description":"Different Claudes use different path encoding for handoff folders. Some use tr '/.' '-' (preserves @ and space), others encode more aggressively (@ and space → -). Results in fragmentation again.\n\n## Evidence\nAfter fix in this session, another Claude created:\n- `-Users-modha-Library-CloudStorage-GoogleDrive-sameer-modha-itv-com-My-Drive-Work`\n\nWhile our canonical is:\n- `-Users-modha-Library-CloudStorage-GoogleDrive-sameer-modha@itv-com-My Drive-Work`\n\n## Root cause\nsession-closing SKILL.md says 'encode path' but doesn't give exact command. Each Claude interprets encoding differently.\n\n## Fix\nAdd explicit encoding command to skill, or have scripts do the encoding and write to a known location.","notes":"## Additional bug: HANDOFF_DIR not output for container directories\n\nclose-context.sh only outputs HANDOFF_DIR when IS_CONTAINER=false. For container sessions (~/Repos, ~/Work), HANDOFF_DIR is missing entirely → Claude improvises → writes to CWD.\n\nFix: Move HANDOFF_DIR output outside the is_container conditional.","status":"open","priority":2,"issue_type":"bug","created_at":"2026-01-04T22:52:04.713831Z","updated_at":"2026-01-04T23:04:59.339452Z"}
{"id":"claude-modus-8lt","title":"Handoff path fragmentation from symlink vs canonical path","description":"Google Drive symlink causes handoffs to land in different folders depending on how user cd'd to Work. pwd returns different values for same logical location, encoding differs, handoffs fragment.\n\nDiscovered during 1mx investigation. Claude in Work couldn't find 'right' handoff because it was looking at canonical path while handoffs were in symlink-path folder.\n\n## Current behavior\n- ~/Google Drive is symlink to ~/Library/CloudStorage/GoogleDrive-...\n- pwd returns whichever path you used to get there\n- Encoding differs: -Users-modha-Google Drive-... vs -Users-modha-Library-CloudStorage-...\n- Handoffs split across two folders\n\n## Expected behavior\n- All handoffs for same logical location land in same folder\n- Use pwd -P to canonicalize before encoding","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-04T22:18:13.246233Z","updated_at":"2026-01-04T22:22:38.831813Z","closed_at":"2026-01-04T22:22:38.831813Z","close_reason":"Fixed alongside 1mx: pwd -P canonicalization in both scripts, migration script ran and consolidated Work folder handoffs."}
{"id":"claude-modus-amh","title":"todoist-gtd skill missing Personal vs MIT project split","description":"Skill doesn't document the two-account structure: personal projects (Personal, @Home, etc) vs MIT shared projects (Desired Outcomes H1, Areas of Focus, etc). User had to correct Claude when it tried to add personal outcome to MIT Desired Outcomes H1. Skill should document this split and which projects are personal vs team.","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-04T18:38:18.030827Z","updated_at":"2026-01-04T22:41:34.618571Z","closed_at":"2026-01-04T22:41:34.618571Z","close_reason":"Documented Personal vs MIT shared project split in todoist-gtd skill. Added table showing which projects are personal vs team-visible, and critical distinction between Personal project's 'Desired Outcomes' section vs Desired Outcomes Q4/H1 projects."}
{"id":"claude-modus-cf1","title":"Field Report: Todoist find-tasks hides tasks assigned to others by default","description":"The Todoist MCP's find-tasks tool defaults responsibleUserFiltering to 'unassignedOrMe', which hides tasks assigned to other collaborators in shared projects. This caused duplicate creation when Claude couldn't see existing tasks assigned to teammates.","design":"## Context\nWorking on MIT Contract Stewardship bead (Lantern-c6d). Needed to update Todoist \"Supplier Relationships\" section with descriptions for 7 suppliers.\n\n## Observation\nInitial find-tasks query returned only 6 tasks (assigned to Sameer). Created 7 \"new\" supplier tasks. User pointed out duplicates existed — the originals were assigned to Stefano and Lauren, invisible to Claude's API queries.\n\nThe culprit: `responsibleUserFiltering` defaults to `unassignedOrMe`. To see ALL tasks in a section (regardless of assignee), must explicitly set `responsibleUserFiltering: \"all\"`.\n\n## Impact\n- Created 7 duplicate tasks before discovering the issue\n- Had to delete duplicates, then update originals by ID\n- Working doc incorrectly stated \"only 6 entries\" because Claude couldn't see the other 12\n\n## Suggestion\nThe todoist-gtd skill should document this gotcha prominently. When querying shared projects (especially Areas of Focus sections used for stewardship), always use `responsibleUserFiltering: \"all\"` unless you specifically want only your tasks.\n\nConsider adding to skill:\n- Warning about default filtering behavior\n- Pattern for \"show me everything in this section\" queries\n- Note that fetch-object by ID bypasses this filter (useful for updates)","acceptance_criteria":"- [ ] todoist-gtd SKILL.md documents responsibleUserFiltering default behavior\n- [ ] Includes example of querying with \"all\" for shared project sections\n- [ ] Notes that fetch-object by ID works regardless of assignment","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-04T20:59:09.034722Z","updated_at":"2026-01-04T21:23:12.591766Z","closed_at":"2026-01-04T21:23:12.591766Z","close_reason":"Added Assignment Filtering section to todoist-gtd SKILL.md documenting the responsibleUserFiltering gotcha, with examples and mode reference table. Added cross-reference warning in Find by Person section.","labels":["field-report"]}
{"id":"claude-modus-doz","title":"MCP-free todoist-gtd skill for team starter package","description":"Create a version of todoist-gtd that uses direct REST API calls instead of the Todoist MCP. This removes the ~13k token overhead from MCP tool definitions and enables the team starter package to work without global MCP configuration.","design":"## Approach\n\nThe current todoist-gtd skill is a **semantic layer** that provides meaning/coaching on top of MCP data access. It doesn't make MCP calls itself — it guides Claude on HOW to use MCP tools.\n\nFor MCP-free version:\n1. Create shell scripts that call Todoist REST API directly\n2. Update SKILL.md to reference scripts instead of MCP tools\n3. Handle auth via Keychain (same pattern as existing MCP wrapper)\n\n## Key API Mappings\n\n| MCP Tool | REST API Equivalent |\n|----------|---------------------|\n| `find_projects()` | `GET /rest/v2/projects` |\n| `find_sections(projectId)` | `GET /rest/v2/sections?project_id=X` |\n| `find_tasks(sectionId)` | `GET /rest/v2/tasks?section_id=X` |\n| `complete_tasks(id)` | `POST /rest/v2/tasks/{id}/close` |\n| `add_tasks(...)` | `POST /rest/v2/tasks` |\n| `add_sections(...)` | `POST /rest/v2/sections` |\n| `find_comments(taskId)` | `GET /rest/v2/comments?task_id=X` |\n| `user_info()` | No direct equivalent (use Sync API or skip) |\n| `get_overview()` | Composite (projects + sections + tasks) |\n\n## Workflow\n\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Create scripts in skills/todoist-gtd/scripts/\n3. Update SKILL.md to use Bash calls instead of MCP references\n4. Test against real Todoist account\n5. Copy to itv-claude-starter","acceptance_criteria":"- [ ] Shell scripts exist for: get-projects, get-sections, get-tasks, complete-task, add-task, add-section, get-comments\n- [ ] Scripts authenticate via Keychain (TODOIST_API_TOKEN pattern)\n- [ ] SKILL.md updated to reference Bash scripts instead of MCP tools\n- [ ] Scripts handle common query patterns (filter by project, section, label)\n- [ ] Error handling for auth failures, rate limits\n- [ ] Tested with real Todoist data\n- [ ] Copied to itv-claude-starter/skills/todoist-gtd/","status":"in_progress","priority":1,"issue_type":"task","created_at":"2026-01-06T21:48:54.019404Z","updated_at":"2026-01-06T21:51:55.734852Z"}
{"id":"claude-modus-ks9","title":"Test artifact-aware handoff pattern in Google Drive session","description":"session-closing skill now has Knowledge Work Context section. Test it by doing a real session in Google Drive, using /close, and seeing if the Artifacts section populates usefully. Skill changes are uncommitted in claude-modus — commit if it works, iterate if not.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-06T18:31:15.236457Z","updated_at":"2026-01-06T18:31:15.236457Z"}
{"id":"claude-modus-q7u","title":"Orchestration dashboard for multi-Claude sessions","description":"When running 4+ Claude sessions in parallel, need a simple way to track:\n- Which pane has which task\n- Current status of each\n- Last update from each\n\nDiscovered during Jan 4 2026 orchestration session. Currently tracked mentally or in conversation, but a markdown tracker would help.\n\n## Pattern\n| Pane | Project | Task | Status | Last update |\n|------|---------|------|--------|-------------|\n| TL | ... | ... | ... | ... |","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-04T22:59:49.443415Z","updated_at":"2026-01-04T22:59:49.443415Z"}
{"id":"claude-modus-qpe","title":"bd init inherits from parent hub unexpectedly","description":"When running `bd init` in a subdirectory of a location with a parent `.beads/` (hub), the new database inherits/hydrates all issues from the parent hub instead of starting empty.\n\n## Discovery Context\nSession in ~/Repos/claude-modus. The startup hook showed beads from 18+ different projects (infra-openwrt, claude-memory, sb, etc.) even though claude-modus should only have its own issues.\n\nInvestigation revealed:\n- ~/Repos/.beads is a hub with `repos.additional` listing 24 project paths\n- ~/Repos/claude-modus/.beads was created by `bd init` but contained 343 issues from the hub's hydrated state\n- The 3 legitimate claude-modus-* issues were buried in 340+ unrelated issues\n\n## Steps to Reproduce\n1. Have a hub at ~/Repos/.beads with multi-repo config\n2. cd ~/Repos/new-project\n3. git init \u0026\u0026 bd init new-project\n4. bd list shows issues from all hub-hydrated repos, not empty\n\n## Expected Behavior\nbd init in a new project should create an empty database with only the specified prefix. It should NOT inherit from parent .beads/ directories.\n\n## Actual Behavior\nbd init creates a database, then immediately hydrates from the parent hub. The daemon log shows \"Pulled from remote\" and \"Imported from JSONL\" with the full hydrated state.\n\n## Workaround\nInitialize in an isolated temp directory outside the hub's tree, then copy the clean .beads structure:\n\\`\\`\\`bash\nTEMP=$(mktemp -d) \u0026\u0026 cd \"$TEMP\" \u0026\u0026 git init -q\nbd init myprefix --no-daemon\ncp -R .beads /path/to/real/project/\ncd /path/to/real/project \u0026\u0026 bd config set issue-prefix myprefix\n\\`\\`\\`\n\n## Related\n- Possibly same issue as infra-signboard contamination (mentioned by another Claude)\n- May be intentional for \"project inherits from org hub\" use cases, but needs opt-in not default","design":"## Approach\n1. Investigate bd init source code to understand parent discovery logic\n2. Determine if this is intentional behavior or bug\n3. If intentional: add --no-inherit or --isolated flag to bd init\n4. If bug: fix parent .beads discovery to not hydrate during init\n\n## Key Files (likely)\n- cmd/bd/init.go — init command implementation\n- internal/storage/discover.go — database discovery logic\n- internal/daemon/sync.go — sync/hydration logic\n\n## Questions for Yegge\n- Is parent hub inheritance intentional?\n- Should there be an opt-in vs opt-out for this behavior?\n- Is routes.jsonl write-routing separate from hydration inheritance?","acceptance_criteria":"- [ ] bd init in child of hub creates empty database (not hydrated)\n- [ ] Explicit flag available if user WANTS to inherit from parent hub\n- [ ] Documentation clarifies hub vs project-local database behavior\n- [ ] Workaround documented in beads skill until fixed","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-04T21:16:22.128093Z","updated_at":"2026-01-04T22:36:28.139412Z","closed_at":"2026-01-04T22:36:28.139412Z","close_reason":"Filed upstream as steveyegge/beads#896. Workaround documented in bead description."}
{"id":"claude-modus-tv0","title":"Knowledge work handoff pattern for non-git projects","description":"Code projects have: git commits + beads + handoff.md\nKnowledge work (Google Drive) has: ??? \n\nDiscovered gap during ITV contracts work. Proposed pattern:\n1. Create 'Working Summary' Google Doc as living artifact\n2. Append session log at bottom (safe, additive)\n3. Bead tracks completion of doc, not contains knowledge\n4. Version History provides diff equivalent\n\nNeeds: testing, skill support, maybe doc-coauthoring integration.\n\n## Open questions\n- How to handle complex edits (not just append)?\n- Where does handoff state live if not in git?","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-04T22:59:56.033316Z","updated_at":"2026-01-04T22:59:56.033316Z"}
{"id":"claude-web-playground-h4e","title":"Setup: Initialize playground for new experiments","description":"This is the meta-issue for setting up the claude-web-playground.\n\n**What to do:**\n1. Check `bd ready` to see available work\n2. Review CLAUDE.md and AGENTS.md for guidelines  \n3. Decide what to build in playground/ or experiments/\n4. Create issues for your work: `bd create \"Your task\" -p 2 -t task`\n5. Use TodoWrite for single-session tasks, bd for multi-session projects\n\n**About this environment:**\n- This is an ephemeral cloud sandbox (Claude Code Web)\n- Only git commits persist between sessions\n- `.beads/beads.db` regenerates each session from `.beads/issues.jsonl`\n- Always commit `.beads/issues.jsonl` together with code changes\n\n**When done:**\nClose this issue with `bd close claude-web-playground-h4e --reason \"Setup complete\"`","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-12T23:00:38.436074039Z","updated_at":"2025-11-13T07:12:52.896717259Z","closed_at":"2025-11-13T07:12:52.896717259Z"}
{"id":"infra-linux-servers-aa5","title":"Train departure board kiosk setup","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"closed","priority":3,"issue_type":"epic","created_at":"2025-11-23T14:25:17.994434Z","updated_at":"2025-12-30T19:12:55.723742Z","closed_at":"2025-12-30T19:12:55.723742Z","close_reason":"Redundant - train departure board work lives in infra-signboard repo, mostly complete. These were empty skeleton beads never worked on."}
{"id":"infra-linux-servers-aa5.1","title":"Phase 1: Foundation \u0026 Security","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-23T14:25:37.773065Z","updated_at":"2025-12-30T19:13:14.752693Z","closed_at":"2025-12-30T19:13:14.752693Z","close_reason":"Parent epic closed - work lives in infra-signboard"}
{"id":"infra-linux-servers-aa5.1.1","title":"Set up SSH key authentication","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-23T14:26:02.294991Z","updated_at":"2025-12-30T19:13:14.758143Z","closed_at":"2025-12-30T19:13:14.758143Z","close_reason":"Parent epic closed - work lives in infra-signboard"}
{"id":"infra-linux-servers-aa5.1.2","title":"Install base tools and packages","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-23T14:26:02.400985Z","updated_at":"2025-12-30T19:13:14.758896Z","closed_at":"2025-12-30T19:13:14.758896Z","close_reason":"Parent epic closed - work lives in infra-signboard"}
{"id":"infra-linux-servers-aa5.1.3","title":"Configure time synchronization","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-23T14:26:02.506136Z","updated_at":"2025-12-30T19:13:14.759671Z","closed_at":"2025-12-30T19:13:14.759671Z","close_reason":"Parent epic closed - work lives in infra-signboard"}
{"id":"infra-linux-servers-aa5.1.4","title":"Document and address boot errors","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-23T14:26:02.607348Z","updated_at":"2025-12-30T19:13:14.760444Z","closed_at":"2025-12-30T19:13:14.760444Z","close_reason":"Parent epic closed - work lives in infra-signboard"}
{"id":"infra-linux-servers-aa5.1.5","title":"Configure passwordless sudo","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-23T14:26:02.720154Z","updated_at":"2025-12-30T19:13:14.761174Z","closed_at":"2025-12-30T19:13:14.761174Z","close_reason":"Parent epic closed - work lives in infra-signboard"}
{"id":"infra-linux-servers-aa5.2","title":"Phase 2: Display System","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-23T14:25:37.874284Z","updated_at":"2025-12-30T19:13:14.753866Z","closed_at":"2025-12-30T19:13:14.753866Z","close_reason":"Parent epic closed - work lives in infra-signboard","dependencies":[{"issue_id":"infra-linux-servers-aa5.2","depends_on_id":"infra-linux-servers-aa5.1","type":"blocks","created_at":"2025-11-23T14:25:46.556282Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-linux-servers-aa5.3","title":"Phase 3: Train Board Application","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-23T14:25:37.975302Z","updated_at":"2025-12-30T19:13:14.75488Z","closed_at":"2025-12-30T19:13:14.75488Z","close_reason":"Parent epic closed - work lives in infra-signboard","dependencies":[{"issue_id":"infra-linux-servers-aa5.3","depends_on_id":"infra-linux-servers-aa5.2","type":"blocks","created_at":"2025-11-23T14:25:46.630813Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-linux-servers-aa5.4","title":"Phase 4: System Maintenance","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-23T14:25:38.077572Z","updated_at":"2025-12-30T19:13:14.755764Z","closed_at":"2025-12-30T19:13:14.755764Z","close_reason":"Parent epic closed - work lives in infra-signboard","dependencies":[{"issue_id":"infra-linux-servers-aa5.4","depends_on_id":"infra-linux-servers-aa5.1","type":"blocks","created_at":"2025-11-23T14:25:46.706578Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-linux-servers-aa5.5","title":"Phase 5: Documentation \u0026 Recovery","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-23T14:25:38.188582Z","updated_at":"2025-12-30T19:13:14.756526Z","closed_at":"2025-12-30T19:13:14.756526Z","close_reason":"Parent epic closed - work lives in infra-signboard"}
{"id":"infra-linux-servers-aa5.6","title":"Phase 6: Testing \u0026 Validation","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"closed","priority":3,"issue_type":"task","created_at":"2025-11-23T14:25:38.305474Z","updated_at":"2025-12-30T19:13:14.757339Z","closed_at":"2025-12-30T19:13:14.757339Z","close_reason":"Parent epic closed - work lives in infra-signboard","dependencies":[{"issue_id":"infra-linux-servers-aa5.6","depends_on_id":"infra-linux-servers-aa5.3","type":"blocks","created_at":"2025-11-23T14:25:46.782365Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-linux-servers-aa5.6","depends_on_id":"infra-linux-servers-aa5.4","type":"blocks","created_at":"2025-11-23T14:25:46.803825Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-linux-servers-nmd","title":"Replaced failing 6TB drive on kube.lan","description":"WD Red 6TB (WD60EFRX) has 14 pending bad sectors after 4.75 years. Order replacement (same model or WD Red Plus), migrate data, swap drive.","notes":"## Research (2026-01-04)\n\n**Recommendation:** WD Red Plus 6TB (WD60EFPX) — CMR, NAS-optimized\n\n**Why not Skyhawk?** Drive has mixed workload (Scrypted NVR + Plex library). Surveillance drives optimize for writes; NAS drives handle read/write mix better for Plex streaming.\n\n**Link:** https://www.amazon.co.uk/dp/B0DR8WPPQD (2025 version, dispatched by Amazon)\n**Price:** ~£140\n\n**Migration plan:** TBD — stop Scrypted/Plex, rsync data, swap drive, verify.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-04T13:13:02.341263Z","updated_at":"2026-01-04T14:33:07.224076Z"}
{"id":"infra-linux-servers-ojk","title":"Made video recording reliable on kube.lan (Scrypted + HKSV)","description":"New video doorbell needs recording working. Multiple issues:\n\n1. **HDD failing** - needs physical swap (meatspace)\n2. **Scrypted permission errors** - weird errors preventing recording\n3. **HKSV settings** - may be working but need to verify Apple-compatible settings\n\n## Constraints\n- Don't disrupt WiFi telemetry (kube.lan receives it)\n- kube.lan has other duties (Plex, Claude Code Web, HTML tool executor)\n\n## Context\n- Scrypted docs: https://docs.scrypted.app/scrypted-nvr/storage/docker.html\n- kube.md has existing Scrypted setup notes","design":"## Approach\n1. Check Scrypted logs for permission errors\n2. Verify HKSV settings against Apple requirements\n3. Diagnose HDD health (smartctl)\n4. Plan HDD swap procedure\n5. Test recording after fixes\n\n## Open Questions\n- What exactly are the permission errors?\n- Is HKSV recording to iCloud or local?","notes":"## 2026-01-04 Session\n\n### COMPLETED\n- Fixed read-only filesystem on /mnt/6tb (EXT4 journal had aborted)\n- Ran fsck.ext4 -y, repaired ~80 bad blocks, cleared orphan video files\n- Scrypted recording now working (tested container write)\n- Pending sectors: 20 → 14 (some reallocated during fsck)\n\n### KEY FINDINGS\n- WD Red 6TB (WD60EFRX), 4.75 years power-on — end of life\n- Journal errors started today at 11:46\n- Scrypted error \"invalid path or permissions?\" was misleading — real issue was read-only mount\n- Device IDs: 27, 29 = existing cameras, 49 = new G3 doorbell\n\n### IN PROGRESS\n- HKSV \"working (ish)\" but codec settings not verified\n- Need to check H.264/resolution in Scrypted UI for both cameras\n\n### NEXT\n- Filed separate beads for: HKSV verification, drive replacement, SMART monitoring","status":"closed","priority":2,"issue_type":"epic","created_at":"2026-01-04T12:17:53.185864Z","updated_at":"2026-01-04T14:37:21.939185Z","closed_at":"2026-01-04T14:37:21.939185Z"}
{"id":"infra-linux-servers-ojk.1","title":"Verified HKSV codec settings for both cameras","description":"Check H.264/resolution settings in Scrypted UI for devices 27, 29, 49. HKSV requirements: H.264 (not H.265), 1080p/720p/360p, 1-2s keyframe interval, AAC audio.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-04T13:13:01.175077Z","updated_at":"2026-01-04T14:23:59.624786Z","closed_at":"2026-01-04T14:23:59.624786Z","dependencies":[{"issue_id":"infra-linux-servers-ojk.1","depends_on_id":"infra-linux-servers-ojk","type":"parent-child","created_at":"2026-01-04T13:13:01.17709Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-linux-servers-woc","title":"Set up SMART monitoring on kube.lan","description":"Configure smartd to email alerts before drive failure. Package already installed (smartmontools). Edit /etc/smartd.conf, enable service.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-04T13:13:03.639431Z","updated_at":"2026-01-04T13:13:03.639431Z"}
{"id":"infra-mcp-workspace-01t","title":"Fixed bugs and sorted out hygiene through a mild refactor","description":"Bugs discovered during MCP bakeoff comparing Official Google MCP vs our Organic MCP","design":"## Context\nDuring bakeoff on 3 Jan 2026, tested both MCPs head-to-head across 12 scenarios.\nFound 3 bugs in our implementation that need fixing.\n\n## Findings Doc\nClaude Research/MCP Bakeoff - Findings Summary - Jan 2026","acceptance_criteria":"- [ ] Binary format detection returns correct format (not always \"pdf\")\n- [ ] Multi-sheet spreadsheets return all sheets\n- [ ] Drive search includes content search, not just name search","status":"closed","priority":1,"issue_type":"epic","created_at":"2026-01-03T23:21:28.427876Z","updated_at":"2026-01-04T18:14:53.386058Z","closed_at":"2026-01-04T18:14:53.386058Z","close_reason":"All three acceptance criteria complete: (1) Binary format detection fixed in a1h, (2) Multi-sheet spreadsheets fixed in 7k8, (3) Content search fixed in g7u (previous session)"}
{"id":"infra-mcp-workspace-0cu","title":"Add search_workspace() tool for preview-before-commit pattern","design":"New tool returns snippets without creating shortcuts. Modify gather_context() to prefer explicit file_ids. Two-stage funnel: search → review → gather.","notes":"Implemented search_workspace() tool with preview-before-commit pattern. Added snippet extraction for Drive files. Updated workspace-fluency Skill documentation with two-stage pattern. Modified gather_context docstring to recommend search_workspace for exploration.","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-14T18:54:40.298254Z","updated_at":"2025-12-14T19:16:13.569547Z","closed_at":"2025-12-14T19:16:13.569558Z"}
{"id":"infra-mcp-workspace-1a7","title":"Add Calendar primitives (list calendars, list events)","description":"Official MCP has full Calendar CRUD:\n- list, listEvents, getEvent\n- createEvent, updateEvent, deleteEvent\n- respondToEvent, findFreeTime\n\nWe only have check_schedule_health (opinionated audit tool).\nNeed actual calendar manipulation for workplace automation.","design":"## Official MCP Tools\n- calendar_list: List all calendars\n- calendar_listEvents: Get events in date range\n- calendar_getEvent: Get single event details\n- calendar_createEvent: Create new event\n- calendar_updateEvent: Modify existing event\n- calendar_deleteEvent: Remove event\n- calendar_findFreeTime: Find available slots\n- calendar_respondToEvent: Accept/decline invites\n\n## What We Have\n- check_schedule_health: Our opinionated \"Freedom Score\" tool\n- This uses Calendar API internally but doesn't expose CRUD\n\n## Implementation Options\n1. Add all 8 tools (comprehensive, matches Official)\n2. Add core 4: list, create, update, delete (minimal viable)\n3. Add core 4 + findFreeTime (useful for scheduling)\n\n## Integration\ncheck_schedule_health should continue to work.\nNew tools should complement, not replace, the Freedom Score approach.","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-03T23:23:38.099646Z","updated_at":"2026-01-04T20:43:02.668654Z","dependencies":[{"issue_id":"infra-mcp-workspace-1a7","depends_on_id":"infra-mcp-workspace-5ak","type":"parent-child","created_at":"2026-01-03T23:25:28.534413Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-mcp-workspace-29n","title":"Add folder management tools to workspace MCP server","description":"Currently no way to create folders, move files, or organize shortcuts after gather_context runs.\n\nNeed tools for:\n- Creating folders\n- Moving files/shortcuts\n- Organizing existing working sets\n- Cleaning up clutter","design":"New MCP tools to add:\n\n1. create_folder(name, parent_folder_id)\n   - Creates folder in Drive\n   - Returns folder metadata (id, name, webViewLink)\n   - Handles path detection if parent not specified\n\n2. move_files(file_ids: list, destination_folder_id)\n   - Moves multiple files/shortcuts at once\n   - Returns success/failure for each\n   - Handles permission errors gracefully\n\n3. organize_working_set(working_folder_id, containing_folder_name)\n   - Finds all shortcuts in working folder\n   - Creates containing subfolder\n   - Moves shortcuts into it\n   - Cleanup operation for existing clutter\n\n4. delete_shortcuts(shortcut_ids: list, confirm: bool)\n   - Removes shortcuts (not target files)\n   - Safety: requires explicit confirm flag\n   - Returns list of deleted shortcuts\n\nThese enable:\n- Post-hoc organization of messy working sets\n- Manual folder structure creation\n- Cleanup operations\n- Testing folder organization patterns","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-11-12T15:46:54.53442Z","updated_at":"2025-11-12T15:47:26.553536Z","closed_at":"2025-11-12T15:47:26.553536Z"}
{"id":"infra-mcp-workspace-2jz","title":"Add find_my_pattern tool for retrieving email templates","description":"## Context\nDuring Gmail inbox clarify workflow, Claude needed to draft a welcome email matching a previous pattern. This took 3+ tool calls:\n1. search for past welcome emails\n2. get full email to extract format\n3. manually parse recipients, structure, Q\u0026A format\n\n## Proposed Tool\n```\nfind_my_pattern(topic=\"welcome email\", type=\"sent\")\n→ Returns: {\n    template_text: \"...\",\n    typical_recipients: [\"sales-7th-floor-group@itv.com\", ...],\n    attachments_used: [\"photo.jpg\"],\n    format_notes: \"Intro paragraph + 'X writes' section + Q\u0026A bullet list\"\n  }\n```\n\n## Implementation Notes\n- Search sent mail for topic\n- Extract addressee patterns (To, CC, BCC) across matching emails\n- Identify common structure (greeting style, sections, sign-off)\n- Return structured object, not raw email\n\n## Value\n- Single call instead of 3+\n- Captures *intent*: \"I've done this before, show me the pattern\"\n- Enables template-based drafting workflows\n\n## Real Example\nUser asked: \"draft a welcome email for Lauren following the pattern of previous ones\"\nClaude had to: search \"from:me subject:welcome writes\" → get full email → extract CC list → extract Q\u0026A format\nCould be: find_my_pattern(topic=\"new joiner welcome\", type=\"sent\")","design":"## API\n```python\nfind_my_pattern(\n    topic: str,           # e.g. \"welcome email\", \"weekly update\"\n    type: str = \"sent\",   # \"sent\" only for now\n    n: int = 1            # number of emails to analyze (default: most recent)\n) -\u003e {\n    template_text: str,           # full email body\n    typical_recipients: list,     # aggregated To/CC/BCC across n emails\n    attachments_used: list,       # filenames\n    structure: {                  # structural detection, NOT LLM inference\n        greeting_style: str,      # \"Hi [name],\" / \"Team,\" / etc\n        sections: list[str],      # headers/dividers found\n        bullet_patterns: list,    # \"- question? answer\" etc\n        sign_off: str             # \"Best,\" / \"Thanks,\" / etc\n    },\n    variance_note: str | None,    # \"3 matches found, structures vary\" if applicable\n    source_ids: list[str]         # email IDs analyzed (for provenance)\n}\n```\n\n## Implementation\n1. Search sent mail for topic (from:me + topic keywords)\n2. Fetch up to n matching emails\n3. Extract structural elements (greeting, sections, bullets, sign-off) — NO LLM inference\n4. Aggregate recipients across matches\n5. If n\u003e1 and structures vary, note variance but return most recent as primary\n6. Always include source email IDs\n\n## Key Decisions\n- Structural detection only — caller LLM infers \"Q\u0026A format\" from seeing the pattern\n- Most recent as primary, variance flagged if detected\n- Provenance mandatory for \"show me source\" and draft_reply(template_from=...) workflows","acceptance_criteria":"- [ ] Tool returns template_text from most recent matching email\n- [ ] Tool aggregates recipients (To/CC/BCC) across n emails\n- [ ] Tool extracts structural elements: greeting_style, sections, bullet_patterns, sign_off\n- [ ] Tool returns variance_note when n\u003e1 and structures differ\n- [ ] Tool always returns source_ids (email IDs analyzed)\n- [ ] Tool supports n parameter (default 1)\n- [ ] Structural detection only — no LLM inference baked in\n- [ ] Unit tests for structure extraction","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-04T20:44:27.94935Z","updated_at":"2026-01-04T21:30:59.666886Z"}
{"id":"infra-mcp-workspace-2xb","title":"Centralize auth: single credential manager instead of per-call loading","description":"Current: Every tool calls get_credentials() which reads token.json from disk each time.\nOfficial pattern: AuthManager instantiated once at startup, services hold reference.\n\nBenefits of centralizing:\n- Single place for auth logging, metrics, error handling\n- No repeated disk reads (minor perf)\n- Cleaner separation of concerns\n- Easier to add token caching if needed\n\nNot urgent — current approach works — but it's a design smell worth fixing.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-03T23:44:04.15991Z","updated_at":"2026-01-04T12:43:46.429778Z","closed_at":"2026-01-04T12:43:46.429778Z","close_reason":"Created services.py with centralized credential management and service caching","dependencies":[{"issue_id":"infra-mcp-workspace-2xb","depends_on_id":"infra-mcp-workspace-5ak","type":"parent-child","created_at":"2026-01-03T23:44:40.268205Z","created_by":"modha","metadata":"{}"},{"issue_id":"infra-mcp-workspace-2xb","depends_on_id":"infra-mcp-workspace-01t","type":"parent-child","created_at":"2026-01-04T11:27:12.683349Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-mcp-workspace-3qp","title":"Update workspace://patterns/binary-vs-text resource","description":"The binary-vs-text resource may be stale after get_content() ergonomics changes. Should reflect new auto-routing philosophy.","design":"## Current State\nResource explains when to use read_file vs download_file.\n\n## What Changed\n- get_content() now auto-routes — callers don't need to decide\n- Shortcuts auto-resolve\n- Non-exportable types return guidance\n\n## Update Needed\n- Lead with \"use get_content() — it routes automatically\"\n- Keep the primitives documented for edge cases\n- Add the ergonomics principle","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-04T18:22:13.382774Z","updated_at":"2026-01-04T18:36:13.280354Z","closed_at":"2026-01-04T18:36:13.280354Z","close_reason":"Updated workspace://patterns/binary-vs-text resource to reflect get_content() auto-routing philosophy. Now leads with 'Just Use get_content()' instead of explaining separate read_file/download_file tools."}
{"id":"infra-mcp-workspace-53z","title":"Implement get_content() opinionated wrapper","description":"Create unified get_content(file_id, purpose) tool that handles text/binary routing automatically. Replaces read_file + download_file pattern.","design":"Smart wrapper that: (1) Detects file type, (2) Routes to text extraction OR binary download, (3) Returns consistent interface. Server-side intelligence, no 'fail then redirect' pattern.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-18T21:44:38.143095Z","updated_at":"2025-11-18T21:44:38.143095Z","closed_at":"2025-11-10T14:08:19.15287909Z","dependencies":[{"issue_id":"infra-mcp-workspace-53z","depends_on_id":"infra-mcp-workspace-vsp","type":"blocks","created_at":"2025-11-10T11:42:54.551713Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-mcp-workspace-5ak","title":"Bakeoff Jan 2026: Features to Adopt from Official MCP","description":"Features from Official Google MCP that we should adopt or learn from","design":"## Context\nDuring bakeoff, Official MCP showed capabilities we lack.\nThese are enhancements, not bugs - our MCP works, but could do more.\n\n## Philosophy\nKeep our opinionated, LLM-friendly approach.\nAdd coverage where Official excels (Calendar, multi-sheet, table extraction).\n\n## Priority\nCalendar is highest value - completely missing capability.\nTable extraction from Slides is nice-to-have.","acceptance_criteria":"- [ ] Calendar management: list, create, update, delete events\n- [ ] Table data extraction from Slides (not just noting existence)\n- [ ] Consider: Docs CRUD operations (insert, append, replace text)","status":"open","priority":1,"issue_type":"epic","created_at":"2026-01-03T23:23:05.958052Z","updated_at":"2026-01-04T11:19:51.783986Z"}
{"id":"infra-mcp-workspace-5cu","title":"Fix format selection default to markdown","description":"Default format for Google Docs was 'pdf' (binary) causing errors. Should be 'markdown' (text) for token efficiency.","design":"Change line 205 in utils.py: 'default': 'pdf' → 'default': 'markdown'. Also update Sheets default from 'xlsx' to 'csv' for same reason.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-10T11:42:26.829563Z","updated_at":"2025-11-10T11:42:38.024848Z","closed_at":"2025-11-10T11:42:38.024848Z"}
{"id":"infra-mcp-workspace-5xk","title":"Add move_file capability for Google Drive files","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"open","priority":1,"issue_type":"feature","created_at":"2025-12-22T09:50:52.066908Z","updated_at":"2025-12-30T23:09:09.697925Z","dependencies":[{"issue_id":"infra-mcp-workspace-5xk","depends_on_id":"infra-mcp-workspace-5ak","type":"parent-child","created_at":"2026-01-04T11:27:41.411453Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-mcp-workspace-5zh","title":"Implement 'check_schedule_health' calendar tool","design":"Implement strict Exoskeleton audit logic: calculate meeting load, fragmentation, and boundary violations. Return health score 1-10.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-11-22T21:57:30.160476Z","updated_at":"2025-11-22T22:11:13.348448Z","closed_at":"2025-11-22T22:11:13.348451Z"}
{"id":"infra-mcp-workspace-6q3","title":"Add partial document reading to get_content()","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"open","priority":1,"issue_type":"feature","created_at":"2025-12-22T21:45:37.51133Z","updated_at":"2026-01-04T20:42:57.536251Z","dependencies":[{"issue_id":"infra-mcp-workspace-6q3","depends_on_id":"infra-mcp-workspace-5ak","type":"parent-child","created_at":"2026-01-04T11:27:36.273958Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-mcp-workspace-74h","title":"Handle nested brackets in link text","description":"Current escaping handles [text] but not [text with [nested] brackets].\n\nEdge case - rare in practice but could break markdown parsing if encountered.\n\nMay need recursive escaping or different approach.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-05T20:39:09.689113Z","updated_at":"2026-01-05T20:39:09.689113Z"}
{"id":"infra-mcp-workspace-7k8","title":"Fix multi-sheet spreadsheet handling - only returns first sheet","description":"get_content() on Google Sheets only returns the first sheet as CSV. Multi-sheet spreadsheets lose data.","design":"## Comparison\nOfficial MCP (sheets_getText): Returns ALL sheets with \"Sheet Name: X\" headers\nOrganic MCP (get_content): Returns only first sheet as CSV\n\n## Options\n1. Return all sheets concatenated with headers (like Official)\n2. Return xlsx binary for multi-sheet (triggers xlsx Skill)\n3. Add sheet selection parameter\n4. Return metadata indicating multiple sheets exist\n\n## Recommendation\nOption 1 for text mode, with metadata showing sheet count.\nFor purpose='archival', use option 2 (xlsx binary).","notes":"NEXT UP: Multi-sheet spreadsheet handling - only returns first sheet","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-03T23:22:39.03053Z","updated_at":"2026-01-04T18:14:26.702897Z","closed_at":"2026-01-04T18:14:26.702897Z","close_reason":"Created sheets.py with read_sheets_as_csv() using Sheets API. Now extracts ALL sheets with headers, not just first sheet. Metadata includes sheet_count and sheet names list.","dependencies":[{"issue_id":"infra-mcp-workspace-7k8","depends_on_id":"infra-mcp-workspace-01t","type":"parent-child","created_at":"2026-01-03T23:25:18.237643Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-mcp-workspace-8qt","title":"Add tests for Google API error pattern detection","description":"The error detection in get_content() uses string matching ('404' in error_msg). Add tests with realistic Google API error strings to verify the patterns work. Consider parsing actual exception types for robustness.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-04T21:15:04.480126Z","updated_at":"2026-01-04T21:15:04.480126Z"}
{"id":"infra-mcp-workspace-a0l","title":"Add consistent error handling pattern across all tools","description":"Official MCP pattern: Each service has handleError() method.\n\ndef handle_error(error, context: str):\n    logger.error(f\"Error during {context}: {error}\")\n    return {\"error\": str(error), \"context\": context}\n\nBenefits:\n- Consistent error format for Claude to parse\n- Centralized logging\n- Context about which operation failed\n\nCurrently our error handling is scattered and inconsistent.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-03T23:49:06.961952Z","updated_at":"2026-01-04T12:44:05.578646Z","closed_at":"2026-01-04T12:44:05.578646Z","close_reason":"Added handle_api_error() and format_error_response() to utils.py","dependencies":[{"issue_id":"infra-mcp-workspace-a0l","depends_on_id":"infra-mcp-workspace-5ak","type":"parent-child","created_at":"2026-01-03T23:49:23.863544Z","created_by":"modha","metadata":"{}"},{"issue_id":"infra-mcp-workspace-a0l","depends_on_id":"infra-mcp-workspace-01t","type":"parent-child","created_at":"2026-01-04T11:27:22.965609Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-mcp-workspace-a1h","title":"Fix binary format detection - always reports 'pdf'","description":"get_content() returns format:'pdf' for xlsx, pptx, and other binary files. The mimeType is correct but format field is wrong.","design":"## Location\nLikely in the format detection logic of get_content()\n\n## Expected Behavior\n- xlsx files → format: \"xlsx\"\n- pptx files → format: \"pptx\"  \n- pdf files → format: \"pdf\"\n- docx files → format: \"docx\"\n\n## Evidence\nTest 7 (xlsx): format: \"pdf\", mimeType: \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"\nTest 8 (pptx): format: \"pdf\", mimeType: \"application/vnd.openxmlformats-officedocument.presentationml.presentation\"","notes":"COMPLETED: Fixed format detection for all file types:\n\n1. Binary files (xlsx, pptx, docx, pdf, images): Now report correct format instead of always 'pdf'\n2. Google Drawings: Added proper format mapping, defaults to SVG (text-based)\n3. Non-exportable types (Forms, Sites, Scripts, Shortcuts, Folders, Colab): Return marker formats with helpful error messages\n4. SVG: Removed from binary list since it's XML text, now properly decoded\n\nKEY DECISION: Fallback for truly unknown MIME types changed from 'pdf' to extracted subtype (e.g., 'application/zip' → 'zip')","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-03T23:22:33.081806Z","updated_at":"2026-01-04T17:31:58.141482Z","closed_at":"2026-01-04T17:26:18.355052Z","close_reason":"Fixed select_optimal_format() in utils.py to recognize binary file MIME types (xlsx, pptx, docx, pdf, images). Also added smart subtype extraction for unknown MIME types. Tests updated and passing.","dependencies":[{"issue_id":"infra-mcp-workspace-a1h","depends_on_id":"infra-mcp-workspace-01t","type":"parent-child","created_at":"2026-01-03T23:25:13.091391Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-mcp-workspace-byw","title":"Add shared validation schemas (Zod patterns for emails, dates, IDs)","description":"Official MCP pattern: Reusable Zod schemas for common input types.\n\nExamples:\n- iso8601DateTimeSchema (validates datetime format)\n- emailArraySchema (single email or array)  \n- googleDocumentIdSchema (alphanumeric with hyphens/underscores)\n- calendarIdSchema ('primary' or email)\n\nBenefits: Define once, validate consistently, better error messages.\nLow effort, improves robustness.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-03T23:48:54.587844Z","updated_at":"2026-01-04T12:43:58.86282Z","closed_at":"2026-01-04T12:43:58.86282Z","close_reason":"Created validation.py with email, calendar ID, date, and page size validators","dependencies":[{"issue_id":"infra-mcp-workspace-byw","depends_on_id":"infra-mcp-workspace-5ak","type":"parent-child","created_at":"2026-01-03T23:49:18.726345Z","created_by":"modha","metadata":"{}"},{"issue_id":"infra-mcp-workspace-byw","depends_on_id":"infra-mcp-workspace-01t","type":"parent-child","created_at":"2026-01-04T11:27:17.826641Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-mcp-workspace-ch0","title":"Google Docs comment extraction","description":"Extract comments from Google Docs via Drive API comments.list(). Neither our MCP nor Google's official MCP currently handles this.\n\nContext from exploration:\n- Comments are via Drive API, not Docs API\n- Requires separate API call: drive.comments().list(fileId)\n- Comments have anchor positions (character ranges in doc)\n- Need to decide output format: inline markers vs section at end\n\nOptions considered:\n1. Quick: Append comments as section at end (no position mapping)\n2. Full: Inline markers with definitions (like footnotes)\n\nReferences:\n- Google API: https://developers.google.com/workspace/drive/api/guides/manage-comments\n- Test doc with comment: 1hUbfIpP6HjSIBRMNW8RxQuVhQFGKP0EwWgtQNAw19N0","notes":"Test doc with comment: 1hUbfIpP6HjSIBRMNW8RxQuVhQFGKP0EwWgtQNAw19N0 (Markdown Edge Cases)","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-05T20:30:00.588454Z","updated_at":"2026-01-05T20:38:31.59573Z"}
{"id":"infra-mcp-workspace-dad","title":"Implement subagent testing infrastructure (Phase 3)","description":"Test framework for validating MCP tools with Claude subagents. Verify agents can use opinionated tools efficiently.","design":"Per 2025-10-24 design doc Phase 3: (1) Create test scenarios, (2) Launch subagents with MCP server, (3) Measure token usage and success rate, (4) Iterate on tool design based on results.","notes":"Subagent testing validated:\n1. search_workspace() is used for exploration (not gather_context)\n2. Snippets return actual content (async bug fixed)\n3. Local-first guidance is followed (Read tool for ~/Google Drive files)\n4. Subagents quote the docstring guidance when explaining decisions\n\nBugs found and fixed during testing:\n- Async snippet extraction (coroutine objects returned)\n- Export format not passed to download_file (PDF instead of PPTX)\n- Speaker notes path in Slides API\n\nApproach: Spawn subagents with Task tool, give them scenarios, verify they follow the documented patterns.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-18T21:44:38.14352Z","updated_at":"2025-12-14T20:11:38.992895Z","closed_at":"2025-12-14T20:11:38.992904Z","dependencies":[{"issue_id":"infra-mcp-workspace-dad","depends_on_id":"infra-mcp-workspace-go3","type":"blocks","created_at":"2025-11-10T11:43:30.029467Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-mcp-workspace-eab","title":"Accept URLs or IDs in tool inputs (input normalization)","description":"Official MCP pattern: Tools accept either file ID or full Google URL, normalize internally.\n\nExample from Official:\n  presentationId: 'The ID or URL of the presentation'\n  → Service extracts ID if given URL\n\nReduces cognitive load on Claude — just pass whatever you have.\nCurrently our tools require bare IDs, so Claude must extract IDs from URLs first.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-03T23:44:28.49963Z","updated_at":"2026-01-04T12:43:53.011924Z","closed_at":"2026-01-04T12:43:53.011924Z","close_reason":"Created validation.py with extract_file_id() for URL/ID normalization","dependencies":[{"issue_id":"infra-mcp-workspace-eab","depends_on_id":"infra-mcp-workspace-5ak","type":"parent-child","created_at":"2026-01-03T23:44:45.404814Z","created_by":"modha","metadata":"{}"},{"issue_id":"infra-mcp-workspace-eab","depends_on_id":"infra-mcp-workspace-01t","type":"parent-child","created_at":"2026-01-04T11:27:07.533086Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-mcp-workspace-eau","title":"gather_context should create containing folders, not dump shortcuts in root","description":"Currently gather_context creates shortcuts directly in working folder (e.g., \"0 Inbox\"), resulting in 20+ loose shortcuts cluttering the root.\n\nShould create a containing subfolder with sensible name based on topic + date, matching ~/Repos pattern of organizing related files in subfolders.\n\nExample: \"TVA Contract Review - Nov 2025/\" containing all shortcuts","design":"Pattern from user's ~/Repos:\n- docs/plans/2025-10-24-opinionated-tools-refactor.md\n- Containing folders for related files\n\nApply to Drive shortcuts:\n- 0 Inbox/TVA Contract Review - Nov 2025/ (containing folder)\n  - Advice Note (shortcut)\n  - Contract (shortcut)\n  - Legal Memo (shortcut)\n\nImplementation in gather_context:\n1. Determine base folder (path detection or explicit)\n2. Create containing folder: f\"{topic} - {datetime.now().strftime('%b %Y')}\"\n3. Create shortcuts in containing folder (not root)\n\nReturn path info: \"0 Inbox/TVA Contract Review - Nov 2025\"","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-11-12T15:46:54.351905Z","updated_at":"2025-11-12T17:17:08.957436Z","closed_at":"2025-11-12T17:17:08.957436Z"}
{"id":"infra-mcp-workspace-fqg","title":"INVESTIGATE: Shortcuts created by MCP server have permission issues","description":"gather_context creates shortcuts via OAuth, but user cannot move those shortcuts in Drive UI.\n\nError: \"Can't move 'Advice Note re: TVA Collector Agreement - 30 October 2025.gdoc' because you don't have access to move this file.\"\n\nThis is a critical UX issue - shortcuts should be fully manageable by the user.","design":"Investigate three theories:\n\nTheory 1: Shortcut ownership\n- Shortcuts owned by OAuth app, not user account\n- Check: Who is listed as owner in Drive API metadata?\n- Solution: Ensure shortcuts created with user as owner\n\nTheory 2: Target file permissions\n- Shortcuts point to files user doesn't own (legal docs from colleagues)\n- Drive prevents moving shortcuts to restricted targets\n- Check: Can user move shortcuts to files they DO own?\n\nTheory 3: Folder permissions\n- \"0 Inbox\" folder has weird permissions from MCP creation\n- Check: Folder ACLs and effective permissions\n\nInvestigation steps:\n1. Query shortcut metadata: owner, permissions, ACLs\n2. Query target file metadata: owner, user's role\n3. Test creating shortcuts to user-owned files\n4. Test moving those shortcuts manually\n5. Compare with shortcuts created manually in Drive UI\n\nIf app ownership is the issue:\n- Research Drive API transferOwnership option\n- Consider creating shortcuts with user delegation\n- Document in workspace-fluency SKILL.md as limitation","notes":"INVESTIGATION 2025-11-18 (Gemini):\n1. Created repro script 'repro_shortcut_bug.py' to test shortcut creation via API.\n2. Tested creating shortcuts in '0 Inbox' and 'My Drive Root'.\n3. Tested targeting both owned files and shared files (owned by others).\n4. RESULT: In ALL cases, the API reports 'canMoveItemWithinDrive': True for the created shortcut.\n5. CONCLUSION: The API permissions are correct. The UI error 'You don't have access to move this file' is likely due to:\n   - Transient propagation delay.\n   - UI-specific caching or multi-account confusion.\n   - The '0 Inbox' folder itself having specific ACLs that the API isn't revealing in the capabilities summary.\n\nNEXT STEPS:\n- Close this bug as 'Cannot Reproduce' (API side).\n- If it happens again, verify if the user is trying to move the FOLDER or the SHORTCUT.\n- Consider implementing the 'move_files' tool (infra-mcp-workspace-g5l) as a workaround - if UI fails, CLI might succeed.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-11-18T21:44:38.143982Z","updated_at":"2025-11-22T21:57:35.086296Z","closed_at":"2025-11-22T21:57:35.086298Z"}
{"id":"infra-mcp-workspace-fql","title":"Field Report: Direct markdown approach beats Official's HTML intermediate step","description":"Bakeoff finding: Our direct markdown-to-Google-Docs conversion produces higher quality output than Official MCP's approach.\n\nOfficial approach:\n  markdown → marked (HTML) → jsdom (DOM) → Docs API formatting requests\n\nOur approach:\n  markdown → Google Drive import API (native markdown support)\n\nThe HTML intermediate step loses fidelity. Google's native markdown import is better.\n\nThis is a WIN for Organic MCP. Don't adopt their pattern here.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-03T23:49:41.486084Z","updated_at":"2026-01-04T11:26:11.730583Z","closed_at":"2026-01-04T11:26:11.730583Z","close_reason":"Field report, not actionable","labels":["field-report"]}
{"id":"infra-mcp-workspace-g5l","title":"Add folder management tools to workspace MCP server","description":"Currently no way to create folders, move files, or organize shortcuts after gather_context runs.\n\nNeed tools for:\n- Creating folders\n- Moving files/shortcuts\n- Organizing existing working sets\n- Cleaning up clutter","design":"New MCP tools to add:\n\n1. create_folder(name, parent_folder_id)\n   - Creates folder in Drive\n   - Returns folder metadata (id, name, webViewLink)\n   - Handles path detection if parent not specified\n\n2. move_files(file_ids: list, destination_folder_id)\n   - Moves multiple files/shortcuts at once\n   - Returns success/failure for each\n   - Handles permission errors gracefully\n\n3. organize_working_set(working_folder_id, containing_folder_name)\n   - Finds all shortcuts in working folder\n   - Creates containing subfolder\n   - Moves shortcuts into it\n   - Cleanup operation for existing clutter\n\n4. delete_shortcuts(shortcut_ids: list, confirm: bool)\n   - Removes shortcuts (not target files)\n   - Safety: requires explicit confirm flag\n   - Returns list of deleted shortcuts\n\nThese enable post-hoc organization, manual folder creation, cleanup operations, and testing folder patterns.","notes":"No longer needed: search_workspace() enables preview-before-commit pattern. Users won't have shortcut clutter if they use the two-stage flow. Manual folder management not worth the complexity.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-11-18T21:44:38.144385Z","updated_at":"2025-12-14T19:40:42.352328Z","closed_at":"2025-12-14T19:40:42.352334Z","dependencies":[{"issue_id":"infra-mcp-workspace-g5l","depends_on_id":"infra-mcp-workspace-fqg","type":"related","created_at":"2025-11-12T15:47:11.168462Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-mcp-workspace-g7u","title":"Scoring algorithm buries content matches behind title matches","description":"We DO have fullText search (gather.py:275) but score_relevance() weights title matches at 50% and gives content-only matches 0% boost. A folder named \"MIT Manual\" scores 0.6+ while a doc containing \"MIT Manual\" in body scores only 0.15.\n\nOptions:\n1. Return Google's results unranked (simplest - trust Google's relevance)\n2. Rebalance scoring to give content matches fair weight\n3. Offer both modes (ranked vs raw)\n\nRoot cause: Over-engineering. We added a relevance layer that's worse than Google's.","design":"## Current Behavior\nsearch_workspace(topic=\"measurement\") → finds folders named \"measurement\"\n\n## Expected Behavior  \nsearch_workspace(topic=\"measurement\") → finds files CONTAINING \"measurement\"\n\n## Google Drive API\nOfficial uses: fullText contains 'measurement'\nWe might be using: name contains 'measurement'\n\n## Implementation\nCheck how we build the Drive API query in search_workspace()\nAdd fullText search, possibly keep name search as fallback or combine.\n\n## Trade-off\nfullText search is slower but more useful for discovery.\nName search is faster but only for navigation.\nConsider: search both, rank fullText matches higher?","notes":"COMPLETED: Two commits for this fix:\n1. First rebalanced scoring weights (content +20%, title reduced to 25%)\n2. Then simplified further: removed scoring entirely, trust Google's ranking\n\nFinal approach: fullText first (Google order), name matches appended at end.\nRemoved 95 lines of scoring logic.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-03T23:22:45.239375Z","updated_at":"2026-01-04T13:44:16.763773Z","closed_at":"2026-01-04T13:25:48.840424Z","close_reason":"Rebalanced scoring: content matches now 20% boost (was 0%), title matches reduced to 25% (was 50%)","dependencies":[{"issue_id":"infra-mcp-workspace-g7u","depends_on_id":"infra-mcp-workspace-01t","type":"parent-child","created_at":"2026-01-03T23:25:23.385165Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-mcp-workspace-go3","title":"Create workspace-fluency Skill (Phase 2)","description":"Skill for Claude Sonnet to orchestrate multi-step context assembly workflows. Uses opinionated MCP tools for 'Work Fluency Infrastructure'.","design":"Per 2025-10-24 design doc Phase 2: Skill provides: (1) Multi-step workflow coordination, (2) Smart retry logic, (3) Context prioritization. Built after Phase 1 refactor complete.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-18T21:44:38.144829Z","updated_at":"2025-11-18T21:44:38.144829Z","closed_at":"2025-11-10T23:00:13.101898371Z","dependencies":[{"issue_id":"infra-mcp-workspace-go3","depends_on_id":"infra-mcp-workspace-vsp","type":"blocks","created_at":"2025-11-10T11:43:22.810739Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-mcp-workspace-go3","depends_on_id":"infra-mcp-workspace-53z","type":"blocks","created_at":"2025-11-10T11:43:22.811065Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-mcp-workspace-j4c","title":"Improve document editing ergonomics","description":"## Context\n\nTested the google-workspace MCP's doc editing tools while adding image placeholders to a consolidated onboarding guide. The tools work but the ergonomics are limited compared to what a higher-level abstraction could offer.\n\n## Current State\n\nAvailable tools:\n- `docs_insertText` — insert at beginning only\n- `docs_appendText` — append at end only  \n- `docs_replaceText` — find/replace all occurrences\n\n### What Works\n- `replaceText` is effective for surgical insertions if you find unique anchor strings\n- Batching multiple replacements in parallel is efficient\n- The actual replacement mechanics are solid\n\n### What's Ropey\n1. **No positional insertion** — can only insert at beginning, append at end, or find-replace. If you want to add something after a paragraph that isn't unique text, you're stuck.\n2. **Must read first** — need to see exact text to find a unique anchor. Can't say 'after section 2' or 'after the 3rd heading'.\n3. **No visibility into structure** — can't target 'the 3rd bullet point' or 'after the table'. It's all string matching.\n4. **Workaround pattern** — find unique sentence near insertion point → replace with same sentence + addition. Works but feels like picking locks rather than using keys.\n\n## Ideal Ergonomics\n\nFor an MCP abstracting the raw APIs, document editing should feel more like how humans think about editing:\n\n### 1. Structural Navigation\n```\ndocs_insertAfter(documentId, anchor, text)\n  anchor options:\n    - { heading: 'Section Name' }\n    - { heading_level: 2, index: 3 }  // 3rd H2\n    - { paragraph_containing: 'unique text' }\n    - { after_table: 1 }  // after first table\n    - { end_of_section: 'Section Name' }\n```\n\n### 2. Structural Awareness  \n```\ndocs_getStructure(documentId)\n  returns:\n    - headings with levels and positions\n    - tables with row/col counts\n    - lists with nesting\n    - images/embeds\n```\n\nThis lets Claude understand the doc shape before editing.\n\n### 3. Safe Multi-Edit\n```\ndocs_batchEdit(documentId, edits[])\n  edits applied in reverse document order to preserve positions\n  atomic: all succeed or none\n```\n\n### 4. Section Operations\n```\ndocs_replaceSection(documentId, sectionName, newContent)\ndocs_appendToSection(documentId, sectionName, content)\n```\n\n## Implementation Notes\n\nThe Google Docs API does support positional operations via startIndex/endIndex, but:\n- Requires knowing exact character positions\n- Positions shift as edits are made\n- The raw API is complex (batchUpdate with requests array)\n\nThe abstraction layer should:\n1. Use `docs_getStructure` internally to map anchors to positions\n2. Handle position arithmetic for multi-edit batches\n3. Expose human-readable anchoring to Claude\n\n## Acceptance Criteria\n\n- [ ] Can insert text after a heading by name\n- [ ] Can get document structure (headings, tables, lists)\n- [ ] Can append to a named section\n- [ ] Batch edits work without position drift issues","status":"open","priority":3,"issue_type":"feature","created_at":"2026-01-05T12:27:40.367466Z","updated_at":"2026-01-05T12:27:40.367466Z"}
{"id":"infra-mcp-workspace-jo1","title":"Reference: Bakeoff Architecture Deep Dive (Jan 2026)","description":"Full analysis doc: https://docs.google.com/document/d/10A7CxDQOrnU-_pkOfQp8c6nEUhk2QflHGoHKFUH1K5M/edit\n\nCompares Official Google Workspace MCP vs Organic (this repo):\n- 50 vs 16 tools\n- Coverage gaps (Calendar CRUD, Chat)\n- Architectural patterns (auth, validation, error handling)\n- What to adopt vs what to keep\n\nLinks both bug fix and feature epics.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-03T23:55:18.058366Z","updated_at":"2026-01-04T11:26:06.562892Z","closed_at":"2026-01-04T11:26:06.562892Z","close_reason":"Reference doc, not actionable","labels":["reference"]}
{"id":"infra-mcp-workspace-l51","title":"Measure actual token cost before/after refactor","description":"Measure current token cost of all exposed tools. Compare to target (~1k tokens). Track reduction through refactor.","design":"Use Claude's context info to measure actual token usage. Baseline: ~22.5k tokens (estimated). Target: ~1k tokens (5-7 tools × ~200 tokens). Success metric: 95% reduction.","notes":"Final measurement: 16 tools, ~6,221 tokens (72.4% reduction from 22.5k baseline). Good enough - diminishing returns beyond this.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-18T21:44:38.145253Z","updated_at":"2025-12-14T19:40:42.230284Z","closed_at":"2025-12-14T19:40:42.230294Z"}
{"id":"infra-mcp-workspace-n0i","title":"Reference-style markdown links for token efficiency","description":"For docs with many repeated URLs, use reference-style links:\n[text][1] instead of [text](url)\n\nWith definitions at end:\n[1]: https://example.com\n\nWould reduce token count for link-heavy docs. Lower priority - current inline style works fine.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-05T20:38:57.567748Z","updated_at":"2026-01-05T20:38:57.567748Z"}
{"id":"infra-mcp-workspace-n4z","title":"Consider: Add Docs text manipulation (insert, append, replace)","description":"Official MCP has docs_insertText, docs_appendText, docs_replaceText. We only have create_doc_from_markdown.","design":"## Official MCP Tools\n- docs_insertText: Insert at beginning\n- docs_appendText: Append to end\n- docs_replaceText: Find/replace text\n\n## What We Have\n- create_doc_from_markdown: Create new doc only\n- No modification of existing docs\n\n## Question\nDo we need this? Our philosophy is:\n- Assemble context (read many sources)\n- Create artifacts (new docs from synthesis)\n- NOT: incrementally modify existing docs\n\n## When It Would Help\n- Appending session notes to a running doc\n- Programmatic doc updates (template filling)\n- Collaborative editing patterns\n\n## Recommendation\nLower priority. Our create-from-markdown works well.\nConsider only if use cases emerge.","status":"closed","priority":3,"issue_type":"feature","created_at":"2026-01-03T23:23:52.057488Z","updated_at":"2026-01-04T11:26:01.422259Z","closed_at":"2026-01-04T11:26:01.422259Z","close_reason":"Not worth it","dependencies":[{"issue_id":"infra-mcp-workspace-n4z","depends_on_id":"infra-mcp-workspace-5ak","type":"parent-child","created_at":"2026-01-03T23:25:38.837011Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-mcp-workspace-omk","title":"Fix guidance discoverability - inline hints in tool docstrings","design":"Add local-first and binary-vs-text hints to get_content() and gather_context() docstrings. Update workspace-fluency Skill. Test with adversarial prompts.","notes":"Completed: Added inline hints to get_content() and gather_context() docstrings. Updated workspace-fluency Skill with Local vs Remote File Access section.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-14T18:54:40.02731Z","updated_at":"2025-12-14T19:36:51.254607Z","closed_at":"2025-12-14T19:36:51.254612Z"}
{"id":"infra-mcp-workspace-pob","title":"Validate Slides extraction quality","design":"Test with real presentation. Check speaker notes, image handling, formatting. Document findings.","notes":"Tested and validated Slides extraction. Found and fixed bug: speaker notes were not being extracted because code looked at slide.notesPage instead of slide.slideProperties.notesPage. Now working correctly - extracts text, speaker notes, tables, images, videos.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T18:54:40.552484Z","updated_at":"2025-12-14T19:15:44.209371Z","closed_at":"2025-12-14T19:15:44.209386Z"}
{"id":"infra-mcp-workspace-r4z","title":"Extract table data from Slides (not just note existence)","description":"When reading Slides, we mark [TABLE] 6x6 but don't extract content. Official extracts actual table data.","design":"## Current Behavior\nOrganic: \"[TABLE] 6x6 table\" - just notes existence\nOfficial: Shows actual table content with headers/rows\n\n## Slides API\nTables in Slides have table.tableRows with cells containing text.\nWe're detecting tables but not extracting cell content.\n\n## Implementation\nIn our Slides → structured text conversion:\n1. Detect TABLE elements (already doing this)\n2. Extract tableRows and cell text\n3. Format as markdown table or structured text\n\n## Trade-off\nMore verbose output but more useful.\nCould add flag: include_table_content=True/False","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-03T23:23:44.879605Z","updated_at":"2026-01-04T17:54:17.227187Z","closed_at":"2026-01-04T17:54:17.227187Z","close_reason":"Tables now fully extracted as markdown tables instead of just [TABLE] 6x4 flags. Added _extract_table_content() and _format_table_as_markdown() functions.","dependencies":[{"issue_id":"infra-mcp-workspace-r4z","depends_on_id":"infra-mcp-workspace-5ak","type":"parent-child","created_at":"2026-01-03T23:25:33.683509Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-mcp-workspace-raf","title":"Update workspace://patterns/export-formats resource","description":"Resource may have stale guidance from before get_content() auto-routing. Check for old tool names and update to reflect current architecture.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-04T21:14:59.329351Z","updated_at":"2026-01-04T21:14:59.329351Z"}
{"id":"infra-mcp-workspace-se7","title":"Add unit tests for get_content() routing logic","description":"get_content() now has complex routing: shortcuts, non-exportable types, Sheets multi-tab, Slides structured. Needs test coverage.","design":"## Test Cases Needed\n1. Shortcut → auto-resolves to target\n2. Shortcut to shortcut → recursive resolution\n3. Broken shortcut → error response\n4. Google Form → content_type: not_exportable\n5. Google Site → content_type: not_exportable  \n6. Multi-sheet spreadsheet → all sheets extracted\n7. Slides → structured extraction with tables\n\n## Approach\nMock the Google APIs, test the routing logic in isolation.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-04T18:21:58.970741Z","updated_at":"2026-01-04T18:34:01.723736Z","closed_at":"2026-01-04T18:34:01.723736Z","close_reason":"Added 15 unit tests for get_content() routing: shortcuts, non-exportable types, Slides/Sheets special cases, text vs binary routing, truncation handling"}
{"id":"infra-mcp-workspace-tsf","title":"Add Chat integration (spaces, messages, DMs)","description":"Official MCP has full Chat API coverage:\n- listSpaces, findSpaceByName\n- sendMessage, getMessages\n- sendDm, findDmByEmail\n- listThreads, setUpSpace\n\nWe have nothing. This is a significant gap for workplace automation.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-03T23:54:33.990999Z","updated_at":"2026-01-04T11:25:56.284547Z","closed_at":"2026-01-04T11:25:56.284547Z","close_reason":"Not needed - don't use Chat","dependencies":[{"issue_id":"infra-mcp-workspace-tsf","depends_on_id":"infra-mcp-workspace-5ak","type":"parent-child","created_at":"2026-01-03T23:54:57.567072Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-mcp-workspace-uge","title":"Update CLAUDE.md with refactor design","description":"CLAUDE.md still documents old primitive tool architecture. Update to reflect opinionated refactor plan and current state.","design":"Add section on: (1) Token efficiency as PRIMARY constraint, (2) Reference 2025-10-24 design doc, (3) Current state vs target (17 tools → 5-7), (4) What's implemented (gather_context, batch_analyze_files) vs remaining work.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-18T21:44:38.145668Z","updated_at":"2025-11-18T21:44:38.145668Z","closed_at":"2025-11-10T14:38:09.135346387Z"}
{"id":"infra-mcp-workspace-vct","title":"Add find_my_link tool for retrieving URLs from sent mail","description":"## Context\nDuring Gmail clarify workflow, Claude needed to find the Outcomes Planner URL that had been shared before. This took 5+ searches:\n1. \"outcomes planner\" - got meeting docs, not the URL\n2. \"todoist invitation\" - wrong tool entirely\n3. various attempts excluding Google doc URLs\n4. finally found it by searching for domain pattern\n\n## Proposed Tool\n```\nfind_my_link(keyword=\"outcomes planner\", domain_hint=\"itv.com\")\n→ Returns: [\n    {url: \"http://outcomes-planner.itv.com/\", context: \"Staging version email to Caroline\", date: \"2025-07-14\"},\n    ...\n  ]\n```\n\n## Implementation Notes\n- Search sent mail (from:me) for keyword\n- Extract URLs from email bodies\n- Filter by domain_hint if provided\n- Exclude common noise: docs.google.com, meet.google.com, drive.google.com, maps.google.com\n- Return with context snippet showing how URL was used\n\n## Value\n- Single call instead of 5+ search iterations\n- Knows to exclude Google infrastructure URLs by default\n- Returns the *URL* not the email - that's what user actually wants\n\n## Real Example\nUser asked: \"draft reply pointing Elliott to the outcomes planner URL - but I can't remember it\"\nClaude had to: search 5+ variations → get emails → scan for URLs → filter out Google URLs\nCould be: find_my_link(keyword=\"outcomes planner\", domain_hint=\"itv.com\")\n\n## Edge Cases\n- Multiple URLs in same email: return all with position/context\n- URL shorteners (bit.ly): maybe expand? or just return as-is\n- Dead links: not our problem, just return what was sent","design":"## API\n```python\nfind_my_link(\n    keyword: str,                    # search term\n    domain_hint: str | None = None,  # filter to specific domain\n    limit: int = 10                  # max results\n) -\u003e list[{\n    url: str,\n    last_sent: str,          # ISO date\n    times_sent: int,         # dedupe count\n    context: str             # sentence containing URL, max ~200 chars\n}]\n```\n\n## Implementation\n1. Search sent mail (from:me) for keyword\n2. Extract URLs from email bodies (NOT attachments)\n3. Filter out Google infrastructure: docs.google.com, meet.google.com, drive.google.com, maps.google.com\n4. Apply domain_hint filter if provided\n5. Deduplicate by URL, keep most recent instance, count occurrences\n6. Extract surrounding sentence for context (max ~200 chars)\n7. Return up to limit results, sorted by last_sent descending\n\n## Key Decisions\n- Email body only — attachments are expensive to parse, different problem\n- Default excludes Google URLs — that's the noise I had to filter manually\n- Dedupe by URL, return count — if you need all instances, use normal search\n- Sentence context, not N chars — more semantically meaningful\n- No pagination — 50+ sends means you know the URL","acceptance_criteria":"- [ ] Tool searches sent mail (from:me) for keyword\n- [ ] Tool extracts URLs from email body only (not attachments)\n- [ ] Tool excludes Google infrastructure URLs by default (docs/meet/drive/maps.google.com)\n- [ ] Tool filters by domain_hint when provided\n- [ ] Tool deduplicates by URL, returns most recent with times_sent count\n- [ ] Tool extracts sentence context (~200 chars max)\n- [ ] Tool respects limit parameter (default 10)\n- [ ] Tool returns results sorted by last_sent descending\n- [ ] Unit tests for URL extraction and filtering","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-04T20:44:49.117891Z","updated_at":"2026-01-04T21:31:12.906273Z"}
{"id":"infra-mcp-workspace-vsp","title":"Hide primitive Drive tools - make internal only","description":"Expose only 5-7 opinionated high-level tools. Hide primitives (list_files, get_metadata, etc.) as internal functions not decorated with @mcp.tool()","design":"Per 2025-10-24 design doc: Target 95% token reduction (23.7k → ~1k tokens). Primitives should be internal implementation details, not part of public MCP interface.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-11-18T21:44:38.14605Z","updated_at":"2025-11-18T21:44:38.14605Z","closed_at":"2025-11-10T14:05:58.063168498Z"}
{"id":"infra-mcp-workspace-wdc","title":"Wire validation.py into tools (extract_file_id, handle_api_error)","description":"validation.py and error handling utilities exist but are orphaned:\n\n**Unused functions:**\n- extract_file_id() - tools still require bare IDs, Claude must extract from URLs\n- is_valid_email(), normalize_email() - not called anywhere\n- handle_api_error(), format_error_response() - 20+ exception handlers don't use them\n\n**To wire in:**\n1. Add `file_id = extract_file_id(file_id)` at entry points of get_content, get_file_metadata, etc.\n2. Replace scattered `except Exception as e` blocks with handle_api_error()\n3. Consider validation for email inputs in contacts tools\n\nFiled during hygiene audit - infrastructure exists, just needs integration.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-04T13:20:30.792669Z","updated_at":"2026-01-04T20:49:17.959839Z","closed_at":"2026-01-04T20:49:17.959839Z","close_reason":"Wired extract_file_id() into get_content, batch_analyze_files, create_doc_from_markdown. Extended URL pattern for folders. Added 11 validation tests."}
{"id":"infra-mcp-workspace-xfi","title":"Add get_slide_thumbnail() tool for per-slide visual context","description":"Middle ground between text-only extraction and full PDF export. Slides API has presentations.pages.getThumbnail for individual slide images.","design":"## Approach\nExtend get_content() for Slides files when purpose=\"visual-analysis\":\n1. Structured extraction (current behavior)\n2. Plus SMALL thumbnails for slides that have visual content AND are not single-large-image\n3. Return both in one payload\n\n## Heuristics for \"worth thumbnailing\"\n- Chart objects: YES (explicitly tagged, high value)\n- Multiple shapes (5+): YES (likely diagram)\n- Single large image filling slide: NO (likely hero photo/stock)\n- Background images: Hard to detect, accept some noise\n\n## API Integration\nSlides API: presentations.pages.getThumbnail\n- Size options: SMALL (default), MEDIUM, LARGE\n- Returns PNG image data\n- Need to base64 encode for JSON response\n\n## Token Budget\nSMALL thumbnails ≈ 85 tokens each at ~512px\nAcceptable overhead for visual context\n\n## Response Shape\n```python\n{\n  \"slides\": [...],  # existing structured extraction\n  \"thumbnails\": {\n    \"2\": {\"image_base64\": \"...\", \"reason\": \"chart\"},\n    \"5\": {\"image_base64\": \"...\", \"reason\": \"shapes\"},\n    # slide 7 skipped: single_large_image\n  },\n  \"skipped\": {\n    \"7\": \"single_large_image\"\n  }\n}\n```\n\n## Workflow\n1. Add single_large_image detection to slide analysis\n2. Add thumbnail fetching logic\n3. Integrate into get_content() visual-analysis path\n4. Test with real presentations","acceptance_criteria":"- [ ] Detect single_large_image slides (skip these for thumbnails)\n- [ ] Fetch SMALL thumbnails via Slides API for visual slides\n- [ ] Integrate thumbnails into get_content() when purpose=visual-analysis\n- [ ] Return thumbnails with reason (chart/shapes) and skipped with reason\n- [ ] Base64 encode images for JSON response\n- [ ] Unit tests for single_large_image detection\n- [ ] Integration test with real presentation","notes":"## COMPLETED\n- Added single_large_image detection (\u003e50% page coverage)\n- Added fragmented_text detection (\u003e5 fragments, \u003c50 char avg)\n- Added thumbnail fetching via Slides API getThumbnail\n- Integrated into get_content() with purpose='visual-analysis'\n- Changed default size from SMALL to MEDIUM (800x450)\n- 74 unit tests pass\n\n## KEY DISCOVERY\nSlides API rate limit: 60 \"expensive read requests\" per minute per user.\nEach getThumbnail is expensive. 96-slide deck = quota exhaustion.\n\n## GOTCHAS\n- Service object may not be thread-safe for parallel fetches\n- Diagnostic script has \"thumbnail fetch failed\" bug - using thumbnails dict but it has different structure than all_thumbnails expected\n\n## NEXT\n- Fix diagnostic script thumbnail dict handling\n- Consider rate-limit-aware batching with delays\n- Could parallelize but needs fresh service per thread","status":"open","priority":1,"issue_type":"feature","created_at":"2026-01-04T17:49:34.256914Z","updated_at":"2026-01-04T22:54:37.367143Z","dependencies":[{"issue_id":"infra-mcp-workspace-xfi","depends_on_id":"infra-mcp-workspace-5ak","type":"parent-child","created_at":"2026-01-04T17:49:48.932616Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-mcp-workspace-y73","title":"Add Google Slides API support (read/write)","description":"Currently workspace MCP can't read or edit Google Slides presentations. Need to add Slides API integration.","design":"Two-phase approach:\n\n**Phase 1: Read access**\n- Use `presentations.get()` to retrieve structured JSON (slides, text, speaker notes, shapes)\n- Return markdown-friendly format for LLM consumption\n- Speaker notes are particularly valuable - not available via PDF export\n\n**Phase 2: Write access**  \n- Use `presentations.batchUpdate()` for modifications\n- Operations: update text, add/delete slides, modify speaker notes\n- Could enable 'create presentation from markdown' workflow\n\n**Export formats to consider:**\n- PDF (visual, already supported pattern)\n- Plain text (just content)\n- Structured JSON (richest, most useful for LLM)\n\n**Scopes needed:** `https://www.googleapis.com/auth/presentations.readonly` (read) or `https://www.googleapis.com/auth/presentations` (read/write)\n\n**Reference:** https://developers.google.com/slides/api/reference/rest","notes":"Implemented dual extraction approach: (1) Slides API structured extraction for llm-analysis (text + speaker notes + element flags), (2) PDF export for visual-analysis. Also fixed download_file to handle Google Workspace file exports. Files: tools/slides.py (new), server.py, utils.py, resources/documentation.py, tools/drive.py.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-08T18:20:08.947573Z","updated_at":"2025-12-08T19:58:18.60901Z","closed_at":"2025-12-08T19:58:18.609013Z"}
{"id":"infra-mcp-workspace-z76","title":"Rename workspace MCPs to reduce confusion","description":"Current state:\n- 'workspace' = Python MCP (mcp-google-workspace repo)\n- 'google-workspace' = Node.js fork (mcp-workspace-google repo)\n- Confusing, especially with Google's official 'workspace-developer'\n\nOptions discussed:\n- mcp-gworkspace, mcp-gsuite, mcp-workspaceplus\n- Or accept the confusion and document clearly\n\nNeed to pick and execute rename across:\n- Repo names\n- MCP server names in configs\n- Documentation","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-04T23:00:02.08073Z","updated_at":"2026-01-04T23:00:02.08073Z"}
{"id":"infra-openwrt-020","title":"Disable 2.4GHz on 5 of 8 APs","description":"Only 3 non-overlapping 2.4GHz channels (1, 6, 11). With 8 APs, unavoidable co-channel interference. Select 3 physically distributed APs for 2.4GHz coverage (IoT devices), disable on remaining 5.","design":"## Selection Criteria\nPick 3 APs that:\n- Cover different physical zones\n- Serve IoT device concentrations\n- Assign channels 1, 6, 11 respectively\n\n## Implementation\n- Add disabled_2g: true to locations/campbell.yaml per-AP config\n- Generator must handle this (may need schema update)\n- Or: set 2.4GHz radio disabled in template\n\n## IoT Consideration\nSome IoT devices need 2.4GHz + 20MHz + WPA2-PSK only","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-30T23:26:38.037583Z","updated_at":"2025-12-31T12:32:03.829091Z","closed_at":"2025-12-31T12:32:03.829091Z","close_reason":"Applied via UCI: 2.4GHz disabled on 5 APs (ashap,loungeap,guestap,denap,frontap). Kept on kitchenap(ch1), isaacap(ch6), gardenap(ch11) for IoT.","dependencies":[{"issue_id":"infra-openwrt-020","depends_on_id":"infra-openwrt-4gi","type":"parent-child","created_at":"2025-12-30T23:26:50.481732Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-0qj","title":"Run rf-planner-v2 with normalized survey data","description":"Use the normalized-power survey (iteration 006) as input to rf-planner-v2 to get final channel/power recommendations.","design":"## Command\ncd imagebuilder \u0026\u0026 uv run ../rf-optimization/scripts/rf_planner_v2.py \\\n  --location campbell \\\n  --scan ../rf-optimization/data/iteration-006/rf-scan-results.json\n\n## What the planner does\n- Reads neighbor signals from survey\n- Solves for optimal 5GHz channel assignment (avoid interference)\n- Recommends power levels based on geography\n- Confirms 2.4GHz anchor placement","acceptance_criteria":"- [ ] Planner run with --scan pointing to iteration 006 data\n- [ ] Output reviewed and understood\n- [ ] Recommendations saved for comparison","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-31T14:32:52.34643Z","updated_at":"2025-12-31T15:58:40.274331Z","closed_at":"2025-12-31T15:58:40.274331Z","close_reason":"Planner run with iteration 006 data. Recommends moving to DFS channels (100-140) and changing 2.4GHz anchors. Output saved to iteration-006/rf-planner-output.md","dependencies":[{"issue_id":"infra-openwrt-0qj","depends_on_id":"infra-openwrt-d87","type":"blocks","created_at":"2025-12-31T14:33:02.593398Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-openwrt-0qj","depends_on_id":"infra-openwrt-4gi","type":"parent-child","created_at":"2025-12-31T14:33:02.620709Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-0so","title":"Record switch MAC and update campbell.yaml","description":"First step when switch arrives - get MAC from label, update config","design":"1. Find MAC on switch label (bottom or back)\n2. Update locations/campbell.yaml in TWO places:\n   - switch.mac: \"AA:BB:CC:DD:EE:FF\"\n   - device_groups.infrastructure.campbell-switch.mac: \"AA:BB:CC:DD:EE:FF\"\n3. Commit and push\n4. Either rebuild router image OR add DHCP reservation manually","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T11:43:17.004508Z","updated_at":"2025-12-30T10:29:00.570977Z","closed_at":"2025-12-30T10:29:00.570977Z","close_reason":"Cancelled - parent epic (ZyXEL switch) cancelled.","dependencies":[{"issue_id":"infra-openwrt-0so","depends_on_id":"infra-openwrt-l8h","type":"parent-child","created_at":"2025-12-28T11:43:33.170764Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-0t2","title":"Validate Lambourn with re-deploy","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-03T21:28:01.852625Z","updated_at":"2026-01-03T21:28:01.852625Z","dependencies":[{"issue_id":"infra-openwrt-0t2","depends_on_id":"infra-openwrt-e9o","type":"parent-child","created_at":"2026-01-03T21:28:11.077227Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-openwrt-1ag","title":"Test expanded ap-audit.py against live APs","description":"Run ap-audit.py to verify new checks (SSID, 802.11r, bridge-VLAN, guest) work correctly against deployed APs","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T13:16:20.796685Z","updated_at":"2025-12-30T18:16:31.590767Z","closed_at":"2025-12-30T18:16:31.590767Z","close_reason":"Tested against live APs - all 7 online APs aligned to spec. loungeap shows expected gap (802.11r intentionally disabled for HomePod). gardenap offline (separate issue). Audit covers: channels, txpower, htmode, AQL, SSID, 802.11r, bridge-VLAN, guest network."}
{"id":"infra-openwrt-1e3","title":"Write unboxing-to-deployment runbook","description":"Step-by-step physical setup and flashing instructions","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T10:30:16.650494Z","updated_at":"2025-12-28T11:42:32.735079Z","closed_at":"2025-12-28T11:42:32.735079Z","close_reason":"Created docs/switch-deployment-runbook.md with unboxing checklist","dependencies":[{"issue_id":"infra-openwrt-1e3","depends_on_id":"infra-openwrt-bro","type":"parent-child","created_at":"2025-12-28T10:30:27.478874Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-openwrt-1e3","depends_on_id":"infra-openwrt-2so","type":"blocks","created_at":"2025-12-28T10:30:28.88855Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-1g8","title":"Reduce TX power to 12-17dBm (5GHz) and 10-12dBm (2.4GHz)","description":"Current 20-25dBm creates asymmetry: APs transmit loud but clients (iPhones ~12dBm) are quieter. AP hears client poorly, triggers retries. Goal: clients see 2-3 APs, not all 8.","design":"## Target Power Levels\n- 5GHz: 14-17 dBm (start at 17, adjust down)\n- 2.4GHz: 10-12 dBm\n\n## Verification Walk-Survey\nAt any point should see:\n- 1 AP at -50 to -65dBm (primary)\n- 1-2 APs at -67 to -75dBm (roaming candidates)\n- Other APs below -80dBm\n\nIf all 8 visible above -70dBm, power still too high.\n\n## Implementation\nUpdate locations/campbell.yaml txpower settings per AP","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-30T23:26:35.665291Z","updated_at":"2025-12-31T12:32:03.862265Z","closed_at":"2025-12-31T12:32:03.862265Z","close_reason":"Applied via UCI: 2.4GHz TX reduced to 10dBm on 3 remaining APs. 5GHz TX unchanged (already per-AP tuned).","dependencies":[{"issue_id":"infra-openwrt-1g8","depends_on_id":"infra-openwrt-4gi","type":"parent-child","created_at":"2025-12-30T23:26:50.436683Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-1rm","title":"Make post-flash-router.sh non-interactive for Claude","design":"## Problem\npost-flash-router.sh requires interactive input (CF token, ControlD y/n), making it impossible for Claude to run autonomously.\n\n## Proposed Changes\n1. Fix shebang: `#!/bin/bash` → `#!/bin/sh` (OpenWRT uses ash)\n2. Accept arguments or environment variables instead of read prompts:\n   - `--cf-token TOKEN` or `CF_TOKEN` env var\n   - `--skip-acme` flag\n   - `--skip-controld` flag\n3. Fallback to interactive prompts if not provided (backward compatible)\n\n## Example Usage\n```bash\n# Claude can run:\nCF_TOKEN=xxx /tmp/post-flash-router.sh --skip-controld\n\n# Or fully automated:\n/tmp/post-flash-router.sh --cf-token xxx --install-controld\n\n# Human can still run interactively:\n/tmp/post-flash-router.sh\n```\n\n## Acceptance Criteria\n- [ ] Script runs on OpenWRT (ash-compatible)\n- [ ] Can be run non-interactively with env vars or flags\n- [ ] Still works interactively for humans\n- [ ] Claude can execute full post-flash autonomously","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T09:58:39.313754Z","updated_at":"2025-12-29T13:12:02.080864Z","closed_at":"2025-12-29T13:12:02.080864Z","close_reason":"Added --skip-acme, --skip-controld flags, CF_TOKEN/INSTALL_CONTROLD env vars, idempotency check for ACME"}
{"id":"infra-openwrt-1z7","title":"GLinet GL-MV1000 Brume router config","design":"## Context\nEmergency backup router for Campbell Road. Gold image approach — flash and it's ready.\n\n## Hardware\n- GL.iNet GL-MV1000 (Brume): Marvell Armada 3720, dual-core Cortex-A53, 1GB RAM, 16MB flash + 8GB eMMC\n- Ports: 1x WAN RJ45, 2x LAN RJ45 (bridged as br-lan)\n- No wireless (wired router only)\n- Target: mvebu/cortexa53, Profile: glinet_gl-mv1000\n\n## Gold Image Build (GitHub Actions)\nSame pattern as APs and existing routers:\n1. hardware/routers/glinet-gl-mv1000.yaml — hardware definition\n2. imagebuilder/files-brume-campbell/ — config files for Campbell deployment\n3. .github/workflows/build-router-images.yml — add Brume target\n\n## Configuration (baked into image)\n1. **Network**: LAN 172.17.2.1/24, WAN DHCP\n2. **DHCP**: Full reservations from campbell.yaml (via generate-dhcp-config.py)\n3. **DNS**: ControlD resolver + local overrides\n4. **SQM**: ~950Mbps with proper overhead\n5. **SSL**: ACME for *.planetmodha.com (post-flash script)\n6. **SSH**: Authorized keys baked in\n\n## Files to Create\n- hardware/routers/glinet-gl-mv1000.yaml\n- imagebuilder/files-brume-campbell/etc/config/network\n- imagebuilder/files-brume-campbell/etc/config/dhcp\n- imagebuilder/files-brume-campbell/etc/config/firewall\n- imagebuilder/files-brume-campbell/etc/config/sqm\n- imagebuilder/files-brume-campbell/etc/config/system\n- Update .github/workflows/build-router-images.yml\n\n## Acceptance Criteria\n- [ ] hardware/routers/glinet-gl-mv1000.yaml exists\n- [ ] imagebuilder/files-brume-campbell/ directory with full config\n- [ ] GitHub Actions builds gold image successfully\n- [ ] Flash from stock OpenWRT works\n- [ ] Network comes up as 172.17.2.1/24\n- [ ] DHCP serves correct reservations\n- [ ] Internet routing works\n- [ ] SQM active\n- [ ] post-flash-router.sh works for ACME + ControlD","acceptance_criteria":"- [ ] Can drop it in as an emergency replacement and everything continues to work","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-03T21:27:59.412429Z","updated_at":"2026-01-04T11:40:39.216409Z","closed_at":"2026-01-04T11:40:39.216409Z","dependencies":[{"issue_id":"infra-openwrt-1z7","depends_on_id":"infra-openwrt-e9o","type":"parent-child","created_at":"2026-01-03T21:28:11.008858Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-openwrt-2ep","title":"Verify Bristol OpenWRT ONE network config - lan1-lan4 ports don't exist on 2-port hardware","notes":"Fixed: removed lan1-4 (don't exist), changed WAN from eth2 to eth0. OpenWRT ONE has only eth0 (WAN) and eth1 (LAN).","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T01:12:49.784462Z","updated_at":"2025-12-22T09:44:30.586874Z","closed_at":"2025-12-22T09:44:30.586884Z"}
{"id":"infra-openwrt-2m6","title":"Flash guestap and test UCI flag reboot pattern","description":"Guestap is bricked from boot loop debugging. Safe no-reboot image ready at /tmp/unifi-images/. Also queued: build 20584416239 with UCI flag pattern (uses uci setting instead of file as reboot guard). Test if UCI commits persist on first boot.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-29T22:53:29.100148Z","updated_at":"2025-12-30T09:41:21.938235Z","closed_at":"2025-12-30T09:41:21.938235Z","close_reason":"Superseded by direct sysfs + hotplug approach. UCI flag pattern was never tested - pivoted to simpler solution that applies AQL immediately during firstboot without needing reboot."}
{"id":"infra-openwrt-2so","title":"Add GS1900 to GitHub Actions build workflow","description":"Build switch gold image alongside AP images","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T10:30:15.360571Z","updated_at":"2025-12-28T11:42:31.613481Z","closed_at":"2025-12-28T11:42:31.613481Z","close_reason":"Created build-switch-images.yml workflow","dependencies":[{"issue_id":"infra-openwrt-2so","depends_on_id":"infra-openwrt-bro","type":"parent-child","created_at":"2025-12-28T10:30:27.445265Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-openwrt-2so","depends_on_id":"infra-openwrt-xz4","type":"blocks","created_at":"2025-12-28T10:30:28.85536Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-2xg","title":"Run post-policy-change WiFi capture","description":"Capture AP metrics after policy settings (cell_density, ieee80211k, normalized power) to compare against pre-change baseline.","acceptance_criteria":"- [ ] Run capture-ap-metrics.sh from kube.lan\n- [ ] Save to rf-optimization/data/capture-postpolicy-YYYYMMDD/\n- [ ] Compare retry rates to pre-change captures","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-31T15:15:24.940109Z","updated_at":"2025-12-31T18:00:10.849094Z","closed_at":"2025-12-31T18:00:10.849094Z","close_reason":"RF scan completed. Planner shows 5GHz unchanged, 2.4GHz just channel rotation among same anchors — not significant, keeping current config."}
{"id":"infra-openwrt-30m","title":"Rebuild gold images with new 2.4GHz config","description":"UCI changes to 2.4GHz (denap/isaacap/frontap enabled, others disabled) will revert on reflash. Need to rebuild gold images to persist.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-02T21:49:30.646934Z","updated_at":"2026-01-02T21:49:30.646934Z"}
{"id":"infra-openwrt-3l4","title":"Fix radio mapping in rf-planner-v2 UCI output","description":"UCI output assumes radio0=2.4GHz, radio1=5GHz but this is hardware-dependent. Should load mapping from hardware YAML (aps/*.yaml radios field).","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-31T13:19:48.151661Z","updated_at":"2025-12-31T13:19:48.151661Z","dependencies":[{"issue_id":"infra-openwrt-3l4","depends_on_id":"infra-openwrt-c4u","type":"parent-child","created_at":"2026-01-03T21:14:59.486458Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-openwrt-3y6","title":"Fix Bristol router SSH access","design":"Copy SSH public key to Bristol router (172.17.92.1). Currently getting 'Permission denied (publickey)'. Need to access via another method or physical console.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T08:14:15.077807Z","updated_at":"2025-12-20T08:18:20.708738Z","closed_at":"2025-12-20T08:18:20.708738Z","close_reason":"Fixed via LuCI web interface - added SSH public key through System \u003e Administration \u003e SSH Keys"}
{"id":"infra-openwrt-46r","title":"Create hardware/switches/gs1900-24hp-v2.yaml definition","description":"Define switch hardware spec similar to AP hardware files","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T10:30:11.179475Z","updated_at":"2025-12-28T11:42:28.426721Z","closed_at":"2025-12-28T11:42:28.426721Z","close_reason":"Created hardware/switches/gs1900-24hp-v2.yaml","dependencies":[{"issue_id":"infra-openwrt-46r","depends_on_id":"infra-openwrt-bro","type":"parent-child","created_at":"2025-12-28T10:30:27.344726Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-openwrt-46r","depends_on_id":"infra-openwrt-ons","type":"blocks","created_at":"2025-12-28T10:30:28.755085Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-49y","title":"Push policy settings + normalize 5GHz power to 12dBm","description":"Apply all policy settings (min rates, 802.11k/v) uniformly to all APs, and normalize 5GHz power to 12dBm for fair survey baseline.","design":"## Policy Settings to Push\n- Min data rate 2.4GHz: 12 Mbps (basic_rate, supported_rates)\n- Min data rate 5GHz: 24 Mbps\n- 802.11k (RRM): ieee80211k='1', rrm_neighbor_report='1'\n- 802.11v (BSS TM): ieee80211v='1', bss_transition='1'\n- TXOP: Consider wmm_ac_be_txop_limit (optional, test impact)\n\n## Power Normalization\n- All plan-enabled 5GHz radios: 12 dBm (equal for fair survey)\n- All plan-enabled 2.4GHz radios: max power (10 dBm per YAML)\n\n## Method\nSSH to each AP, apply UCI commands, wifi reload.","acceptance_criteria":"- [ ] Min data rates set on all APs (2.4GHz: 12Mbps, 5GHz: 24Mbps)\n- [ ] 802.11k enabled on all APs\n- [ ] 802.11v enabled on all APs  \n- [ ] 5GHz power normalized to 12dBm on all active radios\n- [ ] 2.4GHz power at 10dBm on anchor APs\n- [ ] All APs wifi reloaded and stable","notes":"COMPLETED (Dec 31):\n- cell_density=2 on 2.4GHz radios (min 12 Mbps)\n- cell_density=3 on 5GHz radios (min 24 Mbps)\n- ieee80211k=1 on all wifi-ifaces (802.11k RRM enabled)\n- txpower normalized: 12dBm 5GHz, 10dBm 2.4GHz anchors\n\nNOT COMPLETED:\n- 802.11v (bss_transition, wnm_sleep_mode) — requires wpad-mbedtls, not supported by wpad-basic-mbedtls\n- Pushed to all 7 APs; hostapd crashed; removed 802.11v options; WiFi restored\n\nLESSON: netifd hostapd.sh supports the UCI options but the hostapd binary in wpad-basic-* doesn't have 802.11v compiled in. OpenWRT wiki confirms \"needs the full version of hostapd or wpad.\"\n\nNEXT: Part B of plan adds wpad-mbedtls to gold images, then 802.11v can be enabled.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-31T14:32:12.944551Z","updated_at":"2025-12-31T15:15:40.543794Z","closed_at":"2025-12-31T15:15:40.543794Z","close_reason":"Policy settings applied (cell_density, ieee80211k, normalized power). 802.11v deferred to wpad-mbedtls upgrade.","dependencies":[{"issue_id":"infra-openwrt-49y","depends_on_id":"infra-openwrt-4gi","type":"parent-child","created_at":"2025-12-31T14:32:25.817945Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-4gi","title":"RF optimization: reduce interference, match power to clients","description":"Based on Compass research (Dec 2025): High retries are co-channel interference from 8 APs at max power with 80MHz channels. Fix requires reducing power to create proper cell boundaries, narrowing channels, and disabling 2.4GHz on most APs.","design":"## Research Source\ndocs/compass_artifact_wf-0713bfa3-3718-439d-992a-30876fab28ff_text_markdown.md\n\n## Approach\nFollow prioritized tuning order from research:\n- Phase 1: Power, channel width, channel allocation, 2.4GHz reduction\n- Phase 2: 802.11r fix, minimum data rates\n\n## Measurement\nPer methodology doc, measure between each change. But these Phase 1 changes are interrelated - may need to batch some. Use 7-day baselines where practical, or 24-48h for quick validation.\n\n## Target State\n- \u003c10% retry rate (down from 20-37%)\n- Clients see 2-3 APs, not all 8\n- -67dBm cell edge for voice-grade coverage","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-30T23:25:50.534141Z","updated_at":"2025-12-30T23:25:50.534141Z","dependencies":[{"issue_id":"infra-openwrt-4gi","depends_on_id":"infra-openwrt-uws","type":"parent-child","created_at":"2026-01-03T21:14:55.358957Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-openwrt-57w","title":"OpenWRT Firmware Upgrade Strategy","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"open","priority":3,"issue_type":"epic","created_at":"2025-12-20T08:13:59.355641Z","updated_at":"2025-12-30T18:22:19.709654Z"}
{"id":"infra-openwrt-57w.1","title":"Document current package lists for all devices","design":"Before any upgrade, capture opkg list-installed from each device for restoration","notes":"Package lists captured for all 10 devices (2 routers, 8 APs). Discovered 3 different AP hardware profiles: Unifi 6 Lite, Unifi nanoHD, TP-Link EAP225-Outdoor. Saved to package-lists/ directory.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T08:14:12.068394Z","updated_at":"2025-12-20T08:48:36.831074Z","closed_at":"2025-12-20T08:48:36.831084Z","dependencies":[{"issue_id":"infra-openwrt-57w.1","depends_on_id":"infra-openwrt-57w","type":"parent-child","created_at":"2025-12-20T08:14:12.069903Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-openwrt-57w.1","depends_on_id":"infra-openwrt-3y6","type":"blocks","created_at":"2025-12-20T08:14:21.628295Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-openwrt-57w.1","depends_on_id":"infra-openwrt-57w.5","type":"blocks","created_at":"2025-12-20T08:33:50.538315Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-57w.2","title":"Research attended-sysupgrade vs manual upgrade","design":"Compare ASU package with manual sysupgrade approach. Document pros/cons of each for our use case.","notes":"Researched ASU - good for minor updates, not major. Had Dec 2024 security vulns (patched). Only preserves packages, not configs.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T08:14:12.953281Z","updated_at":"2025-12-20T08:59:04.889443Z","closed_at":"2025-12-20T08:59:04.889453Z","dependencies":[{"issue_id":"infra-openwrt-57w.2","depends_on_id":"infra-openwrt-57w","type":"parent-child","created_at":"2025-12-20T08:14:12.954959Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-57w.3","title":"Define upgrade order and test plan","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-20T08:14:13.94676Z","updated_at":"2025-12-30T23:19:07.170096Z","deleted_at":"2025-12-30T23:19:07.170096Z","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"infra-openwrt-57w.4","title":"Research idempotent OpenWRT configuration approaches","design":"Investigate Infrastructure-as-Code patterns for OpenWRT:\n\n**Options to evaluate:**\n1. **Ansible + openwrt modules**: Playbooks for UCI config, package management\n2. **OpenWRT ImageBuilder**: Pre-bake configs into firmware images\n3. **UCI script idempotency**: Design patterns for run-repeatedly-safely\n4. **NixWRT**: NixOS-based declarative OpenWRT (experimental)\n5. **Custom shell scripts**: Current approach but more disciplined\n\n**Evaluation criteria:**\n- Effort to set up vs maintain\n- Recovery time from blank device\n- Drift detection capability\n- Cross-hardware portability (BPI R4 vs OpenWRT ONE)","notes":"Evaluated: Ansible (gekmihesg), ImageBuilder+uci-defaults, Freifunk Ansible+ImageBuilder. Recommendation: ImageBuilder+uci-defaults for APs (golden images per hardware profile), ASU for router minor updates.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T08:14:37.107333Z","updated_at":"2025-12-20T08:59:05.01749Z","closed_at":"2025-12-20T08:59:05.017502Z","dependencies":[{"issue_id":"infra-openwrt-57w.4","depends_on_id":"infra-openwrt-57w","type":"parent-child","created_at":"2025-12-20T08:14:37.107749Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-57w.5","title":"Deploy SSH keys to Campbell APs","design":"Deploy SSH public key to all 8 Campbell APs (ashap, loungeap, guestap, denap, kitchenap, frontap, gardenap, isaacap) so Claude can SSH in for package list capture and future upgrades. Current state: Permission denied (publickey).","notes":"SSH keys deployed to all 8 Campbell APs via LuCI. Cleaned up 3 stale keys (samemodh@C2VQF93F24, FISHy, sameer@MacBookAir.lan). Also discovered: clock drift on multiple APs (NTP not stepping large offsets), LoungeAP has segfaulting logread. All APs on 24.10.3 vs router on 24.10.4.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T08:33:44.814188Z","updated_at":"2025-12-20T08:44:51.07609Z","closed_at":"2025-12-20T08:44:51.076095Z","dependencies":[{"issue_id":"infra-openwrt-57w.5","depends_on_id":"infra-openwrt-57w","type":"parent-child","created_at":"2025-12-20T08:33:44.815869Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-57w.6","title":"Define canonical AP configuration","design":"Establish a single, documented, idempotent configuration for all Campbell APs.\n\n**Current drift discovered:**\n- Stale SSH keys accumulated (3 different old keys)\n- Clock drift (NTP not handling large offsets)\n- LoungeAP: logread segfaulting (memory/binary issue)\n- Minor version differences (APs on 24.10.3, router on 24.10.4)\n\n**Canonical config should define:**\n1. **System**: hostname pattern, timezone, NTP with boot-time step\n2. **Network**: bridge mode, DHCP client, static reservation on router\n3. **Wireless**: SSID, encryption (sae-mixed), channels, OCV settings\n4. **Security**: SSH key (single source of truth), password auth disabled\n5. **Services**: disabled (dnsmasq, firewall, odhcpd)\n6. **SSL**: certificate copied from router after generation\n7. **Packages**: minimal set for dumb AP operation\n\n**Deliverable:**\n- UCI command stream that can be run on fresh AP to achieve canonical state\n- Validation script to detect drift from canonical config\n- Integration with idempotent config research (.4)","notes":"RESOLUTION: Created two deliverables:\n\n1. docs/canonical-ap-config.md - Comprehensive reference defining network (DHCP client), DHCP (ignore '1' - new approach), services (dnsmasq/firewall enabled), wireless (SSID, sae-mixed, 802.11r, DTIM=3), security (SSH key-only), and VLAN stub.\n\n2. scripts/ap-config-check.sh - Drift detection script, tested on LoungeAP (found 7 drift items correctly).\n\nKey insight: OpenWRT now recommends dhcp ignore '1' over disabling services. Migration needed for all 8 APs.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T08:45:04.540112Z","updated_at":"2025-12-21T19:19:31.141948Z","closed_at":"2025-12-21T19:19:31.141954Z","dependencies":[{"issue_id":"infra-openwrt-57w.6","depends_on_id":"infra-openwrt-57w","type":"parent-child","created_at":"2025-12-20T08:45:04.547756Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-openwrt-57w.6","depends_on_id":"infra-openwrt-57w.7","type":"blocks","created_at":"2025-12-20T09:08:59.574765Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-57w.7","title":"Audit current AP configurations","design":"Deep dive into current AP configs to understand drift and issues before defining canonical config.\n\n**Goals:**\n1. Dump and compare configs across all 8 APs\n2. Identify drift between devices of same hardware type\n3. Document what's non-standard or potentially problematic\n4. Research current best practices for dumb AP setup\n5. Consider VLAN requirements for future guest WiFi\n\n**Areas to examine:**\n- Wireless config (channels, power, encryption, 802.11r/k/v)\n- Network config (bridge setup, DHCP disabled properly?)\n- Disabled services (dnsmasq, firewall, odhcpd - are they actually off?)\n- NTP config (we already found issues here)\n- System config (logging, timezone)\n\n**VLAN consideration:**\nGuest WiFi will likely need VLAN tagging on APs. Better to understand current state and plan for this now rather than retrofit later.\n\n**Output:**\n- Summary of current state per AP\n- List of issues/drift found\n- Recommended fixes\n- Informs .6 (canonical config)","notes":"Audit complete. Configs mostly consistent. Key findings: DTIM not set, NTP needs boot-time step, IPv6 inconsistent, channel allocation mixed. See docs/ap-config-audit-2025-12.md","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T09:08:50.322878Z","updated_at":"2025-12-20T09:13:58.692475Z","closed_at":"2025-12-20T09:13:58.692485Z","dependencies":[{"issue_id":"infra-openwrt-57w.7","depends_on_id":"infra-openwrt-57w","type":"parent-child","created_at":"2025-12-20T09:08:50.329118Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-57w.8","title":"Router ImageBuilder - per-location gold images","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","notes":"## Session Dec 22: Phase 2 Complete\n\n**Campbell router successfully flashed and running 24.10.5**\n\n**Bugs found and fixed in repo:**\n1. WAN device: eth2 → wan (Campbell uses switch WAN port, not SFP)\n2. Missing luci-app-* packages (sqm, acme, attendedsysupgrade)\n3. Hostname not set in first-boot scripts (all 3 locations)\n4. **Workflow duplication** - refactored to call shell script (single source of truth)\n\n**Current router state:**\n- WAN: working (wan@eth0)\n- eth1 SFP: working (to switch)\n- Hostname: campbell\n- DHCP: 51 reservations\n- SQM: active at 800Mbps\n- Internet: working\n- Missing: luci-app-* (fix committed but not reflashed)\n\n**Commits:**\n- 9678826: Fix WAN, packages, hostname in config files\n- c46acc9: Fix workflow package list\n- f26e5bf: Refactor workflow to use shell script\n\n**Open items:**\n- luci-app-* packages not installed (needs rebuild+reflash)\n- ControlD not baked in (discussed, not implemented)\n- eth1 boot mystery (link didn't establish on first flash, worked after reseat)\n\n**Learnings:**\n- BPI R4: wan@eth0 is switch WAN port, eth2 is SFP WAN\n- Always check working config before assuming hardware specs\n- Workflow and script had duplicated package lists - now unified","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-21T20:37:57.211166Z","updated_at":"2025-12-30T23:19:07.193044Z","deleted_at":"2025-12-30T23:19:07.193044Z","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"infra-openwrt-57w.8.1","title":"Test router gold image end-to-end (luci-app-*, SQM, ACME)","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-22T09:38:29.025664Z","updated_at":"2025-12-30T23:19:07.215292Z","deleted_at":"2025-12-30T23:19:07.215292Z","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"infra-openwrt-5ax","title":"SQM validation","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T08:29:51.953534Z","updated_at":"2025-12-30T23:09:24.159343Z","closed_at":"2025-12-30T23:09:24.159343Z","close_reason":"SQM validation complete"}
{"id":"infra-openwrt-5ta","title":"YAML Single Source of Truth for OpenWRT config","design":"Consolidate 7+ sources of duplicated device/config data into per-location YAML files. Two layers: hardware/*.yaml (model quirks) + locations/*.yaml (instance data). See ~/.claude/plans/iterative-percolating-stonebraker.md for full plan.","notes":"SESSION: 2025-12-25\n\nCOMPLETED:\n- Phase 0: Hardware YAML definitions (already done)\n- Phase 1: Location YAML files (campbell, bristol, lambourn)\n- Phase 2: infra_lib.py with 17 tests (TDD)\n- Phase 3: RF scripts (rf-scan.py, rf-graph.py) now use infra_lib\n- Phase 4: DHCP generation reads from YAML\n- Phase 5: yaml-extract.py for shell scripts\n\nKEY DELIVERABLES:\n- 34 tests passing\n- All hardcoded AP/device dicts replaced with YAML-driven loading\n- Campbell: 8 APs + 43 devices fully migrated\n- Bristol/Lambourn: minimal configs created\n\nCURRENT STATE:\nCore infrastructure complete. Scripts read from locations/*.yaml.\n\nREMAINING (from plan):\n- Phase 6: Router config check script\n- Phase 7: Bake local DNS into gold image\n- Cleanup: Delete deprecated device-mac-assignments/*.md\n\nNEXT SESSION:\nConsider closing this epic (core objective met) and creating follow-on beads for Phase 6-7.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-25T11:23:32.169787Z","updated_at":"2025-12-25T16:48:16.272339Z","closed_at":"2025-12-25T16:48:16.272339Z","close_reason":"Core objective achieved: YAML Single Source of Truth infrastructure complete.\n\nDelivered:\n- locations/*.yaml for all three sites (campbell: 8 APs + 43 devices)\n- hardware/*.yaml for all router/AP models\n- infra_lib.py with typed dataclasses and 34 tests\n- All scripts (rf-scan, rf-graph, generate-dhcp-config) now read from YAML\n- yaml-extract.py for shell script integration\n\nFollow-on work tracked in separate beads:\n- Phase 6: Router config check script\n- Phase 7: Bake local DNS into gold image"}
{"id":"infra-openwrt-6lr","title":"ap-audit: detect disabled radios","description":"ap-audit.py shows 2.4GHz channels even when radio is disabled via UCI. Should detect and report disabled state.","design":"Check 'uci get wireless.radioX.disabled' and show 'DISABLED' instead of channel/txpower when set to 1.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-31T12:32:05.228961Z","updated_at":"2025-12-31T12:42:32.823055Z","closed_at":"2025-12-31T12:42:32.823055Z","close_reason":"Added disabled radio detection for 2.4GHz in both get_deployed_state() and get_target_state(). Now consumes disabled_2g from YAML (DRY). Verified: audit correctly shows disabled vs channel for 2.4GHz band."}
{"id":"infra-openwrt-6qa","title":"Add tx_bytes_delta and rx_bytes_delta columns for accurate traffic reporting","description":"Top Traffic display uses MAX(tx_bytes) which gives highest counter value, not actual bytes transferred. If client disconnects/reconnects, only max of separate sessions is shown. Counter resets not accounted for.","design":"## Approach\n1. Add tx_bytes_delta and rx_bytes_delta columns to client_metrics schema\n2. Update wifi_poller.py to compute deltas using same calculate_delta() function\n3. Update analyze.py Top Traffic query to use SUM(tx_bytes_delta)\n\n## Trade-offs\n- Schema migration required (new columns)\n- Historical data won't have delta values (will show NULL)\n- Could add sanity bounds like other deltas\n\n## Acceptance Criteria\n- [ ] Schema includes tx_bytes_delta, rx_bytes_delta columns\n- [ ] Poller computes and stores byte deltas\n- [ ] Top Traffic query uses SUM() for accurate totals\n- [ ] Handles counter resets gracefully (NULL delta)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-01T08:31:44.63157Z","updated_at":"2026-01-02T21:15:37.167359Z","closed_at":"2026-01-02T21:15:37.167359Z","close_reason":"Added tx_bytes_delta and rx_bytes_delta columns: schema.sql, migration script, wifi_poller.py calculation, analyze.py backwards-compatible queries"}
{"id":"infra-openwrt-6zf","title":"Expand ap-audit.py to check SSID, 802.11r, bridge-VLAN","design":"## Problem\nap-audit.py only checks RF settings. Missing checks for:\n- SSID (main and guest)\n- 802.11r settings (mobility_domain, ft_over_ds)\n- Bridge-VLAN config (vlan_filtering, lan.device = br-lan.1)\n- Guest network presence\n\n## Approach\nExpand current architecture (Option A from discussion):\n1. Add fields to ApState and ApTarget dataclasses\n2. Add SSH queries for new settings\n3. Add comparisons and gap reporting\n\n## Checks to Add\n| Setting | UCI Path | Target Source |\n|---------|----------|---------------|\n| SSID | wireless.default_{radio}.ssid | loc.wireless.ssid |\n| mobility_domain | wireless.default_{radio}.mobility_domain | loc.wireless.mobility_domain |\n| ft_over_ds | wireless.default_{radio}.ft_over_ds | \"0\" (our standard) |\n| vlan_filtering | network.@device[0].vlan_filtering | \"1\" if guest_network |\n| lan.device | network.lan.device | \"br-lan.1\" if vlan_filtering |\n| guest SSID | wireless.{guest_iface}.ssid | loc.guest_network.ssid |\n\n## Acceptance Criteria\n- [ ] SSID checked on both bands\n- [ ] 802.11r mobility_domain checked\n- [ ] Bridge-VLAN filtering checked (if guest network configured)\n- [ ] Management interface device checked (br-lan.1)\n- [ ] Guest SSID checked (if guest network configured)\n- [ ] Exit code 1 if any gaps","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-29T13:06:03.725443Z","updated_at":"2025-12-29T13:12:02.046126Z","closed_at":"2025-12-29T13:12:02.046126Z","close_reason":"Added SSID, 802.11r, bridge-VLAN, guest network checks to ap-audit.py"}
{"id":"infra-openwrt-765","title":"Create verify-firstboot.sh script","description":"Script to binwalk image and check for danger patterns (reboot outside conditionals, syntax errors, etc.) without flashing. Surfaced during Dec 2025 boot loop debugging - would have caught generator issue earlier.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T23:00:20.141891Z","updated_at":"2025-12-30T18:29:11.774865Z","closed_at":"2025-12-30T18:29:11.774865Z","close_reason":"Created verify-firstboot.sh - extracts squashfs via binwalk and checks for: syntax errors, missing exit 0, unguarded reboot commands, suspicious patterns. Documented as MANDATORY pre-flash step in CLAUDE.md. Full image testing deferred to next build."}
{"id":"infra-openwrt-76v","title":"Physical cutover from Netgear GS324","description":"Move all cables, verify APs boot","design":"1. Label all cables on old switch BEFORE disconnecting\n2. Power off Netgear GS324\n3. Move cables to new switch (same port numbers)\n4. Power on, wait for APs to boot\n5. Verify APs: for i in 20 21 22 23 24 25 26 27; do ping -c1 172.17.2.$i; done\n6. Check PoE: ubus call poe info | grep consumption\n\nCLEANUP:\n- Delete switch-old entry from campbell.yaml\n- Commit \"Switch deployment complete\"","notes":"BLOCKED: ZyXEL hardware not arrived. GS324TP still in use with VLAN 10 configured.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-28T11:43:22.055429Z","updated_at":"2025-12-28T17:21:17.295901Z","dependencies":[{"issue_id":"infra-openwrt-76v","depends_on_id":"infra-openwrt-l8h","type":"parent-child","created_at":"2025-12-28T11:43:33.330794Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-openwrt-76v","depends_on_id":"infra-openwrt-9in","type":"blocks","created_at":"2025-12-28T11:43:34.577832Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-7f2","title":"Build switch gold image via GitHub Actions","description":"Build OpenWRT image with baked-in config","design":"gh workflow run build-switch-images.yml -f location=campbell\nWait ~10 min\ngh run download \u003crun-id\u003e -n campbell-switch-image\n\nVerify TWO files:\n- *-initramfs-kernel.bin (for initial flash)\n- *-sysupgrade.bin (for permanent install)","notes":"BLOCKED: ZyXEL hardware not arrived. Can't test gold image without hardware.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T11:43:18.250617Z","updated_at":"2025-12-30T18:17:35.754172Z","closed_at":"2025-12-30T18:17:35.754172Z","close_reason":"Cancelled - ZyXEL switch not being purchased. Using GS324TP with telnet CLI instead.","dependencies":[{"issue_id":"infra-openwrt-7f2","depends_on_id":"infra-openwrt-l8h","type":"parent-child","created_at":"2025-12-28T11:43:33.215763Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-openwrt-7f2","depends_on_id":"infra-openwrt-0so","type":"blocks","created_at":"2025-12-28T11:43:34.448826Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-7hq","title":"All APs working reliably with secure management","status":"open","priority":2,"issue_type":"epic","created_at":"2026-01-03T21:14:34.939631Z","updated_at":"2026-01-03T21:14:34.939631Z"}
{"id":"infra-openwrt-7hq.1","title":"Flash APs with 2.4GHz gold images (denap, frontap, isaacap)","description":"Gold images built Dec 2025 with 2.4GHz config. Images may be in /tmp/ap-images/ (ephemeral). Rebuild if missing.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-04T11:43:04.363885Z","updated_at":"2026-01-04T11:43:04.363885Z","dependencies":[{"issue_id":"infra-openwrt-7hq.1","depends_on_id":"infra-openwrt-7hq","type":"parent-child","created_at":"2026-01-04T11:43:04.364337Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-openwrt-7p2","title":"Compare planner recommendations to current config","description":"Analyze differences between planner output and current deployed config. Understand what would change and why.","design":"## Comparison points\n- 5GHz channel assignments\n- 5GHz power levels\n- 2.4GHz anchor selection\n- Any unexpected recommendations\n\n## Questions to answer\n- Does the survey data change the optimal channel plan?\n- Are power recommendations different with real signal data?\n- Do we need to adjust geography model?","acceptance_criteria":"- [ ] Side-by-side comparison table produced\n- [ ] Changes understood and documented\n- [ ] Decision made: apply recommendations or adjust model","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-31T14:32:52.390521Z","updated_at":"2025-12-31T16:13:57.233156Z","closed_at":"2025-12-31T16:13:57.233156Z","close_reason":"Comparison complete. Iteration 006 applied: DFS-2 channels (52-140), geography-based power (11-17dBm), new 2.4GHz anchors (loungeap/denap/kitchenap).","dependencies":[{"issue_id":"infra-openwrt-7p2","depends_on_id":"infra-openwrt-0qj","type":"blocks","created_at":"2025-12-31T14:33:02.650262Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-openwrt-7p2","depends_on_id":"infra-openwrt-4gi","type":"parent-child","created_at":"2025-12-31T14:33:02.682181Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-7qo","title":"Add switch to locations/campbell.yaml","description":"Add campbellswitch with IP, PoE settings, port assignments","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T10:30:12.911461Z","updated_at":"2025-12-28T11:42:29.267222Z","closed_at":"2025-12-28T11:42:29.267222Z","close_reason":"Added switch section to campbell.yaml with PoE port config","dependencies":[{"issue_id":"infra-openwrt-7qo","depends_on_id":"infra-openwrt-bro","type":"parent-child","created_at":"2025-12-28T10:30:27.378291Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-openwrt-7qo","depends_on_id":"infra-openwrt-46r","type":"blocks","created_at":"2025-12-28T10:30:28.788968Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-7r0","title":"Wireless optimization","design":"Frequency planning and channel allocation for multi-AP deployment.","notes":"Related to infra-openwrt-uws (WLUL epic). Frequency planning is part of channel/width/power optimization work.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T08:29:51.022424Z","updated_at":"2025-12-24T21:12:01.218979Z","closed_at":"2025-12-24T21:12:01.218979Z","close_reason":"Completed as part of WLUL epic. Frequency planning done in iteration-004 (channel solver), power tuning for vertical stacks."}
{"id":"infra-openwrt-83h","title":"Bake per-AP RF settings into gold images via MAC-based identity lookup","design":"MAC-based identity lookup in firstboot script. Each AP detects its eth0 MAC, looks up RF settings (channel, txpower) from embedded table, applies them. One image per hardware model family (3 total), bit-identical within family. Generator reads from locations/*.yaml and hardware/*.yaml.","notes":"Implemented generate-ap-config.py with 9 tests. Updated build-ap-images.sh to call generator. Both Unifi (7 APs) and EAP225 (1 AP) templates updated. Radio ordering handled correctly (Unifi: radio0=2.4g, EAP225: radio0=5g). Disabled radios handled. All 45 tests pass.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-25T20:11:13.236939Z","updated_at":"2025-12-25T20:11:31.728047Z","closed_at":"2025-12-25T20:11:31.728056Z"}
{"id":"infra-openwrt-85n","title":"Add kube.lan SSH key to AP gold image template","description":"Currently kube.lan SSH key added manually to each AP. Should be baked into gold image (99-campbell-ap template) so it persists across reflashes. Key: ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAINcF0E6V... modha@kube","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-31T00:09:41.092638Z","updated_at":"2025-12-31T00:09:41.092638Z","dependencies":[{"issue_id":"infra-openwrt-85n","depends_on_id":"infra-openwrt-7hq","type":"parent-child","created_at":"2026-01-03T21:14:57.010606Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-openwrt-889","title":"Set up nginx reverse proxy on Campbell router","description":"generate-nginx-config.py exists but isn't integrated into build workflow. Need to: enable nginx in router image, integrate config generator, set up SSL termination for local services (uhttpd, luci). Foundation code added in commit e0045d3.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-30T09:52:08.830302Z","updated_at":"2025-12-30T09:52:08.830302Z"}
{"id":"infra-openwrt-8db","title":"Extract magic numbers to constants","description":"-75 dBm threshold, AQL values, timeouts - define as named constants.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-31T18:33:20.131069Z","updated_at":"2025-12-31T18:33:20.131069Z","labels":["tech-debt"],"dependencies":[{"issue_id":"infra-openwrt-8db","depends_on_id":"infra-openwrt-uws","type":"parent-child","created_at":"2026-01-03T21:14:55.50006Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-openwrt-8hf","title":"Tailscale always-on without routing friction or ControlD conflicts","description":"Want Tailscale on all the time without:\n(a) routing out of house and back in when home\n(b) interfering with ControlD (or just enable ControlD on Tailscale too)\n(c) blocking Claude access to .lan devices (APs etc)\n\nYesterday's fix: split DNS on this machine only - works but per-machine fixes are not ideal.\n\n## Context\n- infra-openwrt has canonical router configs\n- APs all have .lan suffixes\n- Telemetry config also captured here","design":"## Possible Approaches\n1. Enable ControlD on Tailscale (may be simplest)\n2. Tailscale exit node config for home detection\n3. Split DNS at router level instead of per-machine\n4. MagicDNS + local DNS integration\n\n## Related\n- Yesterday's session: split DNS workaround on this Mac","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-04T12:10:07.655879Z","updated_at":"2026-01-04T12:10:07.655879Z"}
{"id":"infra-openwrt-8ho","title":"Investigate 2.4GHz high retry rates - RF scan to identify interference sources","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-31T23:02:26.485808Z","updated_at":"2026-01-02T21:49:32.162779Z","closed_at":"2026-01-02T21:49:32.162779Z","close_reason":"Superseded: 2.4GHz config fundamentally changed (now denap/isaacap/frontap only, max power). Need fresh data before investigating retry rates."}
{"id":"infra-openwrt-8zi","title":"Check GS324TP firmware for updates","description":"Periodic check (~quarterly). Current: 1.0.0.44. Pattern: telnet to switch for current version, web search for latest. See CLAUDE.md 'Switch Firmware Check' section.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-30T10:05:43.630211Z","updated_at":"2025-12-30T18:20:54.920691Z","closed_at":"2025-12-30T18:20:54.920691Z","close_reason":"Already checked Dec 2025 - firmware 1.0.0.44 is current. Documented in CLAUDE.md."}
{"id":"infra-openwrt-9f5","title":"Fix AP blue lights after router flash","design":"AP blue LED config - need to add led_override='off' to AP gold images.\n\n**Actual cause:** Not adoption issue - APs are OpenWRT, not Unifi-controlled. The blue LED is just the default state, needs UCI config to disable.\n\n**Fix:** Add to AP first-boot scripts:\n```\nuci set system.led_status.trigger='none'\nuci commit system\n```\n\nOr bake into AP config files directly.","notes":"Fixed. LED disable (blue:dome sysfs, trigger none) added to Unifi AP firstboot script. Applied manually to all 7 Unifi APs. Documented in canonical-ap-config.md.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-22T00:12:46.647248Z","updated_at":"2025-12-22T01:14:32.374806Z","closed_at":"2025-12-22T01:14:32.374814Z"}
{"id":"infra-openwrt-9in","title":"Connect switch to network and verify","description":"Join network, verify SSH, PoE, connectivity","design":"1. Connect switch uplink to router/network\n2. ssh-keygen -R 172.17.2.4\n3. ssh root@172.17.2.4 (SSH key, no password)\n4. hostname → expect \"campbell-switch\"\n5. ubus call poe info → expect \"budget\": 170\n6. ping 172.17.2.1 → router reachable","notes":"BLOCKED: ZyXEL hardware not arrived.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T11:43:21.029185Z","updated_at":"2025-12-30T18:17:35.696031Z","closed_at":"2025-12-30T18:17:35.696031Z","close_reason":"Cancelled - ZyXEL switch not being purchased. Using GS324TP with telnet CLI instead.","dependencies":[{"issue_id":"infra-openwrt-9in","depends_on_id":"infra-openwrt-l8h","type":"parent-child","created_at":"2025-12-28T11:43:33.295025Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-openwrt-9in","depends_on_id":"infra-openwrt-chp","type":"blocks","created_at":"2025-12-28T11:43:34.537056Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-9o2","title":"Add wifi reload to AP firstboot if needed after testing","description":"After isaacap reboot, 5GHz wasn't broadcasting until wifi reload was run. May need to add to rc.local or end of firstboot script. Test on nanoHD first to confirm it's a general issue.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T11:49:53.849327Z","updated_at":"2025-12-30T18:08:02.97642Z","closed_at":"2025-12-30T18:08:02.97642Z","close_reason":"Not needed for firstboot - uci commit wireless is sufficient since scripts run before services start. Verified by successful 7-AP rollout (Dec 2025)."}
{"id":"infra-openwrt-9ps","title":"Audit GS324TP switch configuration","design":"Full audit of Netgear GS324TP at 172.17.2.4\n\nCLI access: telnet port 60000, admin/dyjzow-4waRku-vugvef\n\n## Audit areas\n1. Port configuration (speed, duplex, PoE status)\n2. VLAN assignments (currently only VLAN 1 + Auto-Video 4089)\n3. Spanning tree config\n4. PoE power allocation and priorities\n5. Firmware version (currently 1.0.0.44 - check for updates)\n6. Logging and monitoring settings\n7. SFP port config (uplink to router)\n\n## Questions to answer\n- Is PoE correctly prioritized for APs?\n- Are there any port config issues (speed mismatches, errors)?\n- What should be documented in campbell.yaml switch section?\n- Is firmware current or needs update?","notes":"## Audit Complete (2025-12-28)\n\n### Switch Access\n- CLI: telnet port 60000 (hidden)\n- Password: in secrets (switch_password)\n- Firmware: 1.0.0.44\n\n### Port Mapping\n17 active ports identified via MAC table:\n- 8 APs: g7, g8, g9, g10, g12, g14, g15, g18\n- Infrastructure: g3 (kube), g13 (g3flex), g17 (infra-switch), g20 (hue), g21 (flex-mini), g24 (denappletv), g25 (router)\n- Smart home: g1, g19 (IKEA DIRIGERA hubs)\n\n### PoE: 36.8W of 190W budget (19%)\n\n### YAML: Updated with port mapping, tests pass","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T16:05:46.145479Z","updated_at":"2025-12-28T16:24:21.552401Z","closed_at":"2025-12-28T16:24:21.552403Z"}
{"id":"infra-openwrt-9tv","title":"Add per-AP ieee80211r override to YAML schema and generator","description":"loungeap needs 802.11r disabled for first-gen HomePod. Currently done via direct SSH, but reflashing will reset it. Need: 1) Add ieee80211r field to AccessPoint dataclass in infra_lib.py, 2) Update generate-ap-config.py to emit delete commands in generator section (after AP_NAME is set), 3) Add ieee80211r: false to loungeap in campbell.yaml","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T18:44:51.72586Z","updated_at":"2025-12-30T23:40:27.250514Z","closed_at":"2025-12-30T23:40:27.250514Z","close_reason":"Merged into z37 (global ft_over_ds='0' fix). Per-AP override noted as fallback if needed later."}
{"id":"infra-openwrt-9xm","title":"Parse guest_network.roaming in infra_lib.py","description":"campbell.yaml lines 104-105 define roaming section. Currently silently ignored. Add parsing.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-31T18:33:19.247005Z","updated_at":"2025-12-31T18:33:19.247005Z","labels":["tech-debt"],"dependencies":[{"issue_id":"infra-openwrt-9xm","depends_on_id":"infra-openwrt-uws","type":"parent-child","created_at":"2026-01-03T21:14:55.535648Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-openwrt-a74","title":"Harden shell=True in rf-scan.py","description":"Lines 111, 338, 352 use shell=True with f-strings. Convert to list form for security.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-31T18:33:18.129598Z","updated_at":"2025-12-31T18:33:18.129598Z","labels":["tech-debt"],"dependencies":[{"issue_id":"infra-openwrt-a74","depends_on_id":"infra-openwrt-uws","type":"parent-child","created_at":"2026-01-03T21:14:55.570286Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-openwrt-awu","title":"Centralized AP logging for WiFi diagnostics","description":"Drain logs from all APs to kube.lan for WiFi topology analysis and RF tuning diagnostics.\n\n## Goals\n- Centralized visibility into AP behavior across the house\n- Historical data for diagnosing roaming issues, interference, client problems\n- Grafana dashboards for WiFi health metrics\n\n## Key metrics to capture\n- Client associations/disassociations (roaming patterns)\n- Channel utilization and interference events\n- 802.11r fast transition success/failures\n- Signal strength reports (if available)\n- AQL queue depths and airtime fairness\n\n## Architecture\n- APs → syslog over UDP → kube.lan receiver → storage → Grafana","notes":"COMPLETED (this session):\n- Fixed syslog parser race condition (pre-create AP directories before parser starts)\n- Backfilled 70k events from all 7 APs (was only ashap due to tail -F glob timing)\n- Parser now following all APs going forward\n\nTELEMETRY STATE:\n- wifi-poller.service: running, 26k client metrics\n- syslog parser: running, 70k events backfilled\n- Baseline experiment: switched to treatment phase\n\nREMAINING:\n- xx8: Bake syslog forwarding into gold images (currently ephemeral UCI)","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-30T10:17:25.625809Z","updated_at":"2025-12-31T13:19:29.86432Z","closed_at":"2025-12-31T13:19:29.86432Z","close_reason":"Centralized AP logging complete. Syslog parser fixed (pre-create dirs), 70k events backfilled, all 7 APs streaming. Gold image bake tracked separately (xx8 closed)."}
{"id":"infra-openwrt-bmq","title":"Add analyze.py health command for AP memory/load trends","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-31T23:02:24.797941Z","updated_at":"2026-01-01T22:01:02.564998Z","closed_at":"2026-01-01T22:01:02.564998Z","close_reason":"Added analyze.py health command showing per-AP uptime, load, memory with trends and warnings. Deployed to kube.lan."}
{"id":"infra-openwrt-bnh","title":"Put signboard 2.4GHz fix in ansible","description":"Signboard forced to 2.4GHz via wpa-freq-list in /etc/network/interfaces. Works but not in ansible. Update infra-signboard ansible role to make this permanent and idempotent.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-30T21:25:10.086056Z","updated_at":"2025-12-30T21:25:10.086056Z"}
{"id":"infra-openwrt-bro","title":"Add ZyXEL GS1900-24HPv2 managed switch to infrastructure","design":"## Context\nReplacing unmanaged GS324 with OpenWRT-managed PoE switch. Enables VLAN guest network and per-port PoE control.\n\n## Hardware\n- ZyXEL GS1900-24HPv2: RTL8382M 500MHz, 128MB RAM, 16MB flash\n- 24x PoE+ ports (802.3at, 170W budget), 2x SFP\n- Target: realtek/rtl838x, Package arch: mips_4kec\n\n## Installation Method (OEM Web UI)\n1. Log into stock firmware at 192.168.1.1\n2. Maintenance \u003e Firmware \u003e Management → note active partition\n3. Maintenance \u003e Firmware \u003e Upload → upload initramfs-kernel.bin to OPPOSITE partition\n4. Select to boot from new image, reboot\n5. scp sysupgrade.bin to /tmp, run: sysupgrade -n /tmp/*.sysupgrade.bin\n\n## Gold Image Requirements\n- Packages: realtek-poe, luci, luci-app-poe (if exists), openssh-sftp-server\n- Network: Management IP in campbell network (172.17.2.x)\n- PoE: Default all ports enabled, persist in /etc/config/poe\n- Hostname: campbellswitch (or similar)\n- SSH keys: Same as AP gold images (from GitHub secret)\n\n## Integration with Existing Infra\n- Add to locations/campbell.yaml as new device type (switch)\n- May need hardware/switches/gs1900-24hp-v2.yaml\n- Update generate-dhcp-config.py if switch needs DHCP reservation\n\n## Acceptance Criteria\n- [ ] Gold image builds via GitHub Actions\n- [ ] Flash from stock firmware works via web UI\n- [ ] All 24 PoE ports controllable (on/off/status)\n- [ ] VLANs configurable for future guest network\n- [ ] Switch appears in ap-audit.py or new switch-audit.py\n- [ ] Recovery documented (TFTP method)","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-28T10:29:56.488388Z","updated_at":"2025-12-28T11:42:34.224295Z","closed_at":"2025-12-28T11:42:34.224295Z","close_reason":"Implementation complete: 18 files, 1219 lines. Tests passing. Commit c89d0c7."}
{"id":"infra-openwrt-btx","title":"Fix critical issues from codebase review","design":"## Context\nComprehensive codebase review identified multiple issues across build scripts, UCI configs, and validation. Fixing before next AP flash.\n\n## Approach\nFix in priority order:\n1. P0: Bugs that would break deployments\n2. P1: Robustness improvements\n\n## Acceptance Criteria\n- [ ] Lambourn WAN interface uses correct device ('wan' not 'eth2')\n- [ ] SQM config uses correct interface name for PPPoE routers\n- [ ] GitHub Actions have `set -e` in all run blocks\n- [ ] Secret placeholder validation after sed injection\n- [ ] README.md reflects YAML as source of truth (not device-mac-assignments)\n- [ ] imagebuilder/README.md removes nonexistent build script reference\n- [ ] TFTP recovery path corrected in docs\n- [ ] All changes tested with `uv run pytest tests/`","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-29T12:49:06.321061Z","updated_at":"2025-12-29T12:52:15.143728Z","closed_at":"2025-12-29T12:52:15.143728Z","close_reason":"Fixed all P0/P1 issues from codebase review:\n\nConfig fixes:\n- Lambourn WAN interface: eth2 → wan (would have broken connectivity)\n- SQM interface for Bristol/Lambourn: pppoe-wan → wan (SQM wouldn't activate)\n\nCI hardening:\n- Added set -e to all GitHub Actions run blocks (3 workflows, ~15 run blocks)\n- Added secret placeholder validation after sed injection (prevents CHANGE_ME_BEFORE_BUILD reaching production)\n\nDocumentation:\n- README.md: YAML is source of truth (not deprecated device-mac-assignments)\n- imagebuilder/README.md: Removed nonexistent build script, fixed TFTP recovery path\n\n59 tests pass."}
{"id":"infra-openwrt-c4u","title":"Infrastructure config is authoritative","status":"closed","priority":2,"issue_type":"epic","created_at":"2026-01-03T21:14:36.828621Z","updated_at":"2026-01-03T21:25:04.304577Z","closed_at":"2026-01-03T21:25:04.304577Z","close_reason":"All children complete: -tze (switch ports in YAML), -3l4 (radio mapping from HW YAML), -qma (per-AP ieee80211r override)"}
{"id":"infra-openwrt-c61","title":"Evaluate advanced WiFi settings (proxy_arp, bss_transition, multicast_to_unicast)","design":"After log collection is working, evaluate these settings with observability:\n\n**proxy_arp='1'**\n- AP answers ARP on behalf of clients\n- Reduces broadcast traffic\n- Low risk\n\n**bss_transition='1'** (802.11v)\n- AP can suggest clients roam to better AP\n- Medium risk - some devices don't like being told what to do\n\n**multicast_to_unicast='1'**\n- Converts multicast → unicast per client\n- More reliable but more airtime\n- Risk: HomePods use multicast for AirPlay\n\n**ieee80211k='1'**\n- Neighbor reports for roaming\n- Low risk - advisory only\n\nBlocked by: Log collection setup (need visibility before tuning)","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-29T15:27:39.665295Z","updated_at":"2025-12-29T15:27:39.665295Z","dependencies":[{"issue_id":"infra-openwrt-c61","depends_on_id":"infra-openwrt-woa","type":"blocks","created_at":"2025-12-29T15:27:51.37223Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-chp","title":"Flash switch with OpenWRT","description":"Flash via stock firmware web UI, then sysupgrade","design":"ISOLATED NETWORK (laptop direct to switch):\n1. Connect laptop to any port, set DHCP or 192.168.1.x\n2. Power on switch, wait 2 min\n3. http://192.168.1.1 (admin / 1234 or blank)\n4. Maintenance → Firmware → note active partition\n5. Upload initramfs-kernel.bin to OTHER partition\n6. Boot from new image, wait 2 min\n7. ssh-keygen -R 192.168.1.1\n8. ssh root@192.168.1.1\n9. scp -O *-sysupgrade.bin root@192.168.1.1:/tmp/\n10. sysupgrade -n /tmp/*-sysupgrade.bin\n11. Wait 2 min","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T11:43:19.783756Z","updated_at":"2025-12-30T18:17:35.725477Z","closed_at":"2025-12-30T18:17:35.725477Z","close_reason":"Cancelled - ZyXEL switch not being purchased. Using GS324TP with telnet CLI instead.","dependencies":[{"issue_id":"infra-openwrt-chp","depends_on_id":"infra-openwrt-l8h","type":"parent-child","created_at":"2025-12-28T11:43:33.257956Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-openwrt-chp","depends_on_id":"infra-openwrt-7f2","type":"blocks","created_at":"2025-12-28T11:43:34.496102Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-cow","title":"Extend ap-audit.py to check policy settings","description":"Audit tool currently checks channels/power/htmode. Extend to verify policy settings (min rates, 802.11k/v, AQL).","design":"## Current ap-audit.py checks\n- Channel (5GHz and 2.4GHz)\n- TX power\n- htmode\n- Hostname\n- 2.4GHz disabled state\n- AQL settings\n\n## Need to add checks for\n- basic_rate / supported_rates (min data rates)\n- ieee80211k, rrm_neighbor_report\n- ieee80211v, bss_transition\n- Potentially TXOP if we set it\n\n## Approach\n1. Add expected values to campbell.yaml wireless section\n2. Extend audit to query these via UCI over SSH\n3. Compare and report gaps","acceptance_criteria":"- [ ] ap-audit.py checks cell_density (2 for 2.4GHz, 3 for 5GHz)\n- [ ] ap-audit.py checks ieee80211k enabled on interfaces\n- [ ] Audit runs clean on all 7 APs after policy push\n- [ ] (DEFERRED) 802.11v checks - requires wpad-mbedtls (Part B)","notes":"SCOPE CHANGE: Removed 802.11v from acceptance criteria.\nwpad-basic-mbedtls doesn't support bss_transition/wnm_sleep_mode.\nWill add 802.11v checks after Part B deploys wpad-mbedtls.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-31T14:32:25.780906Z","updated_at":"2025-12-31T15:54:02.970911Z","closed_at":"2025-12-31T15:54:02.970911Z","close_reason":"Extended ap-audit.py to check policy settings (cell_density, ieee80211k). All 7 online APs show compliant. Added PolicyConfig to infra_lib.py and policy section to campbell.yaml - no hardcoded values in audit.","dependencies":[{"issue_id":"infra-openwrt-cow","depends_on_id":"infra-openwrt-49y","type":"blocks","created_at":"2025-12-31T14:32:36.872575Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-openwrt-cow","depends_on_id":"infra-openwrt-4gi","type":"parent-child","created_at":"2025-12-31T14:32:36.906538Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-cua","title":"Create router-config-check.sh to validate live routers against YAML","design":"Validates running router config matches locations/*.yaml.\n\nChecks (reading expected from YAML via yaml-extract.py):\n- ControlD running and resolver ID matches\n- ACME cert exists for domain\n- SQM active (tc qdisc show | grep cake)\n- Local DNS domains configured (all APs)\n- DHCP reservations match YAML count\n\nVerification tests:\n- DNS filtering works (dig doubleclick.net returns 0.0.0.0)\n- Internal DNS resolves (nslookup ashap.planetmodha.com)\n\nReference: Plan file ~/.claude/plans/iterative-percolating-stonebraker.md Phase 6","notes":"Created router-config-check.sh that validates ControlD, ACME, SQM, local DNS, and DHCP reservations against YAML. Found Campbell router is missing ACME certs and DNS filtering isn't working despite ControlD running - confirms the silent failure mode mentioned in handoff.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-25T16:48:30.957171Z","updated_at":"2025-12-25T17:10:02.824437Z","closed_at":"2025-12-25T17:10:02.824452Z"}
{"id":"infra-openwrt-cz3","title":"Fix bathflex 0 dBm parsing in wifi_poller.py","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-31T17:59:05.046925Z","updated_at":"2025-12-31T17:59:05.046925Z","labels":["telemetry"],"dependencies":[{"issue_id":"infra-openwrt-cz3","depends_on_id":"infra-openwrt-uws","type":"parent-child","created_at":"2026-01-03T21:14:55.466132Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-openwrt-d87","title":"Re-survey with normalized power before RF planning","description":"Current RF survey was done with iteration 005 power limits already applied. For accurate planning, should re-survey with all APs at equal power (e.g., 50%) to get unbiased signal strength data between APs.","design":"1. Set all APs to equal TX power (e.g., 14dBm for 5GHz, 10dBm for 2.4GHz)\n2. Wait 5 minutes for radios to stabilize\n3. Run rf-scan.py\n4. Re-run rf-planner-v2.py with new data\n5. Restore current power settings","acceptance_criteria":"- [ ] All APs at normalized power (12dBm 5GHz, 10dBm 2.4GHz)\n- [ ] rf-scan.py run from all APs\n- [ ] Results saved as iteration 006\n- [ ] Survey data saved to rf-optimization/data/","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-31T13:11:19.928601Z","updated_at":"2025-12-31T15:57:45.017296Z","closed_at":"2025-12-31T15:57:45.017296Z","close_reason":"RF survey completed with normalized power (12dBm 5GHz on all APs). Results saved to rf-optimization/data/iteration-006/rf-scan-results.json","dependencies":[{"issue_id":"infra-openwrt-d87","depends_on_id":"infra-openwrt-cow","type":"blocks","created_at":"2025-12-31T14:32:36.937461Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-openwrt-d87","depends_on_id":"infra-openwrt-4gi","type":"parent-child","created_at":"2025-12-31T14:32:36.968947Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-db6","title":"Research: Log aggregation options for kube.lan","description":"Evaluate log receiver/storage options that can run on kube.lan:\n\nOptions to consider:\n- Loki + Promtail (Grafana native, lightweight)\n- rsyslog + file storage (simple, traditional)\n- Vector + ClickHouse (powerful but heavier)\n- Graylog (feature-rich but Java-heavy)\n\nCriteria:\n- Resource footprint (kube.lan is modest hardware)\n- Grafana integration quality\n- Query capability for WiFi-specific analysis\n- Ease of setup and maintenance\n\nDeliverable: Recommended stack with rationale.","notes":"Deferred: Went straight to practical experimentation rather than completing research sequence. Captured real data, fixed signboard, wrote overnight briefs that include stack recommendations. The briefs (overnight-brief-A-data-architecture.md) cover this ground.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T10:17:58.758061Z","updated_at":"2025-12-30T23:26:59.363489Z","closed_at":"2025-12-30T23:26:59.363489Z","close_reason":"Answered by Compass research doc (wf-2a5ace60): SQLite on kube.lan, SSH ControlMaster polling, syslog UDP forwarding. Full schema and implementation provided.","dependencies":[{"issue_id":"infra-openwrt-db6","depends_on_id":"infra-openwrt-awu","type":"parent-child","created_at":"2025-12-30T10:18:13.944257Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-e9o","title":"Made definitive Router Configs for all routers","status":"open","priority":2,"issue_type":"epic","created_at":"2026-01-03T21:27:51.353624Z","updated_at":"2026-01-03T21:27:51.353624Z"}
{"id":"infra-openwrt-eep","title":"Investigate gardenap (EAP225) flash failure","description":"Flashed gardenap with new image during Dec 30 rollout. Device never came back online after 15+ minutes. All other APs (Unifi 6-lite, nanoHD) worked fine. EAP225 is ath79 platform vs ramips for Unifi. Need physical inspection of device LEDs and possible TFTP recovery.","notes":"## Investigation Steps\n\n1. **Physical check:**\n   - Check LED status (solid/blinking/off?)\n   - Power cycle and observe boot sequence\n   - Note any unusual LED patterns\n\n2. **Network check:**\n   - `ping 172.17.2.26` — still down?\n   - Check switch port (g15) — link light?\n   - Try different port\n\n3. **If still unresponsive — TFTP recovery:**\n   - EAP225 uses TP-Link recovery mode\n   - See: https://openwrt.org/toh/tp-link/eap225\n   - May need to flash back to stock first\n\n4. **ath79 platform notes:**\n   - Different from ramips (Unifi APs)\n   - Firstboot timing may differ\n   - Check if image built correctly (binwalk)\n\n## Context\nFlashed during Dec 30 rollout. All 7 Unifi APs (ramips) worked fine.\ngardenap is the only EAP225 (ath79) and never came back after flash.","status":"open","priority":3,"issue_type":"bug","created_at":"2025-12-30T09:41:48.031078Z","updated_at":"2025-12-30T18:55:01.130575Z","dependencies":[{"issue_id":"infra-openwrt-eep","depends_on_id":"infra-openwrt-7hq","type":"parent-child","created_at":"2026-01-03T21:14:56.943561Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-openwrt-f7n","title":"Apply rf-planner-v2 output via UCI","description":"Test the new 2.4GHz plan by applying rf-planner-v2 output to live APs. Changes: enable 2.4GHz on loungeap/denap, disable on isaacap/gardenap.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-31T13:19:46.921289Z","updated_at":"2025-12-31T16:14:03.581082Z","closed_at":"2025-12-31T16:14:03.581082Z","close_reason":"UCI commands pushed to all 7 online APs. Audit shows 6/7 compliant (loungeap has pre-existing 802.11r gap)."}
{"id":"infra-openwrt-gex","title":"Add analyze.py randomized command for discovering random MAC devices","description":"Make the random MAC discovery repeatable as a command instead of one-off markdown. Should show traffic, AP patterns, and hints about device identity.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-02T14:33:19.928931Z","updated_at":"2026-01-02T21:13:49.533198Z","closed_at":"2026-01-02T21:13:49.533198Z","close_reason":"Added 'randomized' command to analyze.py - shows randomized MAC devices with traffic, AP patterns, and identity hints"}
{"id":"infra-openwrt-gxw","title":"Redistribute 5GHz channels per research allocation","description":"Current: 4 APs crammed into UNII-2A (52-64) sharing one 80MHz channel. Need to spread across UNII-1, UNII-2A, UNII-2C, UNII-3.","design":"## Recommended Allocation (40MHz)\n| AP | Channel | Band | DFS Risk |\n|----|---------|------|----------|\n| 1 | 36 | UNII-1 | None |\n| 2 | 44 | UNII-1 | None |\n| 3 | 149 | UNII-3 | None |\n| 4 | 157 | UNII-3 | None |\n| 5 | 52 | UNII-2A | Medium |\n| 6 | 60 | UNII-2A | Medium |\n| 7 | 100 | UNII-2C | Lower |\n| 8 | 108 | UNII-2C | Lower |\n\nPrioritize non-DFS (36, 44, 149, 157) for latency-sensitive locations.\n\n## Implementation\nMap AP names to channels based on location priority, update locations/campbell.yaml","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-30T23:26:36.677337Z","updated_at":"2025-12-31T12:32:03.794607Z","closed_at":"2025-12-31T12:32:03.794607Z","close_reason":"Applied via UCI: channels redistributed per solver (36,44,52,60,108,149,157). Zero co-channel interference.","dependencies":[{"issue_id":"infra-openwrt-gxw","depends_on_id":"infra-openwrt-4gi","type":"parent-child","created_at":"2025-12-30T23:26:50.459122Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-hda","title":"Add ocv=0 to guest wireless config","description":"LuCI added ocv='0' (Operating Channel Validation disabled) when PSK was changed manually. Should add to gold image for guest wireless - improves compatibility with older devices.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T11:49:53.890114Z","updated_at":"2025-12-30T18:06:47.637712Z","closed_at":"2025-12-30T18:06:47.637712Z","close_reason":"Already implemented - ocv='0' is set for both main wireless (line 70) and guest wireless (line 86) in the template."}
{"id":"infra-openwrt-hwp","title":"Add kube.lan SSH key to all APs","description":"SSH keys added ad-hoc to ashap, loungeap, denap during capture experiments. Add to remaining 5 APs (kitchenap, frontap, guestap, isaacap, gardenap) for consistency. Key: ssh-ed25519 ...INcF0E6V... modha@kube","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-30T21:25:08.581599Z","updated_at":"2025-12-31T00:03:56.674933Z","closed_at":"2025-12-31T00:03:56.674933Z","close_reason":"Added kube.lan SSH key to kitchenap, frontap, isaacap. Already present on ashap, loungeap, guestap, denap. gardenap unreachable (EAP225 flash failure - bead eep). 7/8 APs now reachable from kube.lan."}
{"id":"infra-openwrt-ico","title":"Bake local DNS entries into gold image to eliminate post-flash step","design":"Move local DNS overrides from post-flash-router.sh into firstboot script, generated from YAML at build time.\n\nCurrent pain: post-flash-router.sh is manual and easy to skip/forget. Campbell was running without local DNS for who-knows-how-long.\n\nSolution: Generate DNS entries from locations/*.yaml at image build time and inject into firstboot script.\n\nThis eliminates the \"remember to run post-flash\" failure mode.\n\nRequires: CF_TOKEN in GitHub Secrets (already added in Phase 0)\nReference: Plan file ~/.claude/plans/iterative-percolating-stonebraker.md Phase 7","notes":"Added local DNS generation to generate-dhcp-config.py. Now generates UCI domain entries for router and all APs at build time, eliminating the need for manual post-flash-router.sh DNS setup. Updated build-router-images.sh to remove deprecated markdown device list dependency. Added tests for DNS generation. 36 tests passing.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-25T16:48:43.835501Z","updated_at":"2025-12-25T17:13:14.808746Z","closed_at":"2025-12-25T17:13:14.808757Z"}
{"id":"infra-openwrt-jm2","title":"Switch 5GHz from 80MHz to 40MHz channels","description":"At 80MHz, only 6 non-overlapping 5GHz channels exist. With 8 APs, guaranteed overlap. At 40MHz, get 12 channels - enough for all APs. Wider channels also raise noise floor by 3dB per doubling.","design":"## Change\n- htmode: HE80 → HE40 (or VHT40 if HE40 causes MT7915 quirks)\n- Update locations/campbell.yaml RF settings\n- Rebuild AP images\n\n## Verification\n- iw dev wlanX info shows 40MHz width\n- ap-audit.py confirms htmode","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-30T23:26:34.188378Z","updated_at":"2025-12-31T12:32:03.7587Z","closed_at":"2025-12-31T12:32:03.7587Z","close_reason":"Applied via UCI: all APs now on 40MHz (HE40/VHT40). Verified with ap-audit.","dependencies":[{"issue_id":"infra-openwrt-jm2","depends_on_id":"infra-openwrt-4gi","type":"parent-child","created_at":"2025-12-30T23:26:50.414135Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-jwn","title":"Validate Bristol with re-deploy","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-03T21:28:02.879307Z","updated_at":"2026-01-03T21:28:02.879307Z","dependencies":[{"issue_id":"infra-openwrt-jwn","depends_on_id":"infra-openwrt-e9o","type":"parent-child","created_at":"2026-01-03T21:28:11.112451Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-openwrt-kk0","title":"Fix rf-scan.py --json to output clean JSON without log messages","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-24T18:02:56.090734Z","updated_at":"2026-01-02T21:11:30.190506Z","closed_at":"2026-01-02T21:11:30.190506Z","close_reason":"Added --json flag that suppresses progress messages for clean programmatic output"}
{"id":"infra-openwrt-kmp","title":"Set minimum data rate to 12-24 Mbps","description":"Disabling low data rates shrinks cell size and reduces airtime consumption by slow clients. Phase 2 refinement after power/channel changes.","design":"## Options\n- 12 Mbps: Conservative, ensures IoT compatibility\n- 24 Mbps: More aggressive cell shrinking\n\n## Implementation\nIn hostapd config:\noption basic_rate '12000 24000 36000 48000 54000'\noption supported_rates '12000 18000 24000 36000 48000 54000'\n\n## Risk\nSome legacy IoT devices may not connect. Test with IoT SSID separately.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T23:26:40.547373Z","updated_at":"2025-12-31T13:19:31.769627Z","closed_at":"2025-12-31T13:19:31.769627Z","close_reason":"Superseded by rf-planner-v2 (nv6). min_rate_2g=12, min_rate_5g=24 now included in planner output.","dependencies":[{"issue_id":"infra-openwrt-kmp","depends_on_id":"infra-openwrt-4gi","type":"parent-child","created_at":"2025-12-30T23:26:50.525631Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-ku9","title":"Auto-sync campbell.yaml to kube.lan on changes","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-31T17:59:06.383171Z","updated_at":"2025-12-31T17:59:06.383171Z","labels":["telemetry"],"dependencies":[{"issue_id":"infra-openwrt-ku9","depends_on_id":"infra-openwrt-uws","type":"parent-child","created_at":"2026-01-03T21:17:54.444203Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-openwrt-l7s","title":"Legacy SSID for old HomePod (no 802.11r)","description":"Old HomePod can't connect with 802.11r enabled. Need a separate SSID on loungeap (or dedicated AP) that:\n- No 802.11r (no mobility_domain, no ft_over_ds)\n- Same VLAN as main network (transparent)\n- Only the HomePod uses it\n- Everything else stays on Antimatter with 802.11r\n\nOptions:\n1. Second SSID on loungeap (phy0-ap1) with 802.11r disabled\n2. Dedicated AP for legacy devices\n3. loungeap becomes the legacy AP, others handle roaming","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-03T21:37:56.741961Z","updated_at":"2026-01-03T21:37:56.741961Z","dependencies":[{"issue_id":"infra-openwrt-l7s","depends_on_id":"infra-openwrt-7hq","type":"parent-child","created_at":"2026-01-03T21:38:08.838298Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-openwrt-l8h","title":"Commission ZyXEL GS1900-24HPv2 switch at Campbell","description":"Physical deployment when switch arrives. Runbook: docs/switch-deployment-runbook.md","design":"Trigger: Switch arrives (\"le nouveau switch est arrivé\")\n\nPhases in dependency order - each must complete before next:\n1. Record MAC \u0026 update YAML (both places)\n2. Build switch image via GitHub Actions\n3. Flash switch (isolated network)\n4. Connect to network \u0026 verify\n5. Physical cutover from GS324\n\nRunbook has full checklist. Each phase is a child bead.","notes":"BLOCKED: ZyXEL GS1900-24HPv2 hardware not yet arrived. Currently using GS324TP for VLAN config.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-28T11:42:47.649236Z","updated_at":"2025-12-30T10:29:00.548039Z","closed_at":"2025-12-30T10:29:00.548039Z","close_reason":"Cancelled - GS324TP telnet CLI provides sufficient management. ZyXEL switch no longer needed. Archived all related files."}
{"id":"infra-openwrt-lfp","title":"Load AP_HOSTS from campbell.yaml instead of hardcoded dict","description":"wifi_poller.py has hardcoded AP_HOSTS dict. Should use infra_lib.load_location() for consistency. Requires either: (1) copy infra_lib to kube.lan, or (2) generate AP list at deploy time.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-31T00:09:24.898996Z","updated_at":"2025-12-31T00:09:24.898996Z"}
{"id":"infra-openwrt-m2g","title":"Deploy log receiver on kube.lan","description":"Set up the chosen log aggregation stack on kube.lan.\n\nTasks:\n- Install and configure receiver (Loki/rsyslog/etc)\n- Set up storage with appropriate retention\n- Configure firewall to accept syslog from AP subnet\n- Test with manual logger command from one AP\n- Verify logs are being stored and queryable\n\nDepends on: Log aggregation research complete.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T10:18:34.374826Z","updated_at":"2025-12-30T23:59:11.651101Z","closed_at":"2025-12-30T23:59:11.651101Z","close_reason":"Deployed SQLite + SSH polling to kube.lan. Daemon running (wifi-poller.service). 3/8 APs responding, deltas computing, retry rates visible. Syslog forwarding configured on kube but not yet enabled on APs.","dependencies":[{"issue_id":"infra-openwrt-m2g","depends_on_id":"infra-openwrt-awu","type":"parent-child","created_at":"2025-12-30T10:18:43.130614Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-openwrt-m2g","depends_on_id":"infra-openwrt-db6","type":"blocks","created_at":"2025-12-30T10:18:43.15932Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-mnx","title":"Implement nginx reverse proxy for AP SSL termination","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-25T18:38:30.57684Z","updated_at":"2025-12-25T21:01:31.156703Z","dependencies":[{"issue_id":"infra-openwrt-mnx","depends_on_id":"infra-openwrt-7hq","type":"parent-child","created_at":"2026-01-03T21:14:56.977484Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-openwrt-mwr","title":"Add telemetry data retention policy to prevent unbounded table growth","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-31T23:02:25.695673Z","updated_at":"2026-01-01T22:01:01.405468Z","closed_at":"2026-01-01T22:01:01.405468Z","close_reason":"Added 30-day retention policy. delete_old_data() runs on daemon startup and hourly, deletes from client_metrics, ap_system_metrics, events tables."}
{"id":"infra-openwrt-nn1","title":"Investigate frontap SSH transient connection refused","description":"During /close session 2026-01-02, frontap (172.17.2.25) refused SSH connection but was pingable. Worked on retry. Monitor for pattern.","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-02T19:48:54.659413Z","updated_at":"2026-01-02T21:32:04.781288Z","closed_at":"2026-01-02T21:32:04.781288Z","close_reason":"SSH working, uptime 2d+, dropbear healthy. Likely one-off. Discovered separate issue: frontap 2.4GHz enabled but should be disabled — needs reflash or manual fix.","labels":["infra"]}
{"id":"infra-openwrt-nne","title":"Research: OpenWRT WiFi logging options and formats","description":"Investigate what WiFi-specific logs OpenWRT can produce:\n\n- What does hostapd log by default vs with debug enabled?\n- Are there structured log options (JSON)?\n- What kernel messages relate to MT7915/MT7621 drivers?\n- Can we get per-client RSSI, SNR, data rates?\n- What does 802.11r log on FT events?\n- Are there existing tools (usteer, dawn) that produce useful telemetry?\n\nDeliverable: Summary of available log sources and recommended verbosity settings.","notes":"## Research Summary (2025-12-30)\n\n### Key Finding: Two data sources required\n1. **Event stream (syslog)**: Auth/deauth, PSK failures, RF issues\n2. **State polling (iw/ubus)**: Signal, bitrate, airtime, retries\n\n### What's in syslog (default level 2):\n- Client auth/deauth with MAC addresses\n- PSK mismatch warnings\n- \"did not acknowledge\" (RF issues)\n- NO signal strength, NO 802.11r FT events\n\n### What's in syslog (debug level 0-1):\n- MLME messages for reassociation\n- FT indicator: \"WPA: FT authentication already completed\"\n- Still no per-packet RSSI\n\n### What's in iw station dump (polling):\n- Signal: -42 [-51, -42] dBm (per-antenna!)\n- Bitrate: 72.2 MBit/s MCS 7 short GI\n- tx retries/failures: 34456 / 2311\n- Airtime: tx_duration, rx_duration\n- Expected throughput: 58.868Mbps\n\n### What's in ubus get_status (polling):\n- Airtime utilization: 91%\n- WNM counters (bss_transition_*)\n- RRM counters (neighbor_report_tx)\n- Channel, frequency, DFS status\n\n### usteer (not installed):\nWould add roam_events, per-client signal in JSON via ubus.\nAdds ~1MB to image. Designed for active steering, not just observation.\n\n### Architecture options documented:\nTier 0: rsyslog → file → grep (30 min)\nTier 1: Loki (events) + polling script → Prometheus (metrics) (half day)\nTier 2: Vector unified pipeline (day+)\n\n### Output:\nResearch brief at rf-optimization/docs/logging-research-brief.md\nSuitable for claude.ai deep research prompt.\n\n### Next:\n- db6 research (log aggregation stack for kube.lan)\n- Prototype Tier 1 approach","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T10:17:37.274372Z","updated_at":"2025-12-30T19:07:00.21825Z","closed_at":"2025-12-30T19:07:00.21825Z","close_reason":"Research complete. Key finding: two data sources required (syslog for events, polling for metrics). Research brief at rf-optimization/docs/logging-research-brief.md.","dependencies":[{"issue_id":"infra-openwrt-nne","depends_on_id":"infra-openwrt-awu","type":"parent-child","created_at":"2025-12-30T10:17:48.076497Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-nqx","title":"Wireless channel and width optimization","design":"Analyze and optimize wireless settings across all Campbell APs.\n\n**Current state to analyze:**\n- Channel allocation (which APs on which channels)\n- Channel widths (HT20 for 2.4GHz, VHT40/80 for 5GHz)\n- Interference between APs\n- Scan for neighboring networks\n\n**Goals:**\n- Minimize co-channel interference between our own APs\n- Avoid congested channels from neighbors\n- Appropriate channel widths for each band\n- Document optimal channel plan\n\n**Approach:**\n- Dump iwinfo from each AP (channels in use, signal levels)\n- Scan for neighboring APs from each location\n- Analyze overlap and recommend channel assignments\n- Consider physical AP locations in the house","notes":"Subsumed by infra-openwrt-uws.3 (Channel, width, and power optimization). Work will continue under the WLUL epic.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T09:11:48.063447Z","updated_at":"2025-12-24T21:12:01.101499Z","closed_at":"2025-12-24T21:12:01.101499Z","close_reason":"Completed as part of WLUL epic. Channel plan optimized in iteration-004, escaped The_Clacks interference, documented in manifest."}
{"id":"infra-openwrt-nv6","title":"RF Planner v2: geography-aware complete RF config tool","description":"Create rf-planner-v2.py that outputs complete RF config (channels + power + 802.11r + min-rates) using geography data. Supersedes manual z37/kmp work.","design":"## Inputs\n- locations/campbell.yaml with geography: {room, storey} per AP\n- rf-scan-results.json for signal data + neighbors\n- IoT anchor points (doorbell→Room 0, Honeywell→Room 1, washers→Room 3)\n\n## Algorithm\n1. Load APs with geography\n2. Select 3 2.4GHz anchors (max 1 per room column, prefer IoT coverage)\n3. Assign 2.4GHz channels (graph color, avoid loud neighbors on ch11)\n4. Run 5GHz solver (existing logic)\n5. Calculate power (vertical stack reduction)\n6. Add 802.11r settings (ft_over_ds=0)\n7. Add min data rates (12-24 Mbps)\n\n## Output\nComplete RF config + UCI commands","acceptance_criteria":"- [ ] Geography added to campbell.yaml (room/storey per AP)\n- [ ] infra_lib.py parses geography field\n- [ ] rf-planner-v2.py created with anchor selection\n- [ ] 2.4GHz channel assignment with neighbor avoidance\n- [ ] 5GHz planning integrated (reuse existing solver)\n- [ ] Power calculation for vertical stacks\n- [ ] 802.11r and min-rate settings in output\n- [ ] Unit tests for scoring functions\n- [ ] Integration test with rf-scan-results.json\n- [ ] Generate and compare to iteration 005","notes":"COMPLETED:\n- Geography added to campbell.yaml (room 0-4, storey 0-2, is_outdoor)\n- infra_lib.py parses Geography dataclass\n- rf_planner_v2.py created with:\n  - 2.4GHz anchor selection (max 1 per room column, IoT-weighted)\n  - Channel assignment (ch1/6/11 with neighbor penalty)\n  - 5GHz solver integration (from channel_planner_lib.py)\n  - Power calculation (vertical stack reduction)\n  - 802.11r + min-rate settings\n  - Markdown, JSON, and UCI output formats\n- channel_planner_lib.py extracted for code reuse\n- 11 tests passing (unit + integration)\n\nRESULT:\nCurrent 2.4GHz: kitchenap(R3), isaacap(R3), gardenap(R4-offline)\n  → Problem: 2 anchors in same room column, 1 offline\nProposed: loungeap(R0), denap(R1), kitchenap(R3)\n  → Fix: Spreads across 3 room columns, covers all IoT anchor points\n\nREADY TO CLOSE - all acceptance criteria met","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-31T13:01:50.117119Z","updated_at":"2025-12-31T13:15:49.528774Z","closed_at":"2025-12-31T13:15:49.528774Z","close_reason":"RF Planner v2 complete. Geography-aware 2.4GHz anchor selection, 5GHz solver integration, power/802.11r/min-rate output. 11 tests passing. Proposes better 2.4GHz plan: loungeap/denap/kitchenap spread across rooms 0/1/3 vs current isaacap/kitchenap (same room) + gardenap (offline)."}
{"id":"infra-openwrt-oi5","title":"Packet steering performance test","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-20T08:29:50.06887Z","updated_at":"2025-12-30T23:19:07.238125Z","deleted_at":"2025-12-30T23:19:07.238125Z","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"infra-openwrt-olw","title":"Made kube.lan the central traffic log drain for the network","description":"Consolidate traffic volume logging onto kube.lan instead of running on router. kube.lan is becoming chief log drain for everything.\n\nPreviously: software on router did this\nNow: kube.lan has capacity and is already receiving WiFi telemetry\n\n## Constraints\n- Don't disrupt existing WiFi telemetry\n- kube.lan has other duties (NVR, telemetry, etc)","design":"## Approach\nTBD - need to research options for traffic logging that can receive from OpenWRT\n\n## Open Questions\n- What format does OpenWRT export traffic stats?\n- NetFlow? sFlow? Something else?\n- What receiver/aggregator on kube.lan?","status":"open","priority":2,"issue_type":"epic","created_at":"2026-01-04T12:10:06.648062Z","updated_at":"2026-01-04T12:10:06.648062Z"}
{"id":"infra-openwrt-ons","title":"Research realtek-poe package and PoE UCI config","description":"Understand how PoE control works under OpenWRT for RTL838x switches","notes":"COMPLETED: Full research on realtek-poe package\n\n## Key Findings\n\n### Package Status\n- `realtek-poe` is auto-included as device package for GS1900-24HPv2\n- Source: https://github.com/Hurricos/realtek-poe\n- No additional packages needed in gold image manifest\n\n### UCI Config (/etc/config/poe)\n```\nconfig global\n    option budget '170'\n\nconfig port\n    option enable  '1'      # 1=on, 0=off\n    option id      '1'      # Port number\n    option name    'lan1'   # Interface name\n    option poe_plus '1'     # 1=PoE+ (30W), 0=PoE (15.4W)\n    option priority '2'     # Lower = higher priority\n```\n\n### ubus Commands\n- `ubus call poe info` — status, consumption, per-port details\n- `ubus call poe manage '{\"port\":\"lan3\",\"enable\":true}'` — toggle power\n- `ubus call poe reload` — apply config changes\n- Service auto-reloads on /etc/config/poe changes (procd trigger)\n\n### LuCI Support\n- NO luci-app-poe exists — PoE is CLI/ubus only\n- Could create simple status page in future if needed\n\n### Gold Image Implications\n1. realtek-poe package: already included\n2. Need to generate /etc/config/poe with 24 port entries\n3. Port mapping: physical 1-24 → lan1-lan24\n4. SFP ports 25-26 have no PoE","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T10:30:10.003524Z","updated_at":"2025-12-28T10:39:14.587715Z","closed_at":"2025-12-28T10:39:14.587715Z","close_reason":"Research complete: realtek-poe auto-included, UCI config documented, ubus commands mapped, no LuCI app available","dependencies":[{"issue_id":"infra-openwrt-ons","depends_on_id":"infra-openwrt-bro","type":"parent-child","created_at":"2025-12-28T10:30:27.309997Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-opx","title":"Create WiFi floorplan mapping with Wifiman","description":"Use Wifiman app to capture actual coverage data from floorplans. Will inform future RF tuning iterations.","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-25T11:23:41.366257Z","updated_at":"2025-12-25T21:01:31.626553Z","dependencies":[{"issue_id":"infra-openwrt-opx","depends_on_id":"infra-openwrt-uws","type":"parent-child","created_at":"2026-01-03T21:14:55.395738Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-openwrt-qma","title":"Add per-AP override support to ap-audit.py","description":"ap-audit.py shows loungeap as GAPS because 802.11r is intentionally disabled. Need: 1) Read per-AP overrides from YAML (once ieee80211r field exists), 2) Adjust expected values based on overrides, 3) No false positives for intentional config differences","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-30T18:44:52.525392Z","updated_at":"2025-12-30T18:44:52.525392Z","dependencies":[{"issue_id":"infra-openwrt-qma","depends_on_id":"infra-openwrt-c4u","type":"parent-child","created_at":"2026-01-03T21:14:59.380697Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-openwrt-rd2","title":"Fix campbell.yaml formatting after PyYAML mangle","description":"PyYAML stripped quotes from MAC addresses when updating device names. Restore consistent formatting - quotes around MACs, consistent indentation.","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-02T14:33:20.727337Z","updated_at":"2026-01-02T20:54:15.143872Z","closed_at":"2026-01-02T20:54:15.143872Z","close_reason":"Restored key comments to campbell.yaml via forward-fix. Added PyYAML warning to CLAUDE.md. Tests pass.","labels":["tech-debt"]}
{"id":"infra-openwrt-rox","title":"Add ap_metrics collection to wifi_poller.py","description":"Schema has ap_metrics table for radio-level stats (channel, utilization, noise floor) from ubus hostapd.wlanX get_status. Poller currently only collects client_metrics. Add AP-level polling to complete schema coverage.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-31T00:09:33.092111Z","updated_at":"2025-12-31T00:09:33.092111Z"}
{"id":"infra-openwrt-stz","title":"Centralized SSH Key Management","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"open","priority":3,"issue_type":"epic","created_at":"2025-12-20T08:29:40.549585Z","updated_at":"2025-12-30T18:23:54.390285Z","dependencies":[{"issue_id":"infra-openwrt-stz","depends_on_id":"infra-openwrt-7hq","type":"parent-child","created_at":"2026-01-03T21:14:57.044092Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-openwrt-tze","title":"Make switch config authoritative for port assignments","description":"Design gs324tp_ports in locations/campbell.yaml as canonical source for port→device mapping, VLANs, PoE settings.\n\nCurrently we have gs324tp_vlans (which VLANs are tagged where) but no port inventory. To answer \"what's on port g12?\" requires either checking the switch or remembering.\n\nBenefits:\n- Single source of truth for physical topology\n- Could generate documentation automatically\n- Helps troubleshooting (\"is the TV on a PoE port?\")\n- Consistency with AP config approach (YAML → generator → config)\n\nNote: GS324TP is Netgear managed switch, not OpenWRT. Config is manual via telnet CLI, not generated. So this is documentation/audit, not deployment automation.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-30T19:12:16.335475Z","updated_at":"2025-12-30T19:12:16.335475Z","dependencies":[{"issue_id":"infra-openwrt-tze","depends_on_id":"infra-openwrt-c4u","type":"parent-child","created_at":"2026-01-03T21:14:59.416833Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-openwrt-u3k","title":"Fix 6 failing CI validation tests","description":"Validate workflow failing on main. Tests need updating to match iteration 005 YAML values.","acceptance_criteria":"- [ ] test_extracts_rf_channel passes (ch36 not ch44)\n- [ ] test_aps_have_rf_settings passes\n- [ ] test_generates_lookup_for_unifi_models passes\n- [ ] test_load_switch_hardware passes (create missing switch YAML)\n- [ ] test_switch_hardware_has_packages passes\n- [ ] test_all_placeholders_have_workflow_coverage passes\n- [ ] CI green on main","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-31T15:15:24.892273Z","updated_at":"2025-12-31T16:18:44.167299Z","closed_at":"2025-12-31T16:18:44.167299Z","close_reason":"All 6 tests fixed: updated channel assertions (ch44→100), created gs1900-24hp-v2.yaml, updated RF/EAP225 tests for iteration 006, moved files-gs1900 to archive. 72 tests pass."}
{"id":"infra-openwrt-uws","title":"Wireless Latency Under Load (WLUL) Optimization","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","notes":"SESSION: 2025-12-24 (continued)\n\nITERATION-005 COMPLETE:\n- AQL tuning: tested default (5000/12000), 2000/2000, 1500/1500\n- Deployed AQL 2000/2000 to all 7 APs via /etc/rc.local\n- Latency improvement: 122ms → 65-75ms bidirectional (38-48% reduction)\n- TXOP tuning tested (wmm_ac_be_txop_limit=94) - no benefit, added jitter, not deployed\n\nKEY DISCOVERIES:\n- AQL is the main user-accessible lever for WiFi latency\n- Download latency dramatically improved (63ms → 14ms under load)\n- Upload latency unchanged (~45-50ms) - queue is on client (macOS), not AP\n- Measurement variability ~20ms between runs - need longer tests for A/B\n\nCURRENT STATE:\n- Channel plan optimized (iteration-004)\n- Power tuned for vertical stacks\n- AQL 2000/2000 deployed and persisted\n- Bidirectional latency: 65-75ms (was 122ms default, 137ms baseline)\n\nNEXT LEVERS:\n- CoDel tuning requires custom OpenWRT build (knobs not exposed)\n- Client-side tuning (macOS) could help upload but limited options\n- Monitor for throughput complaints (slight reduction expected)","status":"open","priority":2,"issue_type":"epic","created_at":"2025-12-24T07:26:19.40496Z","updated_at":"2025-12-25T21:01:32.545017Z"}
{"id":"infra-openwrt-uws.1","title":"Set up WLUL testing toolchain","design":"Get all testing tools operational for reproducible latency measurements.\n\n## kube.lan (Debian 12 - test server)\n- [x] FLENT 2.1.1 installed\n- [x] irtt installed\n- [ ] Install iperf3: `sudo apt install iperf3`\n- [ ] Start irtt server for persistent testing\n- [ ] Either: Build netperf from source OR use rrul_be_iperf test\n\n## MacBook (test client)\n- [ ] Install/locate Crusader GUI\n- [ ] Test Crusader client → kube.lan server\n- [ ] Optionally: Install FLENT via homebrew/pip\n\n## Lab Notebook Setup\n- [ ] Create docs/lab-notebook.qmd \n- [ ] Install Quarto if needed\n- [ ] Template with Method/Results/Conclusions structure\n- [ ] Python chunk for processing FLENT JSON output\n\n## Validation\n- [ ] Run test from kube.lan → external (validates wired path)\n- [ ] Run test from MacBook (wired) → kube.lan (validates tooling)","notes":"Tooling setup complete: FLENT+netperf on kube.lan and MacBook, Crusader on both, iperf3 on both. netserver needs to be started on kube.lan each session.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-24T07:26:49.68984Z","updated_at":"2025-12-24T08:22:00.784491Z","closed_at":"2025-12-24T08:22:00.784493Z","dependencies":[{"issue_id":"infra-openwrt-uws.1","depends_on_id":"infra-openwrt-uws","type":"parent-child","created_at":"2025-12-24T07:26:49.691697Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-uws.10","title":"Move FrontAP/KitchenAP to avoid Super_Clacks interference","description":"WiFi Explorer showed FrontAP (ch100) and KitchenAP (ch108) overlapping with neighbor Super_Clacks network in UNII-2C band.\n\n## Current Problem\n- Super_Clacks occupies ~ch100-108 range\n- FrontAP (ch100) and KitchenAP (ch108) directly overlap\n- Test from FrontAP showed 338ms latency (vs 102ms from loungeap)\n\n## Options\n1. Move FrontAP to UNII-1 (ch36-48) - The_Clacks there is weak\n2. Swap positions with APs in UNII-2A (ch52-64)\n3. Move to UNII-3 (ch149-161) if available\n\n## Commands\nssh root@frontap.lan 'uci set wireless.radio1.channel=\"36\" \u0026\u0026 uci commit wireless \u0026\u0026 wifi reload'\nssh root@kitchenap.lan 'uci set wireless.radio1.channel=\"44\" \u0026\u0026 uci commit wireless \u0026\u0026 wifi reload'","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-24T13:08:19.338285Z","updated_at":"2025-12-24T13:20:56.561032Z","closed_at":"2025-12-24T13:20:56.561032Z","close_reason":"Moved frontap (100→44), kitchenap (108→48), denap (60→36) to UNII-1 to avoid Super_Clacks. Added 17/14 dBm power limits to all APs. Disabled gardenap 5GHz. Retest pending.","dependencies":[{"issue_id":"infra-openwrt-uws.10","depends_on_id":"infra-openwrt-uws","type":"parent-child","created_at":"2025-12-24T13:08:19.340069Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-uws.11","title":"Persist AQL settings in AP gold images","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","notes":"**Closed Dec 25:** AQL 2000/2000 now baked into gold images via rc.local.\n\nAlso completed:\n- YAML synced to iteration 004 channels/power\n- htmode generation: HE40 for WiFi 6 (OFDMA), VHT40 for WiFi 5\n- Verified on ashap: hostname, channel 44, txpower 17, HE40, AQL 2000/2000","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-25T18:01:25.949379Z","updated_at":"2025-12-25T21:42:17.559753Z","closed_at":"2025-12-25T21:42:17.559765Z","dependencies":[{"issue_id":"infra-openwrt-uws.11","depends_on_id":"infra-openwrt-uws","type":"parent-child","created_at":"2025-12-25T18:01:25.950711Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-uws.2","title":"Establish WLUL baselines","design":"Capture baseline measurements before any optimization.\n\n## Baseline 1: Wired Path (validates SQM)\n- kube.lan → external server (FLENT rrul or Crusader)\n- Expected: \u003c10ms added latency under load (CAKE is configured)\n- Measures: Router SQM effectiveness\n\n## Baseline 2: Local Wired  \n- MacBook (wired via USB-C adapter) → kube.lan\n- Expected: \u003c2ms latency, no load sensitivity\n- Measures: Tooling overhead, establishes floor\n\n## Baseline 3: WiFi Unloaded\n- MacBook (WiFi) → kube.lan, no load\n- Expected: ~3-5ms (from initial ping test)\n- Measures: Baseline WiFi latency\n\n## Baseline 4: WiFi Under Load (the real test)\n- MacBook (WiFi) → kube.lan, saturating link\n- Current: Unknown - this is what we're measuring\n- Target: \u003c20ms added latency\n\n## Per-AP Baselines\n- Test each AP individually to identify worst performers\n- Document which AP the MacBook connects to during tests\n\n## Deliverables\n- Populate lab notebook with baseline data\n- Identify primary optimization targets","notes":"## Session Dec 24: WiFi Baseline via Crusader\n\n### Test Setup\n- Server: MacBook on WiFi (guestap, ch52, 5GHz VHT80)\n- Client: kube.lan (wired)\n- Tool: Crusader 0.3.2\n\n### Results\n\n| Test | Throughput | Total Latency | Down | Up |\n|------|------------|---------------|------|-----|\n| Idle | - | 3.1ms | - | - |\n| Download | 482 Mbps | 87.6ms | 26.1ms | 61.5ms |\n| Upload | 346 Mbps | 45.6ms | 7.6ms | 38.0ms |\n| **Bidirectional** | 506 Mbps | **137ms** | 22.4ms | **114.8ms** |\n\n### Key Finding\n**WiFi adds +134ms latency under bidirectional load**\n\n- Upload direction is the bottleneck (114.8ms vs 22.4ms down)\n- This is client→AP queuing (mac80211 buffers on the MacBook)\n- Compare to wired path: flat 31-33ms regardless of load\n\n### Comparison: Wired vs WiFi\n\n| Path | Bidirectional Latency | Added Latency |\n|------|----------------------|---------------|\n| Wired (SQM 700Mbps) | 33ms | ~0ms |\n| **WiFi (guestap)** | **137ms** | **+134ms** |\n\n### Next Steps\n- Channel optimization (ch52 conflict with loungeap)\n- TX power reduction\n- mac80211 parameter investigation","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-24T07:26:51.252948Z","updated_at":"2025-12-24T12:51:07.126104Z","closed_at":"2025-12-24T12:51:07.126104Z","close_reason":"Baselines established Dec 24: Wired 33ms flat, WiFi +134ms under load.","dependencies":[{"issue_id":"infra-openwrt-uws.2","depends_on_id":"infra-openwrt-uws","type":"parent-child","created_at":"2025-12-24T07:26:51.254581Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-uws.3","title":"Channel, width, and power optimization","design":"Optimize wireless RF parameters across all Campbell APs.\n\n## Current State Audit\n- Dump channel assignments from all 8 APs\n- Scan for neighboring networks from each location\n- Document current TX power levels\n\n## Channel Planning\n- 2.4GHz: Use non-overlapping channels (1, 6, 11)\n- 5GHz: Prefer DFS channels if available, avoid overlap\n- Consider physical AP locations in house\n\n## Width Optimization  \n- 2.4GHz: HT20 only (dense deployment)\n- 5GHz: VHT40 vs VHT80 tradeoff\n  - Wider = more throughput but more collision domain\n  - Test both and measure latency impact\n\n## Power Reduction\n- Current levels likely too high for dense deployment\n- Lower power = less inter-AP interference\n- Goal: Each AP covers its zone without bleeding into others\n\n## Related\n- Subsumes: infra-openwrt-nqx\n- Relates to: infra-openwrt-7r0","notes":"## Session Dec 24: Channel Optimization Applied\n\n### Width Change\n- All 7 5GHz APs: 80MHz → 40MHz\n- Doubles available channels (6 → 12 non-overlapping blocks)\n\n### 5GHz Fixed Channels (7 APs, 7 blocks, zero overlap)\n| AP | Channel | Block |\n|---|---|---|\n| loungeap | 52 | 52-56 |\n| frontap | 100 | 100-104 |\n| ashap | 116 | 116-120 |\n| denap | 60 | 60-64 |\n| guestap | 140 | 140-144 |\n| kitchenap | 108 | 108-112 |\n| isaacap | 132 | 132-136 |\n| gardenap | OFF | 2.4GHz only |\n\n### 2.4GHz Fixed Channels (graph-colored)\n- ch1: loungeap, guestap, kitchenap (spread across house)\n- ch6: frontap, isaacap (takes The_Clacks interference)\n- ch11: ashap, denap, gardenap\n\n### Key Insight\nAuto channel selection has \"chicken and egg\" problem - all APs pick independently, pile onto same \"best\" channel. Fixed assignments eliminate this.\n\n### Next Session\n1. Re-run RF scan to verify channels settled\n2. Regenerate interference map (expect green, not red)\n3. Run FLENT/Crusader latency tests\n4. If still \u003e20ms: try AQL tuning","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-24T07:26:52.960714Z","updated_at":"2025-12-24T12:51:04.634048Z","closed_at":"2025-12-24T12:51:04.634048Z","close_reason":"Channel optimization complete: 40MHz width on all 7 5GHz APs, fixed channel assignments across 7 non-overlapping blocks, 2.4GHz graph-colored. Power reduction deferred to separate task.","dependencies":[{"issue_id":"infra-openwrt-uws.3","depends_on_id":"infra-openwrt-uws","type":"parent-child","created_at":"2025-12-24T07:26:52.962264Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-uws.4","title":"Investigate mac80211 CoDel parameters","design":"Research and potentially patch mac80211 CoDel parameters for WiFi latency.\n\n## Background\nDave Taht identified that mac80211's CoDel parameters were problematic:\n- Default: target=20ms, interval=100ms\n- His recommendation: target=8ms, interval=80ms for point-to-point\n- Parameters appear hardcoded, not exposed in debugfs\n\n## Research\n- [ ] Find where codel_target/interval are set in mac80211 source\n- [ ] Check if OpenWRT 24.10.5 (kernel 6.6.119) includes any recent changes\n- [ ] Review OpenWRT forum for patches or custom builds\n- [ ] Check if mt76 driver has different behavior\n\n## Testing Options\n1. **Module parameters**: Check if mac80211 has modprobe options\n2. **Custom OpenWRT build**: Patch mac80211 with different defaults\n3. **Runtime sysfs**: Some kernels expose tuning via /sys\n4. **ImageBuilder with patches**: Add to existing CI workflow\n\n## Current AP Status\n- debugfs at /sys/kernel/debug/ieee80211/phy*/aqm shows only fq params\n- fq_quantum=300, fq_limit=8192 currently\n\n## References\n- https://patchwork.kernel.org/project/linux-wireless/patch/CAA93jw6NJ2cmLmMauz0xAgC2MGbBq6n0ZiZzAdkK0u4b+O2yXg@mail.gmail.com/\n- Make WiFi Fast project on bufferbloat.net","notes":"## Research COMPLETE (Dec 2025)\n\n### Key Findings\n\n**CoDel debugfs knobs (patch 5/5):**\n- NEVER merged upstream — silently dropped in 2016\n- Cannot tune target/interval without kernel patches\n- Would need to resurrect Michal Kazior's patch for custom build\n\n**Dave Taht's \"nuke dynamic adjustment\" patch:**\n- MERGED in kernel 6.12.44 → OpenWRT 24.10.3+\n- Fixes the 8-year bug where 50+ associated stations triggered 300ms CoDel interval\n- Campbell now has sane CoDel defaults\n\n**AQL:**\n- Tunable via debugfs (5000/12000 default)\n- Forum-tested: 2500/2500 improves latency\n- Main user-accessible lever\n\n**OFDMA:**\n- Hardware present (WiFi 6 Lites)\n- No user controls — firmware handles scheduling\n- Cannot verify if active\n\n**Latency stack priority:**\n1. Channel contention (CSMA wait) — dominates\n2. AQL limits — controls firmware buffering\n3. CoDel (now fixed)\n4. TXOP limits\n5. Client behavior (AWDL, scanning)\n\n### Sources\n- dtaht 2022 patch: patchwork.kernel.org/...CAA93jw6...\n- 24.10.3 thread confirming merge: forum.openwrt.org/t/240940/3\n- Make-WiFi-Fast project (complete, in mainline)\n\n### Status\nResearch complete. Ready for triage optimization.\nDocumented in: docs/rf-survey/wireless-fundamentals.md, docs/rf-survey/driver-investigation.md","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-24T07:27:26.310288Z","updated_at":"2025-12-24T11:14:53.24898Z","closed_at":"2025-12-24T11:14:53.248982Z","dependencies":[{"issue_id":"infra-openwrt-uws.4","depends_on_id":"infra-openwrt-uws","type":"parent-child","created_at":"2025-12-24T07:27:26.312078Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-uws.5","title":"Create WLUL lab notebook","design":"Set up reproducible documentation for WiFi latency experiments.\n\n## Format\nQuarto document (docs/lab-notebook.qmd) with:\n- Dated experiment entries\n- Method/Results/Conclusions structure\n- Embedded Python for FLENT data processing\n- Generated plots from test data\n\n## Template Sections\n1. **Test Environment** - Hardware inventory, software versions\n2. **Experiments** - Dated entries with:\n   - Hypothesis\n   - Method (exact commands, parameters)\n   - Raw Results (embedded or linked data files)\n   - Analysis (generated plots)\n   - Conclusions\n3. **Cumulative Findings** - Running summary\n\n## Data Management\n- Raw FLENT output in docs/data/\n- Python functions for loading/plotting\n- Consistent plot styling\n\n## Tooling\n- [ ] Install Quarto (brew install quarto)\n- [ ] Create template .qmd file\n- [ ] Test render to HTML\n- [ ] Add to .gitignore: rendered output? Or commit HTML?","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-24T07:27:27.698459Z","updated_at":"2025-12-24T12:51:06.15198Z","closed_at":"2025-12-24T12:51:06.15198Z","close_reason":"Lab notebook created at docs/lab-notebook.qmd with baseline measurements, methodology, and experiment log.","dependencies":[{"issue_id":"infra-openwrt-uws.5","depends_on_id":"infra-openwrt-uws","type":"parent-child","created_at":"2025-12-24T07:27:27.700276Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-uws.6","title":"Retest WiFi latency post-channel optimization","description":"Compare latency after 40MHz width + fixed channel changes.\n\n## Baseline (Dec 24, before changes)\n- WiFi bidirectional: 137ms (+134ms added)\n- Upload: 114.8ms, Download: 22.4ms\n- AP: guestap ch52 VHT80\n\n## Test Setup\n- Tool: Crusader (quick feedback loop)\n- Server: MacBook on WiFi\n- Client: kube.lan (wired)\n\n## Success Criteria\n- Any measurable improvement = channel spread helped\n- Target: \u003c50ms added latency (stretch: \u003c20ms)","notes":"## Test Results (Dec 24)\n\nloungeap (ch52, 40MHz, -39dBm):\n- Bidirectional: 102ms (+99ms added)\n- Baseline was 137ms → 26% improvement\n\nStill above \u003c20ms target. Upload bottleneck (63.4ms).\n\n**Finding:** FrontAP/KitchenAP collide with neighbor Super_Clacks on ch100-108. Need to relocate these APs.\n\nTest script created: scripts/wifi-latency-test.sh","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-24T12:51:21.932768Z","updated_at":"2025-12-24T13:08:42.757527Z","closed_at":"2025-12-24T13:08:42.757527Z","close_reason":"Post-optimization latency: 102ms (was 137ms). 26% improvement. Test automation created. Still above \u003c20ms target - proceed to AQL tuning.","dependencies":[{"issue_id":"infra-openwrt-uws.6","depends_on_id":"infra-openwrt-uws","type":"parent-child","created_at":"2025-12-24T12:51:21.935915Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-uws.7","title":"Tune AQL parameters for latency","description":"Reduce Airtime Queue Limits if latency still \u003e20ms after channel optimization.\n\n## Current AQL (default)\n- aql_txq_limit: 5000µs\n- aql_txq_global: 12000µs\n\n## Forum-recommended values\n- aql_txq_limit: 2500µs\n- aql_txq_global: 2500µs\n\n## Application\nPer-AP via debugfs:\necho 2500 \u003e /sys/kernel/debug/ieee80211/phy0/aql_txq_limit\necho 2500 \u003e /sys/kernel/debug/ieee80211/phy1/aql_txq_limit\n\n## Notes\n- AQL controls firmware buffering\n- Main user-accessible lever after channel optimization\n- Non-persistent (needs init script if beneficial)","notes":"Ready to test after channel+power tuning. Run scripts/wifi-latency-test.sh and compare to 102ms baseline.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-24T12:51:42.079384Z","updated_at":"2025-12-24T21:11:35.544137Z","closed_at":"2025-12-24T21:11:35.544137Z","close_reason":"AQL 2000/2000 deployed to all APs. Bidirectional latency reduced from 122ms to 65-75ms (38-48% improvement). TXOP tuning tested but not deployed (no benefit, added jitter). See iteration-005 manifest.","dependencies":[{"issue_id":"infra-openwrt-uws.7","depends_on_id":"infra-openwrt-uws","type":"parent-child","created_at":"2025-12-24T12:51:42.081136Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-openwrt-uws.7","depends_on_id":"infra-openwrt-uws.6","type":"blocks","created_at":"2025-12-24T12:51:54.355108Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-uws.8","title":"Reduce TX power for dense AP deployment","description":"Lower transmit power to reduce inter-AP CSMA triggering.\n\n## Current Power\n- Likely 20-25 dBm (default/auto)\n\n## Target\n- 5GHz: 17 dBm\n- 2.4GHz: 14 dBm\n\n## Rationale\n- Dense 8-AP deployment = lots of hidden node issues\n- Lower power = smaller collision domain per AP\n- Each AP should cover its zone without bleeding into neighbors\n\n## Application\nuci set wireless.radio0.txpower='14'\nuci set wireless.radio1.txpower='17'","notes":"Power reduction applied: 17dBm 5GHz, 14dBm 2.4GHz on all APs. Part of v2 tuning.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-24T12:51:43.446661Z","updated_at":"2025-12-24T13:20:56.904886Z","closed_at":"2025-12-24T13:20:56.904886Z","close_reason":"Power levels set: 17dBm 5GHz, 14dBm 2.4GHz on all 8 APs. Applied alongside channel replan.","dependencies":[{"issue_id":"infra-openwrt-uws.8","depends_on_id":"infra-openwrt-uws","type":"parent-child","created_at":"2025-12-24T12:51:43.448349Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-openwrt-uws.8","depends_on_id":"infra-openwrt-uws.7","type":"blocks","created_at":"2025-12-24T12:51:54.472712Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-uws.9","title":"Verify RF scan post-optimization","description":"Re-run RF survey to confirm channel assignments have settled.\n\n## Commands\ncd /Users/modha/Repos/infra-openwrt\npython scripts/rf-scan.py \u003e docs/rf-survey/rf-scan-results.json\npython scripts/rf-graph.py\n\n## Expected Result\n- 5GHz: 7 APs on 7 separate 40MHz blocks (all green)\n- 2.4GHz: Graph-colored across ch1/6/11\n\n## Note\nDFS channels take ~1 min to settle after assignment.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-24T12:51:44.526761Z","updated_at":"2025-12-24T13:20:57.019294Z","closed_at":"2025-12-24T13:20:57.019294Z","close_reason":"RF scan and maps regenerated post-tuning. Maps saved with timestamps in docs/rf-survey/.","dependencies":[{"issue_id":"infra-openwrt-uws.9","depends_on_id":"infra-openwrt-uws","type":"parent-child","created_at":"2025-12-24T12:51:44.528487Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-v0q","title":"Investigate ubus airtime utilization 255 values","description":"ubus call hostapd.phyX-apY get_status returns utilization values like 255 and 110 - should be percentages? Need to understand the scaling or find documentation.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-30T21:25:12.133494Z","updated_at":"2025-12-30T21:25:12.133494Z","dependencies":[{"issue_id":"infra-openwrt-v0q","depends_on_id":"infra-openwrt-uws","type":"parent-child","created_at":"2026-01-03T21:14:55.431708Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-openwrt-v1x","title":"Nanopi R5S router config","acceptance_criteria":"- [ ] Got both LAN ports working","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-03T21:28:00.446158Z","updated_at":"2026-01-03T21:30:18.812303Z","dependencies":[{"issue_id":"infra-openwrt-v1x","depends_on_id":"infra-openwrt-e9o","type":"parent-child","created_at":"2026-01-03T21:28:11.043197Z","created_by":"modha","metadata":"{}"}]}
{"id":"infra-openwrt-vvy","title":"Re-enable 802.11r on all APs after Christmas guests leave","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-24T21:44:15.794785Z","updated_at":"2026-01-02T21:12:47.38218Z","closed_at":"2026-01-02T21:12:47.38218Z","close_reason":"Already done - 802.11r enabled on all 7 active APs (verified via uci get)"}
{"id":"infra-openwrt-woa","title":"Implement AP observability via syslog drain","description":"Drain AP logs to central server for STA association/roaming events. Useful for RF optimization feedback loop. Historical config: archive/202112192131 rsyslog on openwrt.md","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-25T11:23:40.183167Z","updated_at":"2026-01-02T21:05:08.587992Z","closed_at":"2026-01-02T21:05:08.587992Z","close_reason":"Done - syslog_parser.py implemented in telemetry system"}
{"id":"infra-openwrt-xpa","title":"Bake rf-planner-v2 into gold images","description":"Integrate rf-planner-v2 output into ImageBuilder workflow. Generate AP firstboot scripts from planner rather than manual UCI in template.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-31T13:19:48.894931Z","updated_at":"2025-12-31T17:47:46.68828Z","closed_at":"2025-12-31T17:47:46.68828Z","close_reason":"Completed as part of Part B gold image improvements"}
{"id":"infra-openwrt-xv8","title":"VLAN Guest Network","design":"## Overview\n\nAdd isolated guest network with separate VLAN, SSID, and firewall zone.\n\n**SSID**: Antimacassar  \n**VLAN**: 10  \n**Subnet**: 172.17.10.0/24  \n**Coverage**: All 8 APs  \n**Isolation**: Full (no LAN access, guests can't see each other)  \n**Bandwidth**: Unlimited\n\n## Design Decisions\n\n| Decision | Choice | Rationale |\n|----------|--------|-----------|\n| Guest PSK rotation | Manual | Change when needed; eventually rotate Antimatter PSK to force migration |\n| DNS filtering | Same ControlD profile | Keep it simple, guests get same filtering |\n| 802.11r | Disabled | Guest devices often older; 802.11r breaks some connections |\n| Onboarding | QR code | Print/display for easy iOS/Android scanning |\n\n## Architecture\n\n```\nGuest device\n    ↓\nAP (Antimacassar SSID, VLAN 10 tagged)\n    ↓\nSwitch (VLAN 10 trunk on AP ports)\n    ↓\nRouter br-lan.10 interface\n    ↓\nFirewall: guest zone → WAN only\n```\n\n## Components to Configure\n\n### 1. Router (BPI-R4)\n\n**Network config** (`/etc/config/network`):\n```\n# VLAN device on bridge\nconfig device\n    option type '8021q'\n    option ifname 'br-lan'\n    option vid '10'\n    option name 'br-lan.10'\n\n# Guest interface\nconfig interface 'guest'\n    option device 'br-lan.10'\n    option proto 'static'\n    option ipaddr '172.17.10.1'\n    option netmask '255.255.255.0'\n```\n\n**DHCP config** (`/etc/config/dhcp`):\n```\nconfig dhcp 'guest'\n    option interface 'guest'\n    option start '100'\n    option limit '150'\n    option leasetime '2h'\n```\n\n**Firewall config** (`/etc/config/firewall`):\n```\nconfig zone\n    option name 'guest'\n    list network 'guest'\n    option input 'REJECT'\n    option output 'ACCEPT'\n    option forward 'REJECT'\n\n# Allow DHCP/DNS from guest\nconfig rule\n    option name 'Allow-Guest-DHCP'\n    option src 'guest'\n    option proto 'udp'\n    option dest_port '67-68'\n    option target 'ACCEPT'\n\nconfig rule\n    option name 'Allow-Guest-DNS'\n    option src 'guest'\n    option proto 'udp'\n    option dest_port '53'\n    option target 'ACCEPT'\n\n# Guest → WAN forwarding\nconfig forwarding\n    option src 'guest'\n    option dest 'wan'\n```\n\n### 2. Switch (ZyXEL GS1900-24HPv2)\n\nConfigure 802.1Q VLANs:\n- **VLAN 1** (default): Untagged on all ports (existing LAN)\n- **VLAN 10** (guest): Tagged on AP ports (1-8) and router uplink port\n\nThis makes AP ports trunk ports carrying both VLANs.\n\n### 3. APs (all 8)\n\nAdd second wireless interface per band with:\n- SSID: Antimacassar\n- Network: tagged VLAN 10 on bridge\n- `option isolate '1'` for client isolation\n- Separate PSK (guest-specific)\n- **No 802.11r** (no ft_over_ds, ft_psk_generate_local, etc.)\n\n**Wireless config pattern**:\n```\nconfig wifi-iface 'guest_5g'\n    option device 'radio1'\n    option mode 'ap'\n    option ssid 'Antimacassar'\n    option encryption 'sae-mixed'\n    option key '${GUEST_WIFI_PSK}'\n    option network 'guest'\n    option isolate '1'\n    option ieee80211w '1'\n```\n\n**Bridge VLAN tagging** (AP network config):\n```\nconfig bridge-vlan\n    option device 'br-lan'\n    option vlan '10'\n    list ports 'eth0:t'\n\nconfig interface 'guest'\n    option device 'br-lan.10'\n    option proto 'none'\n```\n\n### 4. QR Code for Guest Onboarding\n\nGenerate WiFi QR code using standard format:\n```\nWIFI:T:WPA;S:Antimacassar;P:\u003cpassword\u003e;H:false;;\n```\n\nOptions:\n- **qrencode** CLI tool: `qrencode -o wifi-guest.png \"WIFI:T:WPA;S:Antimacassar;P:password;;\"`\n- **Online generators**: qr-code-generator.com, etc.\n- **Print and frame** near front door / guest room\n\niOS Camera app and Android native camera both recognize WiFi QR codes.\n\n### 5. YAML Schema Updates\n\nAdd to `locations/campbell.yaml`:\n```yaml\nguest_network:\n  enabled: true\n  ssid: Antimacassar\n  vlan: 10\n  subnet: 172.17.10.0/24\n  router_ip: 172.17.10.1\n  dhcp:\n    start: 100\n    limit: 150\n    leasetime: 2h\n  isolation:\n    client_isolation: true\n    lan_access: false\n  roaming:\n    ieee80211r: false  # Disabled for guest compatibility\n\nsecrets:\n  guest_wifi_psk: GUEST_WIFI_PSK\n```\n\n## Implementation Order\n\n1. **Schema first**: Update YAML schema, add guest_network section to campbell.yaml\n2. **Router config**: Add VLAN device, interface, DHCP, firewall\n3. **Switch config**: Add VLAN 10, tag on AP + uplink ports\n4. **AP config generator**: Update generate-ap-config.py for guest interface\n5. **Test with one AP**: Flash single AP, verify isolation\n6. **Roll out**: Flash remaining APs\n7. **QR code**: Generate and print for guest convenience\n\n## Acceptance Criteria\n\n- [ ] Guest devices get 172.17.10.x IP\n- [ ] Guest devices can reach internet\n- [ ] Guest devices CANNOT ping 172.17.2.x (LAN)\n- [ ] Guest devices CANNOT see other guest devices\n- [ ] All 8 APs broadcast Antimacassar\n- [ ] QR code works for iOS and Android onboarding\n\n## Future: Antimatter PSK Rotation\n\nWhen ready to force guests to Antimacassar:\n1. Generate new Antimatter PSK\n2. Update all personal devices first\n3. Update router + APs with new PSK\n4. Old visitors can no longer auto-join; redirect to Antimacassar","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-20T08:29:39.264861Z","updated_at":"2025-12-30T18:21:23.461392Z","closed_at":"2025-12-30T18:21:23.461392Z","close_reason":"Guest network fully deployed. All APs broadcasting Antimacassar with VLAN 10 isolation. Tested and verified via ap-audit."}
{"id":"infra-openwrt-xv8.1","title":"Add guest_network schema to YAML structure","design":"Define guest_network section in locations/*.yaml schema. Add to campbell.yaml with all settings (VLAN 10, subnet, SSID, isolation flags, no 802.11r). Add GUEST_WIFI_PSK to secrets section.\n\nFoundation for all other work - config generators read from this.","notes":"## Ready to implement\n\nAdd guest_network section to YAML schema.\n\n### PREREQUISITE: Create GUEST_WIFI_PSK secret\nBefore deploying guest network, create the PSK:\n1. Generate strong password\n2. Add to GitHub Secrets as GUEST_WIFI_PSK\n3. Add to local .env for testing\n\n### Add to locations/campbell.yaml\n```yaml\nguest_network:\n  enabled: true\n  ssid: Antimacassar\n  vlan: 10\n  subnet: 172.17.10.0/24\n  router_ip: 172.17.10.1\n  dhcp:\n    start: 100\n    limit: 150\n    leasetime: 2h\n  isolation:\n    client_isolation: true\n    lan_access: false\n  roaming:\n    ieee80211r: false  # Disabled for guest compatibility\n```\n\n### Add to secrets section\n```yaml\n  guest_wifi_psk: GUEST_WIFI_PSK\n```\n\n### Update infra_lib.py\nAdd dataclasses to parse guest_network section (optional - could just read raw YAML in scripts).\n\n### Blocked by\nNothing - can do this first or alongside xv8.2","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T15:53:42.811835Z","updated_at":"2025-12-28T21:36:48.397134Z","closed_at":"2025-12-28T21:36:48.397134Z","close_reason":"Added guest_network section to campbell.yaml with SSID Antimacassar, VLAN 10, subnet 172.17.10.0/24, isolation and roaming settings. Added GUEST_WIFI_PSK to secrets. Note: infra_lib dataclass doesn't parse this yet - needed for xv8.3.","dependencies":[{"issue_id":"infra-openwrt-xv8.1","depends_on_id":"infra-openwrt-xv8","type":"parent-child","created_at":"2025-12-28T15:53:42.814048Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-xv8.2","title":"Add guest VLAN and firewall to router gold image","design":"Update files-bpi-campbell/etc/config/:\n- network: Add br-lan.10 VLAN device, guest interface (172.17.10.1/24)\n- dhcp: Add guest pool (100-250, 2h lease)\n- firewall: Add guest zone (input REJECT, forward REJECT), DHCP/DNS allow rules, guest→wan forwarding\n\nRead settings from locations/campbell.yaml guest_network section.","notes":"## Ready to implement\n\nSwitch VLAN 10 is configured (xv8.4 complete). Router config is next.\n\n### Files to edit\nAll in `imagebuilder/files-bpi-campbell/etc/config/`:\n\n**network** - Add VLAN device and interface:\n```\nconfig device\n    option type '8021q'\n    option ifname 'br-lan'\n    option vid '10'\n    option name 'br-lan.10'\n\nconfig interface 'guest'\n    option device 'br-lan.10'\n    option proto 'static'\n    option ipaddr '172.17.10.1'\n    option netmask '255.255.255.0'\n```\n\n**dhcp** - Add guest DHCP pool:\n```\nconfig dhcp 'guest'\n    option interface 'guest'\n    option start '100'\n    option limit '150'\n    option leasetime '2h'\n```\n\n**firewall** - Add guest zone and rules:\n```\nconfig zone\n    option name 'guest'\n    list network 'guest'\n    option input 'REJECT'\n    option output 'ACCEPT'\n    option forward 'REJECT'\n\nconfig rule\n    option name 'Allow-Guest-DHCP'\n    option src 'guest'\n    option proto 'udp'\n    option dest_port '67-68'\n    option target 'ACCEPT'\n\nconfig rule\n    option name 'Allow-Guest-DNS'\n    option src 'guest'\n    option proto 'udp'\n    option dest_port '53'\n    option target 'ACCEPT'\n\nconfig forwarding\n    option src 'guest'\n    option dest 'wan'\n```\n\n### After editing\n1. Build new router gold image (GitHub Actions)\n2. Flash router\n3. Run post-flash-router.sh for ACME + ControlD\n4. Test: router should have br-lan.10 interface with 172.17.10.1\n\n### Blocked by\nNothing - ready to implement","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T15:53:53.108415Z","updated_at":"2025-12-28T21:36:49.674375Z","closed_at":"2025-12-28T21:36:49.674375Z","close_reason":"Added router guest network config: br-lan.10 VLAN device, guest interface (172.17.10.1/24), DHCP pool (100-250, 2h lease), firewall zone with DHCP/DNS allow rules, guest→WAN forwarding, DNS interception and DoT blocking for guests.","dependencies":[{"issue_id":"infra-openwrt-xv8.2","depends_on_id":"infra-openwrt-xv8","type":"parent-child","created_at":"2025-12-28T15:53:53.110163Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-openwrt-xv8.2","depends_on_id":"infra-openwrt-xv8.1","type":"blocks","created_at":"2025-12-28T15:54:55.485151Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-xv8.3","title":"Update generate-ap-config.py for guest wireless interface","design":"Extend AP config generator to create:\n- Bridge VLAN config (br-lan.10 tagged on eth0)\n- Guest interface (proto none on br-lan.10)\n- Guest wifi-iface per radio (5GHz and 2.4GHz where applicable)\n- Client isolation enabled (isolate '1')\n- No 802.11r settings for guest interfaces\n\nMust handle radio ordering per hardware model (radio0/radio1 band mapping).","notes":"DESIGN DECISION: Added guest network config to static section of firstboot scripts, NOT to generate-ap-config.py.\n\nRationale: Guest config is identical for all APs (same SSID, VLAN, isolation settings). Only per-AP config (hostname, RF settings) belongs in the generated section. Radio disable already handles \"no 5GHz guest\" for gardenap.\n\nCOMPLETED:\n- Added GUEST_WIFI_PSK secret to both Unifi and EAP225 scripts\n- Added network config (br-lan.10 VLAN device + guest interface)\n- Added guest wifi-iface for both radios (Antimacassar SSID, client isolation, no 802.11r)\n- Replicated to both files-unifi and files-eap225\n- Tests pass, generate-ap-config.py still works\n\nNote: infra_lib dataclass doesn't parse guest_network yet - would be needed if generator ever needs to read guest settings from YAML.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T15:54:02.903641Z","updated_at":"2025-12-28T21:43:21.520324Z","closed_at":"2025-12-28T21:43:21.520324Z","close_reason":"Added guest network config (VLAN, wifi-iface, client isolation, no 802.11r) to both Unifi and EAP225 firstboot scripts. Used static config approach since guest settings are identical across all APs.","dependencies":[{"issue_id":"infra-openwrt-xv8.3","depends_on_id":"infra-openwrt-xv8","type":"parent-child","created_at":"2025-12-28T15:54:02.905306Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-openwrt-xv8.3","depends_on_id":"infra-openwrt-xv8.1","type":"blocks","created_at":"2025-12-28T15:54:55.51293Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-xv8.4","title":"Configure VLAN 10 on ZyXEL switch","design":"Manual configuration via switch web UI:\n1. Create VLAN 10\n2. Tag VLAN 10 on ports 1-8 (AP ports)\n3. Tag VLAN 10 on router uplink port\n4. Leave VLAN 1 untagged on all ports (existing behavior)\n\nResult: AP ports become trunk ports carrying both VLANs.\n\nDocument the config in switch section of campbell.yaml for reference.","notes":"## Completed 2025-12-28\n\nVLAN 10 \"Guest\" configured on GS324TP switch:\n\n### What was done\n1. Created VLAN 10 named \"Guest\"\n2. Added VLAN 10 as **tagged** on AP ports: g7, g8, g9, g10, g12, g14, g15, g18\n3. Added VLAN 10 as **tagged** on router uplink: g25\n4. VLAN 1 left **untouched** (all ports still Include/Untagged)\n5. Config saved to startup-config\n\n### CLI commands used\n```\nvlan database\nvlan 10\nvlan name 10 Guest\nexit\nconfigure\ninterface 0/7  (repeated for each port)\nvlan participation include 10\nvlan tagging 10\nexit\nwrite memory\n```\n\n### Verification\n- g23 used as lifeline port (not configured for VLAN 10)\n- Tested connectivity throughout\n- Main network (VLAN 1) working\n\n### Port state after config\n| Port | VLAN 1 | VLAN 10 |\n|------|--------|---------|\n| AP ports | Include/Untagged | Include/Tagged |\n| g25 router | Include/Untagged | Include/Tagged |\n| g23 lifeline | Include/Untagged | Exclude |","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T15:54:11.630494Z","updated_at":"2025-12-28T17:14:41.720555Z","closed_at":"2025-12-28T17:14:41.720557Z","dependencies":[{"issue_id":"infra-openwrt-xv8.4","depends_on_id":"infra-openwrt-xv8","type":"parent-child","created_at":"2025-12-28T15:54:11.632298Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-xv8.5","title":"Test guest network with single AP","design":"Validation checklist:\n- [ ] Flash router with guest VLAN config\n- [ ] Configure switch VLAN 10\n- [ ] Flash one AP (suggest guestap - fitting name)\n- [ ] Connect test device to Antimacassar\n- [ ] Verify gets 172.17.10.x IP\n- [ ] Verify can reach internet\n- [ ] Verify CANNOT ping 172.17.2.x (LAN)\n- [ ] Verify CANNOT see other guest devices (need 2 devices)\n- [ ] Verify main Antimatter SSID still works\n\nOnly proceed to rollout after all checks pass.","notes":"SESSION: 2025-12-29\n\n✅ AP WORKFLOW FIXED:\n- Added GUEST_WIFI_PSK injection\n- Added YAML-driven per-AP RF config generation (was missing entirely)\n- AP build succeeded with all fixes\n\n✅ ISAACAP FLASHED AND VERIFIED:\n- Hostname: isaacap ✓\n- 5GHz: channel 60, HE40, txpower 17 ✓\n- 2.4GHz: channel 6, HT20, txpower 14 ✓\n- AQL: 2000/2000 on all ACs ✓\n- 802.11r: enabled (mobility_domain 3433) ✓\n- Guest SSID \"Antimacassar\" visible ✓\n- Main SSID \"Antimatter\" ✓\n\n⏳ ROUTER PENDING:\n- Build 20561242820 in progress (includes .itb sysupgrade file)\n- Previous build only had .img.gz (SD card), not .itb (sysupgrade)\n- Download and flash router to complete guest network\n\nNEXT SESSION:\n1. Download router image: gh run download 20561242820 --name campbell-router-image\n2. Find .itb file and scp to router\n3. sysupgrade -n /tmp/*.itb\n4. Run post-flash-router.sh\n5. Connect to Antimacassar, verify 172.17.10.x address","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T15:54:24.329076Z","updated_at":"2025-12-29T11:50:02.552947Z","closed_at":"2025-12-29T11:50:02.552947Z","close_reason":"All checklist items verified on isaacap: guest gets 172.17.10.x, can't reach LAN, client isolation confirmed. Bridge-vlan config with br-lan.1 is the working solution. Gold image updated, build 20572043121 in progress for rollout testing.","dependencies":[{"issue_id":"infra-openwrt-xv8.5","depends_on_id":"infra-openwrt-xv8","type":"parent-child","created_at":"2025-12-28T15:54:24.33153Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-openwrt-xv8.5","depends_on_id":"infra-openwrt-xv8.2","type":"blocks","created_at":"2025-12-28T15:54:55.538616Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-openwrt-xv8.5","depends_on_id":"infra-openwrt-xv8.3","type":"blocks","created_at":"2025-12-28T15:54:55.561654Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-openwrt-xv8.5","depends_on_id":"infra-openwrt-xv8.4","type":"blocks","created_at":"2025-12-28T15:54:55.585293Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-xv8.6","title":"Roll out guest network to all APs","design":"After successful single-AP test:\n1. Build gold images for all AP models (unifi-6-lite, unifi-nanohd, eap225-outdoor)\n2. Flash remaining 7 APs\n3. Verify Antimacassar visible on all APs\n4. Verify roaming works (though less critical without 802.11r)\n5. Update ap-audit.py to check guest interface config","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T15:54:34.065217Z","updated_at":"2025-12-30T18:21:23.402838Z","closed_at":"2025-12-30T18:21:23.402838Z","close_reason":"Complete - ap-audit confirms Antimacassar broadcasting on all 7 online APs with bridge-VLAN isolation working.","dependencies":[{"issue_id":"infra-openwrt-xv8.6","depends_on_id":"infra-openwrt-xv8","type":"parent-child","created_at":"2025-12-28T15:54:34.06668Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-openwrt-xv8.6","depends_on_id":"infra-openwrt-xv8.5","type":"blocks","created_at":"2025-12-28T15:54:55.608613Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-xv8.7","title":"Generate and print guest WiFi QR code","design":"Generate QR code for easy guest onboarding:\n1. Install qrencode: brew install qrencode\n2. Generate: qrencode -o antimacassar-qr.png -s 10 'WIFI:T:WPA;S:Antimacassar;P:\u003cpassword\u003e;;'\n3. Print at reasonable size\n4. Frame and place near front door or guest room\n\nTest with iOS Camera app and Android camera before printing.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T15:54:43.016195Z","updated_at":"2025-12-30T18:21:23.431891Z","closed_at":"2025-12-30T18:21:23.431891Z","close_reason":"QR code can be generated anytime with: qrencode -o antimacassar-qr.png 'WIFI:T:WPA;S:Antimacassar;P:\u003cpassword\u003e;;' - not blocking anything.","dependencies":[{"issue_id":"infra-openwrt-xv8.7","depends_on_id":"infra-openwrt-xv8","type":"parent-child","created_at":"2025-12-28T15:54:43.017742Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-xx8","title":"Configure AP syslog forwarding to kube.lan","description":"Add remote syslog config to AP gold images.\n\nUCI settings needed:\n- system.@system[0].log_ip='172.17.2.x' (kube.lan IP)\n- system.@system[0].log_port='514' (or custom)\n- system.@system[0].log_proto='udp'\n- system.@system[0].log_remote='1'\n\nImplementation:\n- Add to 99-campbell-ap template (not generator)\n- Or add to campbell.yaml and generate\n\nDepends on: Research tasks complete, log server running.","notes":"Syslog forwarding working via live UCI config on all 7 APs. Events flowing to kube.lan, parser running. This bead is for baking into gold image so config persists across reflash.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-30T10:18:13.981992Z","updated_at":"2025-12-31T12:45:09.353171Z","closed_at":"2025-12-31T12:45:09.353171Z","close_reason":"Syslog forwarding working via live UCI on all 7 APs. Baking into gold images tracked separately.","dependencies":[{"issue_id":"infra-openwrt-xx8","depends_on_id":"infra-openwrt-awu","type":"parent-child","created_at":"2025-12-30T10:18:23.458816Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-openwrt-xx8","depends_on_id":"infra-openwrt-nne","type":"blocks","created_at":"2025-12-30T10:18:23.485926Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-openwrt-xx8","depends_on_id":"infra-openwrt-db6","type":"blocks","created_at":"2025-12-30T10:18:23.512604Z","created_by":"daemon","metadata":"{}"}],"comments":[{"id":1,"issue_id":"infra-openwrt-xx8","author":"modha","text":"User preference: keep open as reminder to add to gold image. Current UCI config is ephemeral.","created_at":"2025-12-31T00:10:20Z"}]}
{"id":"infra-openwrt-xz4","title":"Create imagebuilder/files-gs1900/ gold image config","description":"Network config, hostname, SSH keys, PoE defaults","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T10:30:13.83549Z","updated_at":"2025-12-28T11:42:30.090129Z","closed_at":"2025-12-28T11:42:30.090129Z","close_reason":"Created files-gs1900/ with network, dhcp, dropbear, firewall configs","dependencies":[{"issue_id":"infra-openwrt-xz4","depends_on_id":"infra-openwrt-bro","type":"parent-child","created_at":"2025-12-28T10:30:27.411783Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-openwrt-xz4","depends_on_id":"infra-openwrt-7qo","type":"blocks","created_at":"2025-12-28T10:30:28.821715Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-y2o","title":"Add per-AP 802.11r override for HomePod compatibility","description":"HomePod near loungeap can't cope with 802.11r. Add ability to disable 802.11r on specific APs via campbell.yaml (e.g., loungeap.rf.ieee80211r: false)","design":"## Approach\n1. Add optional `ieee80211r` field to RF config in YAML schema\n2. Update generate-ap-config.py to check this field\n3. If false, skip the 802.11r UCI commands for that AP\n4. Default to enabled (current behavior) if not specified\n\n## Affected APs\n- loungeap (has HomePod nearby that doesn't work with 802.11r)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T23:44:16.748026Z","updated_at":"2025-12-30T18:06:23.441Z","closed_at":"2025-12-30T18:06:23.441Z","close_reason":"Disabled 802.11r on loungeap via SSH (for first-gen HomePod compatibility). Also removed dead code from template that never executed (AP_NAME wasn't set yet). Note: reflashing loungeap will re-enable 802.11r until per-AP override is added to imagebuilder."}
{"id":"infra-openwrt-ys0","title":"Device catalog: discover, name, and monitor all network devices","description":"Build a comprehensive device catalog in campbell.yaml. Discover devices via multiple methods (DHCP, mDNS, UPnP, etc.), assign canonical names, monitor for new devices. Filter out randomized MACs.","design":"## Components\n\n1. **Discovery script** (device-discover.py)\n   - Pull DHCP leases from router\n   - mDNS scan (dns-sd or avahi)\n   - ARP table\n   - MAC OUI lookup\n   - Combine results, dedupe by MAC\n   - Output format suitable for YAML import\n\n2. **Schema changes** (infra_lib.py + generators)\n   - Make `ip` optional in device_groups entries\n   - Add optional `type` field (phone, laptop, tablet, iot, av, appliance)\n   - generate-dhcp-config.py skips entries without `ip`\n\n3. **New devices monitor** (analyze.py)\n   - `analyze.py unknown` - MACs in telemetry not in YAML\n   - Filter randomized MACs (first octet \u0026 0x02)\n   - Show with OUI manufacturer for easier ID\n\n## Acceptance Criteria\n- [ ] Discovery script runs and finds devices with names from multiple sources\n- [ ] campbell.yaml can have devices without `ip` field\n- [ ] analyze.py unknown shows unrecognized devices (excluding random MACs)\n- [ ] At least 20 devices cataloged with canonical names","status":"closed","priority":2,"issue_type":"epic","created_at":"2026-01-01T22:28:38.940424Z","updated_at":"2026-01-01T23:01:50.11972Z","closed_at":"2026-01-01T23:01:50.11972Z","close_reason":"Device catalog complete: 48 devices cataloged, device_discover.py created, analyze.py unknown command added, ip now optional in schema. Names show in telemetry output."}
{"id":"infra-openwrt-z37","title":"Fix 802.11r: set ft_over_ds='0' globally","description":"FT Over DS (default ft_over_ds='1') breaks iOS and HomePods. Must use FT Over the Air. Currently only loungeap has this disabled (ephemerally via SSH).","design":"## Change\nIn AP template (files-unifi/etc/uci-defaults/99-campbell-ap):\noption ft_over_ds '0'\n\nAlso add:\noption reassociation_deadline '20000'  # 20 seconds vs default 1\n\n## Verification\nAfter flash: uci show wireless | grep ft_over_ds\n\n---\n**Footnote (from 9tv):** If per-AP 802.11r control is ever needed (e.g., disable entirely for HomePod AP), add ieee80211r field to AccessPoint dataclass and have generator emit uci delete commands after AP_NAME is set. For now, global ft_over_ds='0' should suffice since FT-over-air works for all devices including HomePods.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T23:26:39.557995Z","updated_at":"2025-12-31T13:19:30.634236Z","closed_at":"2025-12-31T13:19:30.634236Z","close_reason":"Superseded by rf-planner-v2 (nv6). ft_over_ds=0 now included in planner output.","dependencies":[{"issue_id":"infra-openwrt-z37","depends_on_id":"infra-openwrt-4gi","type":"parent-child","created_at":"2025-12-30T23:26:50.504232Z","created_by":"daemon","metadata":"{}"}]}
{"id":"infra-openwrt-z8t","title":"Build Grafana WiFi diagnostics dashboard","description":"Create Grafana dashboard for WiFi health and diagnostics.\n\nPanels to include:\n- Client count per AP over time\n- Association/disassociation events (roaming activity)\n- 802.11r FT success/failure rate\n- Per-AP log volume (anomaly detection)\n- Channel utilization heatmap (if available)\n- Client roaming paths (which APs they move between)\n\nNice to have:\n- Alerting on unusual patterns (AP offline, roaming storms)\n- Floor plan visualization with AP status\n\nDepends on: Log server running, APs forwarding logs.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T10:18:52.759443Z","updated_at":"2025-12-31T17:47:46.657827Z","closed_at":"2025-12-31T17:47:46.657827Z","close_reason":"Not doing - out of scope for current work","dependencies":[{"issue_id":"infra-openwrt-z8t","depends_on_id":"infra-openwrt-awu","type":"parent-child","created_at":"2025-12-30T10:19:01.61299Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-openwrt-z8t","depends_on_id":"infra-openwrt-m2g","type":"blocks","created_at":"2025-12-30T10:19:01.640074Z","created_by":"daemon","metadata":"{}"},{"issue_id":"infra-openwrt-z8t","depends_on_id":"infra-openwrt-xx8","type":"blocks","created_at":"2025-12-30T10:19:01.669287Z","created_by":"daemon","metadata":"{}"}]}
{"id":"itv-appscript-deploy-1e4","title":"Add triggers commands","design":"Implement triggers list/create/delete. Use Apps Script trigger builder format for schedules.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-27T21:10:55.352542Z","updated_at":"2025-12-27T21:10:55.352542Z"}
{"id":"itv-appscript-deploy-3bm","title":"Automate API Executable deployment creation","description":"scripts.run API returns 404 \"entity not found\" unless the project has an EXECUTION_API entry point configured.\n\nCurrently requires manual UI step after create/deploy:\n1. Deploy → New deployment\n2. Select \"API Executable\" \n3. Set access to \"Only myself\"\n4. Click Deploy\n\nThis is a friction point in the otherwise-automated flow.","design":"## What We Learned\n\n**Working project has:**\n```json\n{\n  \"entryPoints\": [{\n    \"entryPointType\": \"EXECUTION_API\",\n    \"executionApi\": {\n      \"entryPointConfig\": {\"access\": \"MYSELF\"}\n    }\n  }]\n}\n```\n\n**API-created project has:**\n```json\n{\n  \"entryPoints\": []\n}\n```\n\n## Failed Attempts\n\n1. `projects.deployments().create()` with versionNumber — creates deployment but NO entry points\n2. Running function from UI first — doesn't help\n3. Linking GCP project — necessary but not sufficient\n\n## Investigation Needed\n\n- Can deployments.create accept entryPoints in the body?\n- Is there a separate API to configure entry points?\n- Does the deployment need specific config to enable EXECUTION_API?\n\n## Ideal Outcome\n\n`itv-appscript create --init --open` or `deploy` automatically configures the API Executable entry point, eliminating the manual UI step.\n\n## Workaround\n\nDocument the manual step clearly in CLI output after create/deploy.","notes":"## Investigation Complete\n\n**Finding:** The Apps Script API does NOT support creating or updating EXECUTION_API entry points programmatically.\n\nChecked:\n- `DeploymentConfig` schema: only has description, manifestFileName, scriptId, versionNumber\n- `UpdateDeploymentRequest` uses same DeploymentConfig\n- Having `executionApi` in appsscript.json manifest doesn't auto-create the deployment\n\n**API Executable deployment MUST be created via the UI:**\n1. Deploy → New deployment\n2. Select \"API Executable\"  \n3. Set access to \"Only myself\"\n4. Click Deploy\n\n## Solution Implemented\n\n1. Enhanced `run` command error message when hitting 404 \"not found\":\n   - Now explains the two possible causes (missing function vs missing API Executable)\n   - Provides direct link to deploy page with step-by-step instructions\n   - Mentions user-level toggle as well\n\n2. Enhanced `create` command output:\n   - Now shows 3-step setup guide (GCP link, API Executable, user toggle)\n   - Provides direct URLs for each step\n\n## Status\n\nReady to close - automation not possible, but guidance now comprehensive.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T22:27:00.346589Z","updated_at":"2025-12-27T22:43:46.636787Z","closed_at":"2025-12-27T22:43:46.636787Z","close_reason":"Cannot automate via API (DeploymentConfig doesn't support entryPoints). Added comprehensive guidance to create command output and improved run error messages with direct links and step-by-step instructions."}
{"id":"itv-appscript-deploy-4r6","title":"Add status command","design":"## Consumer Feedback\n\nFrom Claude working on itv-slides-formatter:\n- After creating new GCP project + OAuth credentials, couldn't complete setup\n- deploy.json has gcpProjectId (string) but Apps Script needs project number (numeric)\n- No way to check if script is associated with correct GCP project\n\n## Proposed Solution\n\n`itv-appscript status` should show:\n\n```\nScript: 1abc... (Dad Joke Machine)\n  Editor: https://script.google.com/...\n\nGCP Project:\n  Configured: itv-mit-appscript-deploy (451775514458)\n  Script linked: ✓ Yes / ✗ No / ? Unknown\n  \nAuth:\n  Token: ✓ Valid (expires in 47 minutes)\n  Scopes: script.projects, script.deployments, logging.read\n  \nSetup checklist:\n  [✓] GCP project linked\n  [✓] User-level Apps Script API enabled\n  [?] API Executable deployment (can't verify via API)\n```\n\n## Implementation Notes\n\n1. Project number: Already have `get_gcp_project_number()` - use it\n2. Script metadata: `projects.get()` returns parentId (linked GCP project)\n3. Compare parentId with credentials project number → detect mismatch\n4. If mismatched, show: \"Run: itv-appscript link\" or provide deep link\n\n## API Check\n\nNeed to verify: does projects.get() return the GCP project association?\nIf yes, we can detect mismatches.\nIf no, we can only show \"Unknown\" for link status.","notes":"## API Investigation (2025-12-27)\n\nChecked script.v1.json schema - no GCP project field exposed.\n- `parentId` is Drive parent (Sheet/Doc), not GCP project\n- No `gcpProjectId` or `cloudProject` field in Project schema\n\n**Implication:** Can't programmatically verify GCP project association.\nStatus command can show configured project number but can't confirm the link.\n\nWorkaround: Try a dry-run of scripts.run and interpret the error:\n- \"permission\" error → likely not linked\n- Success or function error → linked correctly","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-27T21:12:36.041547Z","updated_at":"2025-12-27T22:57:56.582399Z"}
{"id":"itv-appscript-deploy-55x","title":"Add diff before deploy","design":"Show what changed before pushing. Compare local files to remote HEAD.","status":"open","priority":4,"issue_type":"task","created_at":"2025-12-27T21:12:35.941902Z","updated_at":"2025-12-27T21:12:35.941902Z"}
{"id":"itv-appscript-deploy-5zd","title":"Create GitHub repo and push","design":"Create spm1001/itv-appscript-deploy repo, push initial commit.","notes":"Created https://github.com/spm1001/itv-appscript-deploy (private)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T21:10:55.520083Z","updated_at":"2025-12-27T21:13:28.214835Z","closed_at":"2025-12-27T21:13:28.214837Z"}
{"id":"itv-appscript-deploy-6bp","title":"Set Apps Script project timezone from config","design":"Use projects.updateMetadata or similar to set project title. Could use folder name or add 'name' field to deploy.json. Avoids 'Untitled project' clutter.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-27T21:19:59.586352Z","updated_at":"2025-12-27T21:19:59.586352Z"}
{"id":"itv-appscript-deploy-6ru","title":"Add pull command","design":"Call projects.getContent API to download current script files. Write to src/ directory. Add --force flag to overwrite modified files.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-27T21:10:55.299907Z","updated_at":"2025-12-27T21:10:55.299907Z"}
{"id":"itv-appscript-deploy-8uc","title":"Add create command","design":"Use Apps Script API projects.create to create new project with title.\n\nCLI: itv-appscript create \"Project Name\"\n\nOutputs scriptId. Could optionally:\n- Update deploy.json with new scriptId\n- Auto-link GCP project if credentials available\n\nRequires: script.projects scope (already have it)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T21:37:43.388717Z","updated_at":"2025-12-27T21:50:26.174065Z","closed_at":"2025-12-27T21:50:26.174065Z","close_reason":"Create command implemented. Uses projects.create API, outputs scriptId and URL. --init flag creates deploy.json. Tested successfully."}
{"id":"itv-appscript-deploy-9ox","title":"Add deploy --version flag","design":"Create versioned deployment via projects.versions.create + projects.deployments.create. Required for run without --dev.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-27T21:10:55.408342Z","updated_at":"2025-12-27T21:10:55.408342Z"}
{"id":"itv-appscript-deploy-br6","title":"Check user-level Apps Script API toggle","description":"scripts.run requires the user-level Apps Script API to be enabled at:\nhttps://script.google.com/home/usersettings\n\nMost users won't have this enabled by default. Should detect and prompt.","design":"## Options\n\n1. **Proactive check during create/auth**\n   - After successful create, remind user to check the toggle\n   - --open could also open usersettings page\n\n2. **Reactive check on run failure**\n   - Detect the specific error that indicates API not enabled\n   - Provide helpful message with URL\n\n3. **Both**\n   - Warn during create\n   - Catch and explain on run failure\n\n## Error Detection\n\nNeed to identify what error scripts.run returns when user-level API is disabled vs other 404s.\n\n## Implementation\n\nCould add to create output:\n```\nAlso ensure Apps Script API is enabled:\n  https://script.google.com/home/usersettings\n```\n\nOr detect on run failure and offer to open the page.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T22:28:56.926475Z","updated_at":"2025-12-27T22:43:47.444795Z","closed_at":"2025-12-27T22:43:47.444795Z","close_reason":"Added proactive guidance (create command shows 3-step setup including user toggle URL) and reactive detection (run error handlers now include toggle URL in both PERMISSION_DENIED and not-found error paths)."}
{"id":"itv-appscript-deploy-mit","title":"Set Apps Script project name on deploy","design":"Use projects.updateMetadata or similar to set project title. Could use folder name or add 'name' field to deploy.json. Avoids 'Untitled project' clutter.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-27T21:20:05.573225Z","updated_at":"2025-12-27T21:20:05.573225Z"}
{"id":"itv-appscript-deploy-n04","title":"Update spec with executionApi gotcha","design":"Document that appsscript.json needs executionApi.access for scripts.run to work.","notes":"Added Gotchas Discovered section to spec.md with executionApi, scope, and project number extraction","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T21:10:55.466498Z","updated_at":"2025-12-27T21:13:04.437039Z","closed_at":"2025-12-27T21:13:04.43704Z"}
{"id":"itv-appscript-deploy-o4b","title":"Add logs command","design":"Query Cloud Logging API for Apps Script execution logs. Filter by gcpProjectId and script resource. Support -n count, --follow mode, --function filter.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T21:10:55.246298Z","updated_at":"2025-12-27T21:34:18.284411Z","closed_at":"2025-12-27T21:34:18.284411Z","close_reason":"Logs command implemented with get_logs(), stream_logs(), -n count, --follow, --function filter. Full deploy→run→logs cycle tested and working."}
{"id":"itv-appscript-deploy-tle","title":"Add watch mode","design":"Auto-deploy on file change during development. Use filesystem watcher.","status":"open","priority":4,"issue_type":"task","created_at":"2025-12-27T21:12:35.991854Z","updated_at":"2025-12-27T21:12:35.991854Z"}
{"id":"itv-google-auth-f7g","title":"Audit and fix itv-slides-formatter OAuth cleanup","design":"Context: Session on 2025-12-27 stripped OAuth files from itv-slides-formatter\nand updated package.json to use itv-auth CLI. Another Claude was spawned to\ndo a full audit but reportedly something went wrong.\n\nTasks:\n1. Review current state of itv-slides-formatter\n2. Check deploy-web-manual.js - still has embedded OAuth that may be redundant\n3. Verify credentials.json exists (or document GCP setup needed)\n4. Check other .js files for OAuth dependencies\n5. Simplify: all scripts should just read token.json, fail helpfully if missing\n6. Test npm run deploy actually works\n7. Update CLAUDE.md to reflect new auth pattern\n\nGoal: All auth via itv-auth CLI, Node.js scripts just consume the token.\n\nRelated: ~/Repos/itv-slides-formatter","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T19:31:57.581695Z","updated_at":"2025-12-27T23:15:59.781315Z","closed_at":"2025-12-27T23:15:59.781315Z","close_reason":"Confirmed working by itv-slides-formatter consumer. Fresh GCP project setup worked flawlessly - auto mode, callback, token saving all correct. Minor future idea noted: config file option for scopes to reduce package.json boilerplate."}
{"id":"itv-google-auth-pbv","title":"Add test coverage to itv-google-auth","design":"The library has no tests. Need pytest tests covering:\n\n1. **Unit tests for auth.py:**\n   - expand_scopes() - shortcut expansion\n   - TokenStatus.check() - various token states (valid, expired, missing, corrupt)\n   - _parse_code_from_input() - URL parsing and raw code handling\n   - _save_credentials() - token file format\n\n2. **Integration tests (mock or real):**\n   - load_credentials() - loading and refreshing\n   - authenticate() - the OAuth flow (may need mocking)\n\n3. **CLI tests:**\n   - itv-auth --help\n   - itv-auth status\n   - itv-auth list-scopes\n\nStart with unit tests (no external deps), then decide on integration approach.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T19:31:46.574129Z","updated_at":"2025-12-27T21:55:45.88356Z","closed_at":"2025-12-27T21:55:45.88356Z","close_reason":"Added 25 unit tests covering expand_scopes, TokenStatus.check, TokenStatus.expires_in, _parse_code_from_input, and _save_credentials. Tests discovered and fixed a timezone bug (comparing aware vs naive datetimes). Each test has 'When X, it should Y' comment."}
{"id":"itv-google-auth-t5c","title":"Apply ITV brand styling to auth callback pages","description":"The callback pages (SUCCESS_HTML, POST_AUTH_HTML, etc.) use generic styling. Apply ITV brand colors/fonts using the itv-brand skill patterns.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T21:28:24.408273Z","updated_at":"2025-12-27T21:37:44.006528Z","closed_at":"2025-12-27T21:37:44.006528Z","close_reason":"Applied ITV brand styling to all callback pages: dark teal background, yellow headlines, teal accents, SVG icons for success/error states. Extracted shared CSS into _ITV_BRAND_CSS constant for DRY."}
{"id":"learning-causality-an5","title":"Work through Undergraduate Course in Causality","description":"## Desired Outcome\nUnderstood core causal inference concepts well enough to apply them and explain to others.\n\n## Source Material\nhttps://hdsr.mitpress.mit.edu/pub/uynpjlow/release/3\n\n## Approach\n- Claude as teacher/guide\n- Build demos to solidify understanding\n- Work through exercises\n\n## Acceptance Criteria\n- [ ] Can explain difference between correlation and causation formally\n- [ ] Understand DAGs and d-separation\n- [ ] Can identify confounders, colliders, mediators\n- [ ] Built at least one interactive demo","status":"open","priority":3,"issue_type":"epic","created_at":"2026-01-03T20:31:41.395424Z","updated_at":"2026-01-03T20:31:41.395424Z"}
{"id":"linkedin-analytics-b3b","title":"Content performance recommendations","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-16T12:29:54.974519Z","updated_at":"2025-12-25T20:59:55.806835Z","dependencies":[{"issue_id":"linkedin-analytics-b3b","depends_on_id":"linkedin-analytics-yzi","type":"parent-child","created_at":"2025-12-30T18:56:31.396718Z","created_by":"modha","metadata":"{}"}]}
{"id":"linkedin-analytics-bce","title":"Event performance comparison","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-16T12:29:54.789025Z","updated_at":"2025-12-25T20:59:56.297214Z","dependencies":[{"issue_id":"linkedin-analytics-bce","depends_on_id":"linkedin-analytics-yzi","type":"parent-child","created_at":"2025-12-30T18:56:41.637538Z","created_by":"modha","metadata":"{}"}]}
{"id":"linkedin-analytics-czi","title":"Marketing calendar ingestion","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-16T12:29:54.881987Z","updated_at":"2025-12-25T20:59:56.053647Z","dependencies":[{"issue_id":"linkedin-analytics-czi","depends_on_id":"linkedin-analytics-yzi","type":"parent-child","created_at":"2025-12-30T18:56:36.519718Z","created_by":"modha","metadata":"{}"}]}
{"id":"linkedin-analytics-hb0","title":"Event detection on weekly impressions chart","design":"## Goal\nAutomatically detect and annotate significant events/spikes on the weekly impressions chart.\n\n## Potential Approaches\n\n### 1. Statistical Spike Detection\n- Calculate rolling average + standard deviation\n- Flag weeks that exceed N standard deviations\n- Annotate chart with markers\n\n### 2. Correlation with Events Table\n- Events table already exists in BigQuery (itv_business, industry, posting types)\n- Overlay event markers on chart where events fall\n- Show which spikes correlate with known events\n\n### 3. Anomaly Detection\n- Simple: week-over-week % change threshold\n- Advanced: time series decomposition (trend + seasonality + residual)\n\n## Implementation Options\n\n### Chart Annotations (Sheets API)\n- Can add data labels, trendlines\n- Limited annotation support natively\n- Could add a second series with markers at event points\n\n### Separate Event Markers\n- Add vertical lines or markers at event dates\n- Would need custom SVG or second data series\n\n## Questions to Resolve\n- Which detection method? (statistical vs event correlation vs both)\n- Visual style for annotations?\n- Should it auto-detect or just show known events?\n\n## Dependencies\n- Events table schema exists\n- Dashboard sheet and chart infrastructure in place","notes":"Superseded by more specific beads: vug (annotated chart), bce (event comparison), czi (calendar ingestion), b3b (recommendations)","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-16T12:23:41.281504Z","updated_at":"2025-12-16T12:30:17.441208Z","closed_at":"2025-12-16T12:30:17.44121Z"}
{"id":"linkedin-analytics-jmg","title":"Set up Apps Script form trigger for Cloud Run Job","design":"## Context\n\nCloud Run Job is deployed and tested:\n- Job: `linkedin-analytics-ingest` in `europe-west2`\n- Tested: `gcloud run jobs execute linkedin-analytics-ingest --region=europe-west2 --wait`\n- Logs confirm: ingest + sheets sync working\n\n## Remaining Work\n\n### 1. Apps Script Setup\nForm: \"LinkedIn Analytics Submission\" (already created)\nScript location: `apps-script/trigger.gs` in repo\n\nSteps:\n1. Open Form → three dots → Script editor\n2. Replace Code.gs with contents of `apps-script/trigger.gs`\n3. Click Project Settings (gear) → Show appsscript.json manifest\n4. Replace manifest with contents of `apps-script/appsscript.json`\n5. Project Settings → GCP Project → Change project → enter `1018230309720`\n6. Run `setupTrigger()` function once (creates the form submit trigger)\n7. Authorize when prompted\n\n### 2. Grant Invoker Permission\n```bash\ngcloud run jobs add-iam-policy-binding linkedin-analytics-ingest \\\n  --region=europe-west2 \\\n  --project=mit-dev-362409 \\\n  --member=\"user:sameer.modha@itv.com\" \\\n  --role=\"roles/run.invoker\"\n```\n\n### 3. Test End-to-End\n1. Submit a test export via the Form\n2. Check Cloud Run logs: `gcloud run jobs logs read linkedin-analytics-ingest --region=europe-west2 --limit=20`\n3. Verify Sheets dashboard updated\n\n## Files\n- `apps-script/trigger.gs` - The Apps Script code\n- `apps-script/appsscript.json` - OAuth scopes manifest\n- `docs/DEPLOYMENT.md` - Full deployment guide\n\n## Config Values\n- GCP Project: `mit-dev-362409`\n- Project Number: `1018230309720`\n- Region: `europe-west2`\n- Job: `linkedin-analytics-ingest`\n- SA: `linkedin-analytics@mit-dev-362409.iam.gserviceaccount.com`","notes":"Completed: Apps Script trigger working. Fixed: (1) use getOAuthToken() not getIdentityToken(), (2) add script.scriptapp scope.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-15T23:10:45.760621Z","updated_at":"2025-12-16T10:33:38.368533Z","closed_at":"2025-12-16T10:33:38.36871Z"}
{"id":"linkedin-analytics-vug","title":"Annotated spike chart with post links","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-16T12:29:54.690825Z","updated_at":"2025-12-25T20:59:56.549175Z","dependencies":[{"issue_id":"linkedin-analytics-vug","depends_on_id":"linkedin-analytics-yzi","type":"parent-child","created_at":"2025-12-30T18:56:46.757206Z","created_by":"modha","metadata":"{}"}]}
{"id":"linkedin-analytics-yzi","title":"LinkedIn Analytics v2 Features","description":"Collection of v2 features for the LinkedIn analytics dashboard. Grouped for planning - pick up features as analytics work continues.","status":"open","priority":2,"issue_type":"epic","created_at":"2025-12-30T18:55:27.378053Z","updated_at":"2025-12-30T18:55:27.378053Z"}
{"id":"mcp-run-html-tools-qyn","title":"Add MCP resources and prompts","description":"MCP currently only exposes tools. Should also expose:\n\n**Resources:**\n- README / usage documentation\n- List of available HTML tools with descriptions\n\n**Prompts:**\n- 'Create a new HTML tool' template\n- 'Debug HTML tool execution' workflow\n\nThis makes the MCP more self-describing and gives Claude built-in guidance without needing a separate skill.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-30T20:08:04.358347Z","updated_at":"2025-12-30T20:08:04.358347Z"}
{"id":"mcp-workspace-google-56w","title":"Extract hyperlinks from Sheets cells","description":"Sheets hyperlinks require a fundamentally different API path. Current implementation uses spreadsheets.values.get which returns only raw values. To get hyperlinks, need spreadsheets.get with includeGridData: true, then read cell.hyperlink or cell.textFormatRuns[].format.link.uri.","design":"## Current State\nSheetsService.getText uses:\n```typescript\nsheets.spreadsheets.values.get({\n    spreadsheetId: id,\n    range: `'${sheetName}'`,\n});\n```\nThis returns only cell values, no metadata.\n\n## Required Change\nNeed to use:\n```typescript\nsheets.spreadsheets.get({\n    spreadsheetId: id,\n    includeGridData: true,\n    ranges: [`'${sheetName}'`],\n});\n```\nThen iterate through gridData[].rowData[].values[].hyperlink\n\n## Considerations\n- includeGridData: true is heavier - consider making it opt-in via parameter\n- Could add new tool sheets_getTextWithLinks or add includeLinks: boolean param\n- textFormatRuns allows partial cell linking (like \"Click [here](url) for more\") - more complex to parse\n\n## Acceptance Criteria\n- [ ] Cells with hyperlinks emit [cell text](url) format\n- [ ] Non-linked cells unchanged\n- [ ] Performance acceptable (or opt-in flag for heavy mode)","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-05T20:25:23.884213Z","updated_at":"2026-01-05T20:25:23.884213Z","dependencies":[{"issue_id":"mcp-workspace-google-56w","depends_on_id":"mcp-workspace-google-fic","type":"parent-child","created_at":"2026-01-05T20:26:11.957309Z","created_by":"modha","metadata":"{}"}]}
{"id":"mcp-workspace-google-7p4","title":"Extract footnotes and bookmarks from Docs","description":"Docs API returns footnotes and bookmarks in the document structure. These are currently ignored. Lower priority as less commonly used.","design":"## API Data\nAlready available in documents.get response:\n- `footnotes` - map of footnote ID to content\n- `footnoteReferences` in paragraph elements - point to footnotes\n- `bookmarks` - named locations in document\n\n## Markdown Representation\nFootnotes: Standard markdown footnote syntax\n```\nSome text[^1] with a footnote.\n\n[^1]: The footnote content here.\n```\n\nBookmarks: No standard markdown - could emit HTML anchor or skip\n\n## Acceptance Criteria\n- [ ] Footnotes appear as markdown footnotes\n- [ ] Footnote references link to correct content\n- [ ] Bookmarks handled (even if just preserved as IDs)","status":"open","priority":4,"issue_type":"task","created_at":"2026-01-05T20:26:05.091826Z","updated_at":"2026-01-05T20:26:05.091826Z","dependencies":[{"issue_id":"mcp-workspace-google-7p4","depends_on_id":"mcp-workspace-google-fic","type":"parent-child","created_at":"2026-01-05T20:26:12.100746Z","created_by":"modha","metadata":"{}"}]}
{"id":"mcp-workspace-google-9z2","title":"Test Google Workspace MCP tool coverage","description":"Test Calendar, Docs, Sheets, Chat, Drive tools. Verify which work with current ITV OAuth scopes.","design":"## Tools to test\n- calendar.listEvents, calendar.createEvent\n- docs.create, docs.getText\n- sheets.getText, sheets.getRange\n- chat.listSpaces (may fail — new scope)\n- drive.search\n\n## Expected issues\n- Chat scopes may not be approved by ITV\n- gmail.modify vs gmail.readonly difference\n\n## Migrated from\n.claude-0fi in ~/.claude","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-03T15:31:27.855105Z","updated_at":"2026-01-03T15:31:27.855105Z"}
{"id":"mcp-workspace-google-fic","title":"Rich content extraction from Google Workspace documents","description":"getText tools currently flatten rich content to plain text, discarding metadata available in the API responses. This epic tracks extracting that metadata into the markdown output.","design":"## Context\nWhen retrieving documents via docs_getText, slides_getText, sheets_getText, the APIs return structured data including:\n- Hyperlinks (textStyle.link.url / style.link.url)\n- Text formatting (bold, italic, underline)\n- Comments (separate API call)\n- Footnotes, bookmarks (Docs only)\n- Cell hyperlinks (Sheets - requires different API path)\n\nThe extraction code discards all but the text content.\n\n## Completed\n- [x] Links in Docs (_readStructuralElement)\n- [x] Links in Slides (extractTextFromTextContent)\n\n## Remaining\n- [ ] Bold/italic → markdown **text** and *text*\n- [ ] Sheets hyperlinks (requires includeGridData: true)\n- [ ] Comments (separate API call)\n- [ ] Footnotes/bookmarks (Docs only)\n\n## Design Principle\nEmit markdown-compatible output where possible. For metadata that doesn't map to markdown (e.g., comments), consider optional JSON sidecar or inline annotations.","status":"open","priority":2,"issue_type":"epic","created_at":"2026-01-05T20:24:58.765513Z","updated_at":"2026-01-05T20:24:58.765513Z"}
{"id":"mcp-workspace-google-fr1","title":"Extract comments from Docs","description":"Google Docs comments are not in the document body - they require a separate API call to drive.comments.list. Consider how to surface these in the text output.","design":"## API Path\nComments require:\n```typescript\ndrive.comments.list({\n    fileId: documentId,\n    fields: 'comments(id,content,author,quotedFileContent,anchor,replies)',\n});\n```\n\n## Design Decisions\n1. **Where to surface comments?**\n   - Inline at anchor point: `Some text [COMMENT: \"Is this right?\" - Jane]`\n   - Separate section at end of document\n   - Optional JSON sidecar alongside text\n\n2. **Include replies?** Comments can have threads\n\n3. **Resolved comments?** Include or filter out?\n\n## Acceptance Criteria\n- [ ] Design decision made on comment representation\n- [ ] Comments retrievable from Docs\n- [ ] Comments appear in output (format TBD)\n- [ ] Option to exclude comments if not needed","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-05T20:25:55.407165Z","updated_at":"2026-01-05T20:25:55.407165Z","dependencies":[{"issue_id":"mcp-workspace-google-fr1","depends_on_id":"mcp-workspace-google-fic","type":"parent-child","created_at":"2026-01-05T20:26:12.028987Z","created_by":"modha","metadata":"{}"}]}
{"id":"mcp-workspace-google-p9e","title":"Extract bold/italic formatting as markdown","description":"Docs and Slides textRun objects contain textStyle.bold and textStyle.italic (Docs) or style.bold and style.italic (Slides). Emit **text** for bold, *text* for italic, ***text*** for both.","design":"## Approach\nModify _readStructuralElement (Docs) and extractTextFromTextContent (Slides) to check:\n- textStyle.bold / style.bold → wrap in **\n- textStyle.italic / style.italic → wrap in *\n- Both → wrap in ***\n\n## Edge Cases\n- Formatting that spans partial words (rare but possible)\n- Nested formatting with links (already handling links)\n- Whitespace handling (preserve trailing whitespace outside formatting marks)\n\n## Acceptance Criteria\n- [ ] Bold text in Docs appears as **bold** in output\n- [ ] Italic text in Docs appears as *italic* in output\n- [ ] Bold text in Slides appears as **bold** in output\n- [ ] Italic text in Slides appears as *italic* in output\n- [ ] Combined formatting works (***bold italic***)\n- [ ] Formatting combined with links works: [**bold link**](url)","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-05T20:25:11.21379Z","updated_at":"2026-01-05T20:25:11.21379Z","dependencies":[{"issue_id":"mcp-workspace-google-p9e","depends_on_id":"mcp-workspace-google-fic","type":"parent-child","created_at":"2026-01-05T20:26:11.88606Z","created_by":"modha","metadata":"{}"}]}
{"id":"myitv-14l","title":"Evaluate navigation API for MCP integration","design":"Discovered /PrimaryMenu/GetMenuItems and GetMenuItemBranch APIs. Need to: (1) Test coverage across all 5 nav sections, (2) Check for rate limits, (3) Determine if menu structure matches content hierarchy, (4) Decide if get_navigation() tool is the right approach vs caching on startup vs something else.","notes":"RESOLUTION: Evaluated nav API: 57 items across 5 sections, 41 link to pages, no rate limits. Key finding: menu structure ≠ content hierarchy (pages exist outside nav, page children not exposed). Decision: not implementing get_navigation() tool — search is primary discovery and works regardless of menu structure. Documented findings in PLATFORM-NOTES.md.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T14:52:45.529976Z","updated_at":"2025-12-23T15:09:42.567988Z","closed_at":"2025-12-23T15:09:42.567992Z"}
{"id":"myitv-16j","title":"Add accordion content parser","design":"Parse data-model JSON from accordion components.\n\nDetection: Look for data-model attributes containing JSON arrays\nExtraction: Decode HTML entities, parse JSON, extract Name/Content pairs\nOutput: List of {question, answer} with HTML stripped from answers\n\nThis handles the FAQ-style pages where content is hidden in collapsed accordions.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T13:02:56.11486Z","updated_at":"2025-12-23T13:13:19.889507Z","closed_at":"2025-12-23T13:13:19.889507Z","close_reason":"Implemented accordion parser: extracts Q\u0026A from data-model JSON attributes, strips HTML, integrates into fetch_page output. Tested on Brand page - all 20 FAQ items extracted correctly."}
{"id":"myitv-39h","title":"Add MCP Resources for site guides and search strategy","description":"MyITV search can't find operational info (parking, facilities) because it lives in site-specific A-Z hubs with accordion content that isn't indexed. Claude needs upfront context about WHEN to use site guides vs search.","design":"## Problem\nSearching 'parking' returns noise (Barking, breaking). Real parking info is in White City A-Z page under 'Car Parking' accordion — but Claude doesn't know to look there.\n\n## Solution: MCP Resources + Tool\n\n### Resource 1: `myitv://sites`\nList of ITV office sites with A-Z guide URLs:\n- White City A-Z: https://my.itv.com/Home/Index/f945e163-606f-462b-ae01-27088f3a557b\n- Media City Travel: https://my.itv.com/Home/Index/31d2b54b-d1e0-4db2-b785-14116dfa11ee\n- Workplace Services hub: https://my.itv.com/Home/Index/1b846e09-37de-47cc-b178-7909e0786ca1\n- ID Pass: https://my.itv.com/Home/Index/a508aa7c-5fa8-4d63-8c96-9c8c656a7152\n\nInclude topics each covers (parking, catering, security, etc.)\n\n### Resource 2: `myitv://search-strategy`\nGuide on when to use search vs site guides:\n- Search: policies, documents, news\n- Site A-Z: parking, facilities, local amenities\n- Explains WHY accordion content isn't searchable\n\n### Tool: `get_site_guide(site, topic=\"\")`\nConvenience wrapper that:\n1. Takes site name (white-city, media-city) or \"list\"\n2. Fetches the A-Z page\n3. Optionally filters to section containing topic\n\n## Implementation\nUse FastMCP decorators:\n- @mcp.resource(\"myitv://sites\")\n- @mcp.resource(\"myitv://search-strategy\")\n- @mcp.tool() for get_site_guide\n\n## Files to modify\n- src/myitv_search/server.py\n\n## Reference\n- PLATFORM-NOTES.md has known GUIDs\n- White City A-Z content verified working via fetch_page","acceptance_criteria":"- [ ] myitv://sites resource returns markdown with office URLs\n- [ ] myitv://search-strategy resource explains when to use each approach\n- [ ] get_site_guide(\"white-city\") returns full A-Z content\n- [ ] get_site_guide(\"list\") shows available sites\n- [ ] get_site_guide(\"white-city\", \"parking\") filters to parking section\n- [ ] Resources visible via ListMcpResourcesTool","status":"closed","priority":2,"issue_type":"epic","created_at":"2026-01-05T10:37:40.062366Z","updated_at":"2026-01-05T11:00:12.906163Z","closed_at":"2026-01-05T11:00:12.906163Z","close_reason":"Added get_site_guide tool with fuzzy topic matching. Enhanced search to hint at site guides for facilities queries. Fixed accordion regex to handle A-Z index format. Tested parking and food queries successfully."}
{"id":"myitv-7cf","title":"Improve content extraction for hub pages","design":"REFINED SCOPE based on Dec 23 exploration:\n\nQ\u0026A accordion extraction: DONE (working)\n\nStill needed:\n1. Link extraction from page content — identify internal links, categorize by destination type\n2. Structured output — return dict with {title, content, links[], qa[]} instead of formatted string\n3. SPA detection — recognize SPA URLs and return clear 'cannot extract' message\n\nNOT needed:\n- Hierarchy/breadcrumb extraction (JS-rendered, not accessible)\n- Full page parsing (current approach is good enough)","notes":"DONE: (1) SPA detection - returns clear error for Hubs#, Members#, event#, Media# URLs. (2) Link extraction - categorizes all links as: download, internal, redirect, google_doc, google_sheet, google_slides, google_drive, external, spa. (3) JSON output - fetch_page now returns structured JSON with: url, type, title, content, links[], accordions[], download_urls[], error.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T12:27:06.197038Z","updated_at":"2025-12-23T15:14:12.232322Z","closed_at":"2025-12-23T15:14:12.232327Z"}
{"id":"myitv-7gn","title":"Investigate Home/Index page auth failures","design":"Some Home/Index pages redirect to login while others work fine. Need to identify pattern - which pages fail, why, and whether it's fixable with current cookies or needs different approach.","notes":"RESOLUTION: Found example - ITV Academy top level (3dd7cb34...) returns 401, but sub level (a7e7f603...) via shortcut URL works. This is page-level access control in the CMS, not a session/cookie issue. Some pages are restricted by design. No fix needed — document in SITEMAP.md and move on.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T12:27:05.358253Z","updated_at":"2025-12-23T14:14:40.936746Z","closed_at":"2025-12-23T14:14:40.936749Z"}
{"id":"myitv-8p2","title":"Add resource discovery for navigation pages","design":"Link extraction with destination awareness. Updated Dec 23 with SITEMAP.md context.\n\nSITEMAP.md now documents:\n- 22+ page GUIDs with sections/hierarchy\n- 12+ Tool GUIDs (searchable by name)\n- URL patterns and what works/doesn't\n\nImplementation:\n1. Extract hrefs from page HTML\n2. Categorize by pattern:\n   - /FileUpload/Download/{guid} → document (pass to pdf skill)\n   - /Home/Index/{guid} or /{guid} → internal page\n   - /redirect/{guid} → resolve first, then categorize\n   - /Content/File/Index/{guid} → document page\n   - docs.google.com → workspace MCP\n   - External URLs → note for user\n3. Return structured link list with destination types\n\nSITEMAP.md provides reference data for known pages/tools.","notes":"Completed as part of myitv-7cf work. Link categorization implemented in extract_links() function: categorizes by download, internal, redirect, google_doc, google_sheet, google_slides, google_drive, external, spa. Returns structured list with url, text, type, destination. fetch_page now includes all categorized links in JSON output.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-23T12:27:07.497918Z","updated_at":"2025-12-23T15:14:29.666862Z","closed_at":"2025-12-23T15:14:29.666865Z"}
{"id":"myitv-9ca","title":"Add URL resolver for redirect chains","design":"New tool or internal function: resolve_url()\n\nTakes any MyITV URL and follows redirects to find actual destination:\n- /redirect/{guid} → follow to real URL\n- /Home/Index/{guid} → identify if it's just a PDF wrapper\n- Content/File/Index → extract download URL\n\nReturns: {type, destination_url, title}\n\nThis is the foundation for the pre-digestion layer - understand what a URL actually points to before deciding how to handle it.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T13:02:54.691751Z","updated_at":"2025-12-23T13:09:38.291773Z","closed_at":"2025-12-23T13:09:38.291773Z","close_reason":"Implemented resolve() tool: follows redirects, detects destination types (document/page/download/external/error), extracts metadata (title, download_url, description). Tested with redirects, direct URLs, relative URLs, broken links."}
{"id":"sb-3c6","title":"Fix Ansible deprecation warnings in security role templates","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-21T23:25:36.824408Z","updated_at":"2025-12-30T23:21:16.639133Z","dependencies":[{"issue_id":"sb-3c6","depends_on_id":"sb-8r9","type":"parent-child","created_at":"2026-01-04T12:35:24.216474Z","created_by":"modha","metadata":"{}"}]}
{"id":"sb-3d6","title":"Implement hybrid data layer","description":"Merge SOAP base data with Push Port real-time updates. Single departures.json output. Handle conflicts, stale data, source priority.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-04T12:40:44.57081Z","updated_at":"2026-01-04T12:40:44.57081Z","dependencies":[{"issue_id":"sb-3d6","depends_on_id":"sb-z7c","type":"parent-child","created_at":"2026-01-04T12:40:55.706318Z","created_by":"modha","metadata":"{}"},{"issue_id":"sb-3d6","depends_on_id":"sb-7go","type":"blocks","created_at":"2026-01-04T12:41:02.970486Z","created_by":"modha","metadata":"{}"}]}
{"id":"sb-41v","title":"Fix two-trains pulsing bug","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"open","priority":3,"issue_type":"bug","created_at":"2025-12-22T21:39:02.297199Z","updated_at":"2025-12-30T23:21:16.638729Z","dependencies":[{"issue_id":"sb-41v","depends_on_id":"sb-mae","type":"parent-child","created_at":"2026-01-04T12:35:25.077419Z","created_by":"modha","metadata":"{}"}]}
{"id":"sb-6d7","title":"Review all beads with Sameer","description":"Walk through open beads, confirm priorities, close stale ones, ensure coherent plan.","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"closed","priority":1,"issue_type":"task","created_at":"2025-11-26T22:24:14.795684Z","updated_at":"2025-12-30T23:21:16.63758Z","closed_at":"2025-12-30T18:54:46.209602Z","close_reason":"Completed during Dec 30 cleanup session. All beads reviewed, priorities adjusted to P3, project parked until interest returns."}
{"id":"sb-7go","title":"Design hybrid merge strategy","description":"If schedules sparse: SOAP provides destinations, Push Port provides real-time updates. Match by scheduled_time + platform (no common RID). Document merge rules.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-04T12:40:43.630063Z","updated_at":"2026-01-04T12:40:43.630063Z","dependencies":[{"issue_id":"sb-7go","depends_on_id":"sb-z7c","type":"parent-child","created_at":"2026-01-04T12:40:55.662549Z","created_by":"modha","metadata":"{}"},{"issue_id":"sb-7go","depends_on_id":"sb-c1w","type":"blocks","created_at":"2026-01-04T12:41:02.923668Z","created_by":"modha","metadata":"{}"}]}
{"id":"sb-7jh","title":"Made train data accessible from anywhere","description":"Move Push Port consumer to kube.lan, expose via API. Signboard becomes thin client. Web UI for Tailscale access from anywhere. Better than any public train app.","status":"open","priority":2,"issue_type":"epic","created_at":"2026-01-04T12:50:43.81403Z","updated_at":"2026-01-04T12:50:43.81403Z"}
{"id":"sb-8r9","title":"Made signboard data reliable","description":"API integrations and infrastructure working correctly - accurate data, clean deployments.","status":"open","priority":2,"issue_type":"epic","created_at":"2026-01-04T12:35:14.112174Z","updated_at":"2026-01-04T12:35:14.112174Z"}
{"id":"sb-9bj","title":"Add acceptance criteria to new beads","description":"Beads created Jan 2026 (sb-8r9, sb-mae, sb-7jh children) have descriptions but no concrete done-when checkboxes. Add acceptance criteria to make completion unambiguous.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-04T13:06:21.343545Z","updated_at":"2026-01-04T13:06:21.343545Z"}
{"id":"sb-9mc","title":"Design kube.lan train service architecture","description":"How the service runs on kube.lan. Container vs systemd. Data storage (SQLite? in-memory?). API design (REST vs WebSocket vs both). Auth for Tailscale access.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-04T12:50:56.66833Z","updated_at":"2026-01-04T12:50:56.66833Z","dependencies":[{"issue_id":"sb-9mc","depends_on_id":"sb-7jh","type":"parent-child","created_at":"2026-01-04T12:51:11.274956Z","created_by":"modha","metadata":"{}"}]}
{"id":"sb-c1w","title":"Validate Schedule message frequency","description":"Deploy pushport_client.py, let run 24-48h, check if Schedule messages arrive often enough for destinations. Determines if hybrid integration is needed.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-04T12:40:42.564253Z","updated_at":"2026-01-04T12:40:42.564253Z","dependencies":[{"issue_id":"sb-c1w","depends_on_id":"sb-z7c","type":"parent-child","created_at":"2026-01-04T12:40:55.613122Z","created_by":"modha","metadata":"{}"}]}
{"id":"sb-c89","title":"Convert signboard to thin display client","description":"Signboard fetches from kube.lan API instead of running its own consumer. Simpler, more reliable. Just renders what it's told.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-04T12:51:02.185855Z","updated_at":"2026-01-04T12:51:02.185855Z","dependencies":[{"issue_id":"sb-c89","depends_on_id":"sb-7jh","type":"parent-child","created_at":"2026-01-04T12:51:11.439344Z","created_by":"modha","metadata":"{}"},{"issue_id":"sb-c89","depends_on_id":"sb-qyd","type":"blocks","created_at":"2026-01-04T12:51:11.590954Z","created_by":"modha","metadata":"{}"}]}
{"id":"sb-cki","title":"Frontend: delay trend indicators","description":"Show \u003e\u003e (worsening) and \u003c\u003c (recovering) in train rows. Color logic for trend. Integrate with existing delay coloring.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-04T12:40:45.700993Z","updated_at":"2026-01-04T12:40:45.700993Z","dependencies":[{"issue_id":"sb-cki","depends_on_id":"sb-z7c","type":"parent-child","created_at":"2026-01-04T12:40:55.785888Z","created_by":"modha","metadata":"{}"}]}
{"id":"sb-dkg","title":"Move Push Port consumer to kube.lan","description":"Migrate pushport_client.py to kube.lan. Systemd unit, credentials, monitoring. Stop running on signboard.lan.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-04T12:50:58.322171Z","updated_at":"2026-01-04T12:50:58.322171Z","dependencies":[{"issue_id":"sb-dkg","depends_on_id":"sb-7jh","type":"parent-child","created_at":"2026-01-04T12:51:11.320159Z","created_by":"modha","metadata":"{}"},{"issue_id":"sb-dkg","depends_on_id":"sb-9mc","type":"blocks","created_at":"2026-01-04T12:51:11.47623Z","created_by":"modha","metadata":"{}"}]}
{"id":"sb-glv","title":"Fix Met Office API","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-14T19:30:54.334276Z","updated_at":"2025-12-30T23:21:16.639612Z","dependencies":[{"issue_id":"sb-glv","depends_on_id":"sb-8r9","type":"parent-child","created_at":"2026-01-04T12:35:24.142624Z","created_by":"modha","metadata":"{}"}]}
{"id":"sb-hxf","title":"Fix National Rail API integration","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-14T19:30:49.109726Z","updated_at":"2025-12-30T23:21:16.639852Z","dependencies":[{"issue_id":"sb-hxf","depends_on_id":"sb-8r9","type":"parent-child","created_at":"2026-01-04T12:35:24.179597Z","created_by":"modha","metadata":"{}"}]}
{"id":"sb-mae","title":"Made signboard display polished","description":"Visual quality and UX - no glitches, looks good.","status":"open","priority":2,"issue_type":"epic","created_at":"2026-01-04T12:35:15.147166Z","updated_at":"2026-01-04T12:35:15.147166Z"}
{"id":"sb-qyd","title":"Build train data API","description":"REST and/or WebSocket API for train data. Endpoints: current departures, historical delays, station info. Tailscale-authenticated.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-04T12:50:59.664191Z","updated_at":"2026-01-04T12:50:59.664191Z","dependencies":[{"issue_id":"sb-qyd","depends_on_id":"sb-7jh","type":"parent-child","created_at":"2026-01-04T12:51:11.36147Z","created_by":"modha","metadata":"{}"},{"issue_id":"sb-qyd","depends_on_id":"sb-dkg","type":"blocks","created_at":"2026-01-04T12:51:11.513719Z","created_by":"modha","metadata":"{}"}]}
{"id":"sb-t4d","title":"Design notification bar events","description":"Priority and duration for each event type (DELAY_INCREASED, PLATFORM_CHANGED, CANCELLED, etc.). When to interrupt weather. Message format. Rotation when multiple events queued.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-04T12:40:45.53895Z","updated_at":"2026-01-04T12:40:45.53895Z","dependencies":[{"issue_id":"sb-t4d","depends_on_id":"sb-z7c","type":"parent-child","created_at":"2026-01-04T12:40:55.745453Z","created_by":"modha","metadata":"{}"}]}
{"id":"sb-tz9","title":"Frontend: event notifications","description":"Notification bar messages on row 7. Event rotation, fade timing, priority queue. Temporarily replaces weather display.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-04T12:40:46.795683Z","updated_at":"2026-01-04T12:40:46.795683Z","dependencies":[{"issue_id":"sb-tz9","depends_on_id":"sb-z7c","type":"parent-child","created_at":"2026-01-04T12:40:55.825739Z","created_by":"modha","metadata":"{}"},{"issue_id":"sb-tz9","depends_on_id":"sb-t4d","type":"blocks","created_at":"2026-01-04T12:41:03.013662Z","created_by":"modha","metadata":"{}"}]}
{"id":"sb-uik","title":"Design refresh","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-14T19:30:59.554552Z","updated_at":"2025-12-30T23:21:16.639383Z","dependencies":[{"issue_id":"sb-uik","depends_on_id":"sb-mae","type":"parent-child","created_at":"2026-01-04T12:35:25.114672Z","created_by":"modha","metadata":"{}"}]}
{"id":"sb-z7c","title":"Push Port events display architecture","description":"Design how Push Port events surface on the display.\n\nEVENT TYPES (from sz2):\n- DELAY_INCREASED/DECREASED/NOW_ON_TIME\n- PLATFORM_CHANGED/CONFIRMED\n- DESTINATION_CHANGED\n- DEPARTED\n- CANCELLED\n- ARRIVING (imminent)\n\nDISPLAY ZONES:\n1. Train rows (1-5): ARRIVING pulse, CANCELLED state, delay colors\n2. Notification bar (row 7): Event messages, temporarily replacing weather\n\nOPEN QUESTIONS:\n- Priority/duration for notification bar events\n- How cancellations affect row display vs notification\n- ARRIVING detection from Push Port vs time-based\n- Event message format and rotation\n\nNeeds design discussion before implementation.","design":"\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Work through items, check direction at each completion\n3. Update notes at milestones","status":"open","priority":3,"issue_type":"epic","created_at":"2025-11-26T21:36:35.114078Z","updated_at":"2025-12-30T23:21:16.640078Z"}
{"id":"sb-zat","title":"Build web UI for remote access","description":"Web page for viewing train data from anywhere via Tailscale. Better than National Rail app. Mobile-friendly.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-04T12:51:01.217722Z","updated_at":"2026-01-04T12:51:01.217722Z","dependencies":[{"issue_id":"sb-zat","depends_on_id":"sb-7jh","type":"parent-child","created_at":"2026-01-04T12:51:11.4006Z","created_by":"modha","metadata":"{}"},{"issue_id":"sb-zat","depends_on_id":"sb-qyd","type":"blocks","created_at":"2026-01-04T12:51:11.552442Z","created_by":"modha","metadata":"{}"}]}
{"id":"sb-zkw","title":"Deploy Push Port service","description":"Systemd unit for pushport_client.py. Ansible role. Monitoring and health checks. Credential management for STOMP connection.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-04T12:40:47.770256Z","updated_at":"2026-01-04T12:40:47.770256Z","dependencies":[{"issue_id":"sb-zkw","depends_on_id":"sb-z7c","type":"parent-child","created_at":"2026-01-04T12:40:55.866442Z","created_by":"modha","metadata":"{}"}]}
{"id":"skill-beads-03o","title":"Add Epic hierarchy presentation rules","description":"Codify how Claude should present beads to user — distinguishing Desired Outcomes (epics) from leaf tasks with visual hierarchy.","design":"## Presentation Pattern\nWhen showing beads:\n\n**Desired Outcomes** (type=epic):\n📦 [id] Outcome Title\n   ├── [child-id] Next Action 1\n   ├── [child-id] Next Action 2\n   └── [child-id] Next Action 3 (waiting for: Action 2)\n\n**Standalone tasks** (no parent):\n• [id] Title [priority] [status]\n\n## Commands for hierarchy\n- bd epic --tree \u003cid\u003e\n- bd dep tree \u003cid\u003e\n\n## Integration with vocabulary\nUse GTD terms in presentation (see CLAUDE.md mapping)","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-01T21:45:47.826705Z","updated_at":"2026-01-01T22:16:24.011397Z","closed_at":"2026-01-01T22:16:24.011397Z","close_reason":"Added 'Presenting Beads to User' section to SKILL.md. Includes: visual hierarchy for Desired Outcomes vs standalone Next Actions, status indicators, example portfolio view. References CLAUDE.md vocabulary mapping.","dependencies":[{"issue_id":"skill-beads-03o","depends_on_id":"skill-beads-sl1","type":"blocks","created_at":"2026-01-01T21:48:17.223278Z","created_by":"modha","metadata":"{}"},{"issue_id":"skill-beads-03o","depends_on_id":"skill-beads-24w","type":"parent-child","created_at":"2026-01-01T21:48:26.881382Z","created_by":"modha","metadata":"{}"}]}
{"id":"skill-beads-0np","title":"Add bd-portfolio to PATH or shell alias","description":"Make portfolio script easier to invoke. Currently requires full path ~/.claude/skills/beads/scripts/bd-portfolio.sh. Options: symlink to ~/bin, shell alias, or wrapper script.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-30T20:20:20.990772Z","updated_at":"2026-01-01T21:44:57.296403Z","closed_at":"2026-01-01T21:44:57.296403Z","close_reason":"Duplicate of skill-beads-oz5"}
{"id":"skill-beads-24w","title":"Beads skill speaks GTD, not Agile","description":"Transform beads skill to use GTD vocabulary and mental model. Desired Outcomes, Next Actions, Waiting For — not Epics, Tickets, Blockers.","design":"## Vision\nWhen Claude works with beads, it thinks in GTD terms:\n- Outcomes, not features\n- Next Actions, not tickets\n- Natural planning, not sprint planning\n\n## Acceptance Criteria\n- [ ] Vocabulary mapping in CLAUDE.md\n- [ ] Presentation rules use GTD framing\n- [ ] Field Reports documented as pattern\n\n## Approach\nFoundation first (vocabulary), then apply to presentation and patterns.","status":"closed","priority":1,"issue_type":"epic","created_at":"2026-01-01T21:48:03.607083Z","updated_at":"2026-01-01T22:18:13.291912Z","closed_at":"2026-01-01T22:18:13.291912Z","close_reason":"Desired Outcome achieved: Beads skill now speaks GTD. Completed: (1) vocabulary mapping in CLAUDE.md, (2) hierarchy presentation rules, (3) Field Reports pattern. Work presented as goals with cascading actions, not flat ticket lists."}
{"id":"skill-beads-2as","title":"Field Report: Presentation format not used despite being in skill","description":"Claude loaded beads skill but defaulted to plain jq output instead of GTD-style visual hierarchy.","design":"## Context\nJust loaded beads skill at session start, checked bd ready, presented results to user.\n\n## Observation\nDespite the skill having a detailed \"Presenting Beads to User\" section with visual hierarchy (📦 for epics, tree structure, status symbols), I defaulted to a plain bullet list via jq. The presentation guidance was *in my context* but I didn't apply it.\n\n## Why I Think This Happened\n1. **Task framing**: I was \"checking state\" not \"presenting to user\" — different mental mode\n2. **Buried in long skill**: The presentation section is mid-document, not at point of use\n3. **No trigger**: Nothing reminded me \"when showing beads, use this format\"\n4. **jq is easy**: Quick command, immediate output — path of least resistance\n\n## Suggestion\nOptions for future Claudes:\n1. **Prominent reminder**: Add to Session Start Protocol section: \"When presenting beads to user, use GTD visual hierarchy (see Presenting Beads section)\"\n2. **Helper script**: `bd ready --pretty` or a wrapper that formats output\n3. **Inline at bd ready**: Put a condensed format reminder right after the bd ready command example\n4. **Skill description**: Add \"presents beads in GTD visual hierarchy\" to skill triggers so it's front-loaded\n\nThe friction: presentation guidance exists but isn't at the moment of action.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-03T14:14:27.835447Z","updated_at":"2026-01-03T14:14:27.835447Z","labels":["field-report"]}
{"id":"skill-beads-36b","title":"Beads integrates with session rituals","description":"Session-management skills reliably load beads context. Deterministic scripts + explicit invocation, not semantic matching.","design":"## Vision\nWhen /open runs, beads context is always available:\n- Script gathers bd ready, in_progress\n- Skill explicitly loads via Skill(beads)\n- Draw-down pattern reliably triggers\n\n## Acceptance Criteria\n- [ ] open-context.sh calls bd directly\n- [ ] Explicit Skill(beads) invocation\n- [ ] Optional: bd blocked check for strategic context\n\n## Cross-Repo\nLives in skill-session-management, not here.\nReference beads point to the work.","status":"closed","priority":1,"issue_type":"epic","created_at":"2026-01-01T21:48:04.828719Z","updated_at":"2026-01-01T23:08:28.686986Z","closed_at":"2026-01-01T23:08:28.686986Z","close_reason":"Moved to skill-session-management repo — work lives where it happens"}
{"id":"skill-beads-37v","title":"Hub infrastructure: multi-repo hydration + bd-portfolio.sh enhancements","description":"Set up ~/Repos/.beads as unified hub for all projects. Enhanced bd-portfolio.sh with setup/register/routes/prune commands.","design":"## What was built\n\n1. **Multi-repo hydration** - ~/Repos/.beads aggregates issues from all child projects\n2. **routes.jsonl** - Enables prefix routing and `bd activity --town`\n3. **bd-portfolio.sh enhancements:**\n   - `setup` - Full hub setup (register + sync + routes)\n   - `register` - Add unregistered projects to hub\n   - `routes` - Update routes.jsonl with discovered prefixes\n   - `prune` - Remove stale entries after moves/deletes\n   - Registration status in portfolio output\n   - Stale detection with warnings\n\n## Key learnings\n\n- `bd repo add` (hydration) and `routes.jsonl` (routing) are complementary systems\n- Hub at parent dir works - child projects find their own .beads first\n- Daemon warnings for ~/Repos (not a git repo) are harmless - direct mode works","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-03T14:17:17.304715Z","updated_at":"2026-01-03T14:17:23.708856Z","closed_at":"2026-01-03T14:17:23.708856Z","close_reason":"Hub setup complete. bd-portfolio.sh enhanced with setup/register/routes/prune. Tested and working."}
{"id":"skill-beads-3dg","title":"Beads and Memory become searchable together","description":"Bead notes become part of searchable memory. Past sessions AND bead content discoverable via mem search.","design":"## Vision\nWhen resuming work after weeks:\n- mem search finds relevant past sessions\n- mem search ALSO finds bead notes with design decisions\n- Field reports surface as institutional knowledge\n\n## Acceptance Criteria\n- [ ] BeadsAdapter in claude-memory indexes .beads/issues.jsonl\n- [ ] Closed beads included (they contain decisions)\n- [ ] Field reports become searchable\n\n## Cross-Repo\nLives in claude-memory, not here.","status":"closed","priority":2,"issue_type":"epic","created_at":"2026-01-01T21:48:06.198273Z","updated_at":"2026-01-01T23:08:29.511339Z","closed_at":"2026-01-01T23:08:29.511339Z","close_reason":"Moved to claude-memory repo — work lives where it happens"}
{"id":"skill-beads-3g5","title":"Add means-ends alignment gate at epic close / phase transitions","description":"At epic close (or phase transition), prompt: 'Does the next phase still serve the original goals, given what this phase learned?'\n\nDiscovered during claude-memory work: Phase 2 validated hybrid extraction, but Phase 3 spec still assumed entity-centric approach. The means and ends had drifted. An alignment check would have surfaced this earlier.\n\nGate should trigger at:\n- Epic close when dependent phases exist  \n- Phase transitions in multi-phase work\n- Possibly at session start when picking up blocked work that just became unblocked\n\nCONTEXT: This touches session-management skills too (skill-session-management repo). The /close ritual might be a natural place for this prompt, not just bd epic close. Consider whether this belongs here or in session-closing skill, or needs coordination between both.","design":"## Means-Ends Alignment Gate\n\n**Trigger:** When closing an epic that unblocks other work, or at phase transitions.\n\n**Prompt:** 'Before moving to the next phase — do the means still match the ends? Given what we learned in [closed phase], does [next phase] still serve the original benchmark/goal?'\n\n**If misaligned:** Pause, reframe the next phase, possibly close/recreate with updated scope.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-30T19:22:02.982208Z","updated_at":"2026-01-01T23:08:28.685688Z","closed_at":"2026-01-01T23:08:28.685688Z","close_reason":"Moved to skill-session-management repo — work lives where it happens","dependencies":[{"issue_id":"skill-beads-3g5","depends_on_id":"skill-beads-36b","type":"parent-child","created_at":"2026-01-01T21:48:26.9679Z","created_by":"modha","metadata":"{}"}]}
{"id":"skill-beads-3rb","title":"Document Field Reports pattern in beads skill","description":"Add Field Reports as a distinct bead genre for Claude-to-Claude knowledge transfer. Dense, observational, judgement-laden — not bug tickets.","design":"## What Field Reports Are\nClaude-to-Claude messaging: observations, friction points, learnings.\n- Author: Claude (specifically)\n- Audience: Future Claudes\n- Lifecycle: Filed → Persists (rarely closed)\n- Voice: Observational judgement, not mechanical logging\n\n## Template\nbd create \"Field Report: [observation]\" \\\n  --type task \\\n  --label field-report \\\n  --description \"[What I noticed]\" \\\n  --design \"Context: [What I was trying to do]\nObservation: [What happened, with judgement]\nSuggestion: [What might help future Claudes]\"\n\n## Integration\n- Don't close field reports — they're institutional memory\n- Review periodically: extract patterns → skill updates\n- If indexed by memory system, becomes searchable knowledge\n\n## Why \"Field Report\" Not \"Bug Ticket\"\nLLMs are judgement machines. Field reports express considered views,\nnot just facts. The vibe is distinct from steps-to-reproduce.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-01T21:45:44.682535Z","updated_at":"2026-01-01T22:18:03.567428Z","closed_at":"2026-01-01T22:18:03.567428Z","close_reason":"Added 'Field Reports (Claude-to-Claude)' section to SKILL.md. Documents: what makes them different from work items, when to file, template, lifecycle (don't close — institutional memory), and why the naming matters.","dependencies":[{"issue_id":"skill-beads-3rb","depends_on_id":"skill-beads-24w","type":"parent-child","created_at":"2026-01-01T21:48:26.902922Z","created_by":"modha","metadata":"{}"}]}
{"id":"skill-beads-4m5","title":"Delete RECENT_DEVELOPMENTS.md — use bd info --whats-new instead","description":"RECENT_DEVELOPMENTS.md covers v0.23.1 but bd is at v0.42.0. Static file can't keep up with weekly releases.","design":"## Action\nDelete references/RECENT_DEVELOPMENTS.md\n\n## Replacement\nbd info --whats-new already exists and is current.\nSkill already documents this command in session start protocol.\n\n## Why\n19 versions behind. Maintenance burden with no value.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-01T21:45:46.569312Z","updated_at":"2026-01-01T21:54:35.179293Z","closed_at":"2026-01-01T21:54:35.179293Z","close_reason":"Deleted references/RECENT_DEVELOPMENTS.md. bd info --whats-new is the authoritative source for version changes."}
{"id":"skill-beads-6a7","title":"Verify kept sections: Session Start, Draw-Down, Presentation, Field Reports, TodoWrite","description":"Final check that essential content remains, target \u003c500 lines.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-01T22:26:34.904597Z","updated_at":"2026-01-01T23:00:51.603951Z","closed_at":"2026-01-01T23:00:51.603951Z","close_reason":"Verified essential sections present: Session Start, Presenting Beads, Field Reports, Integration with TodoWrite, Draw-Down. Line count: 589 (down from 822, target was \u003c500). Further trimming possible in sections: Statistics, Troubleshooting, Database Selection, Bootstrap, Common Patterns.","dependencies":[{"issue_id":"skill-beads-6a7","depends_on_id":"skill-beads-tig","type":"parent-child","created_at":"2026-01-01T22:26:49.503239Z","created_by":"modha","metadata":"{}"},{"issue_id":"skill-beads-6a7","depends_on_id":"skill-beads-a1r","type":"blocks","created_at":"2026-01-01T22:26:56.329448Z","created_by":"modha","metadata":"{}"},{"issue_id":"skill-beads-6a7","depends_on_id":"skill-beads-i1n","type":"blocks","created_at":"2026-01-01T22:26:56.352151Z","created_by":"modha","metadata":"{}"},{"issue_id":"skill-beads-6a7","depends_on_id":"skill-beads-ym5","type":"blocks","created_at":"2026-01-01T22:26:56.372876Z","created_by":"modha","metadata":"{}"},{"issue_id":"skill-beads-6a7","depends_on_id":"skill-beads-hjt","type":"blocks","created_at":"2026-01-01T22:26:56.393356Z","created_by":"modha","metadata":"{}"},{"issue_id":"skill-beads-6a7","depends_on_id":"skill-beads-s4x","type":"blocks","created_at":"2026-01-01T22:26:56.414704Z","created_by":"modha","metadata":"{}"}]}
{"id":"skill-beads-a1r","title":"Replace Core CLI Operations with pointer to CLI_BOOTSTRAP_ADMIN.md","description":"~55 lines. Keep essential commands, point to reference for full list.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-01T22:26:25.20728Z","updated_at":"2026-01-01T22:42:54.723724Z","closed_at":"2026-01-01T22:42:54.723724Z","close_reason":"Trimmed Core CLI Operations from ~53 lines to ~15 lines. Kept essential workflow and jq patterns, pointed to reference for full CLI.","dependencies":[{"issue_id":"skill-beads-a1r","depends_on_id":"skill-beads-tig","type":"parent-child","created_at":"2026-01-01T22:26:49.39118Z","created_by":"modha","metadata":"{}"}]}
{"id":"skill-beads-al2","title":"Second pass: slim SKILL.md to \u003c500 lines","description":"Currently 589 lines, target \u003c500. Trim: Statistics, Troubleshooting, Database Selection, Bootstrap, Common Patterns sections.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-02T19:49:19.112924Z","updated_at":"2026-01-02T19:49:19.112924Z"}
{"id":"skill-beads-e4e","title":"Add 'bd blocked' check for strategic context at session start","description":"At session start, checking only bd ready gives task queue but not strategic picture. Should also check bd blocked to understand dependency graph and what completing current work unlocks.","design":"Add to Session Start Protocol section: after bd ready, run bd blocked to see what's waiting. Helps orient to 'what am I building toward' not just 'what can I do next'.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-30T19:16:50.216961Z","updated_at":"2026-01-01T23:08:28.684507Z","closed_at":"2026-01-01T23:08:28.684507Z","close_reason":"Moved to skill-session-management repo — work lives where it happens","dependencies":[{"issue_id":"skill-beads-e4e","depends_on_id":"skill-beads-36b","type":"parent-child","created_at":"2026-01-01T21:48:26.945689Z","created_by":"modha","metadata":"{}"}]}
{"id":"skill-beads-gp4","title":"Index bead notes in memory system","description":"Enable mem search to find content from bead notes, design fields, and closed issues. Currently beads and memory are parallel but not connected.","design":"## Approach\nAdd BeadsAdapter to claude-memory that indexes .beads/issues.jsonl content.\n\n## Scope\n- Index open AND closed beads (closed contain valuable decisions)\n- Extract: title, description, design, notes, acceptance_criteria\n- Source type: `beads`\n- Track last_updated to avoid re-indexing\n\n## Why This Matters\nWhen resuming a bead after weeks, `mem search \"\u003ccontext\u003e\"` should surface past sessions AND the bead's own accumulated notes.\n\n## Cross-Repo\nThis lives in claude-memory repo, not skill-beads. File reference bead there.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-01T21:45:39.51166Z","updated_at":"2026-01-01T23:08:29.510065Z","closed_at":"2026-01-01T23:08:29.510065Z","close_reason":"Moved to claude-memory repo — work lives where it happens","dependencies":[{"issue_id":"skill-beads-gp4","depends_on_id":"skill-beads-3dg","type":"parent-child","created_at":"2026-01-01T21:48:26.989651Z","created_by":"modha","metadata":"{}"}]}
{"id":"skill-beads-hjt","title":"Replace Molecules section with pointer to MOLECULES.md","description":"~79 lines. Keep quick concepts table, point to reference for commands.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-01T22:26:29.240304Z","updated_at":"2026-01-01T22:51:36.860242Z","closed_at":"2026-01-01T22:51:36.860242Z","close_reason":"Trimmed Molecules section from ~76 lines to ~18 lines. Kept quick concepts table and essential commands, pointed to reference.","dependencies":[{"issue_id":"skill-beads-hjt","depends_on_id":"skill-beads-tig","type":"parent-child","created_at":"2026-01-01T22:26:49.459479Z","created_by":"modha","metadata":"{}"}]}
{"id":"skill-beads-i1n","title":"Replace Dependencies section with pointer to DEPENDENCIES.md","description":"~52 lines. Keep mental model trap warning, point to reference for full semantics.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-01T22:26:26.837377Z","updated_at":"2026-01-01T22:45:16.997862Z","closed_at":"2026-01-01T22:45:16.997862Z","close_reason":"Trimmed Dependencies from ~50 lines to ~14 lines. Kept mental model trap warning and mnemonic, pointed to reference for full patterns.","dependencies":[{"issue_id":"skill-beads-i1n","depends_on_id":"skill-beads-tig","type":"parent-child","created_at":"2026-01-01T22:26:49.413993Z","created_by":"modha","metadata":"{}"}]}
{"id":"skill-beads-jdq","title":"Document Todoist ↔ Beads relationship","description":"Clarify: Todoist = what + why, Beads = what + how. Where they overlap, what's distinct. Weekly review as bridge.","design":"## Key Insight from Session\nTodoist: WHAT + WHY (Desired Outcomes, strategic intent)\nBeads: WHAT + HOW (Technical implementation, dependencies)\n       ↑\n     overlap on \"what\"\n\n## Questions to Answer\n- Should there be sync? (Probably not — too brittle)\n- How does weekly review bridge them?\n- Where should this documentation live?","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-02T19:49:20.721737Z","updated_at":"2026-01-02T19:49:20.721737Z"}
{"id":"skill-beads-oz5","title":"Add bd-portfolio.sh to PATH or create alias","description":"Portfolio script requires full path (~/.claude/skills/beads/scripts/bd-portfolio.sh). Need easier invocation.","design":"## Options\n1. Add to PATH in shell profile\n2. Create alias: alias bd-portfolio='~/.claude/skills/beads/scripts/bd-portfolio.sh'\n3. Symlink to ~/bin or similar\n\n## Context\nScript built in prior session, used successfully this session for prioritization triage.\nCurrently at: ~/.claude/skills/beads/scripts/bd-portfolio.sh","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-30T23:49:56.219202Z","updated_at":"2026-01-01T22:26:04.678979Z","closed_at":"2026-01-01T22:26:04.678979Z","close_reason":"Superseded by 'Presenting Beads to User' section in SKILL.md. Claude can now format beads hierarchically directly from bd list --json. Script remains available for human shell usage but no longer needs PATH setup."}
{"id":"skill-beads-s4x","title":"Replace Issue Lifecycle with pointer to WORKFLOWS.md","description":"~50 lines. Content already in WORKFLOWS.md, can reduce to brief summary.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-01T22:26:33.620569Z","updated_at":"2026-01-01T23:00:17.658447Z","closed_at":"2026-01-01T23:00:17.658447Z","close_reason":"Trimmed Issue Lifecycle from ~49 lines to ~15 lines. Kept workflow summary and key phases, pointed to reference.","dependencies":[{"issue_id":"skill-beads-s4x","depends_on_id":"skill-beads-tig","type":"parent-child","created_at":"2026-01-01T22:26:49.48138Z","created_by":"modha","metadata":"{}"}]}
{"id":"skill-beads-sl1","title":"Add GTD vocabulary mapping to CLAUDE.md","description":"Document GTD ↔ Agile vocabulary preferences in global CLAUDE.md. Preferred: Desired Outcome, Next Action, Waiting For. Avoid: Epic, Ticket, Backlog, Blocker, User Story.","design":"## Approach\nAdd section to ~/.claude/CLAUDE.md:\n\n## Vocabulary Preferences\n\n| Say This | Not This | Because |\n|----------|----------|---------|\n| Desired Outcome | Epic, User Story | Outcomes focus on results |\n| Next Action | Task, Ticket | Actions are concrete |\n| Waiting For | Blocked | Less combative |\n| Someday/Maybe | Backlog | Not a burden |\n| Project Plan | Sprint | Not a race |\n\n## Location\nGlobal CLAUDE.md because:\n- Translation layer applies across all skills\n- Both beads and todoist-gtd need this\n- Vocabulary preference is user's mental model, not tool-specific","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-01T21:45:42.75637Z","updated_at":"2026-01-01T21:55:19.181016Z","closed_at":"2026-01-01T21:55:19.181016Z","close_reason":"Added Vocabulary Preferences section to ~/.claude/CLAUDE.md. GTD terms (Desired Outcome, Next Action, Waiting For) preferred over Agile jargon (Epic, Ticket, Blocker). Includes natural planning model reference and outcome quality test.","dependencies":[{"issue_id":"skill-beads-sl1","depends_on_id":"skill-beads-24w","type":"parent-child","created_at":"2026-01-01T21:48:26.858894Z","created_by":"modha","metadata":"{}"}]}
{"id":"skill-beads-tig","title":"Slim down SKILL.md — move duplicated content to references","description":"SKILL.md is 822 lines — should be \u003c500. Replace duplicated content with pointers to reference files.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-31T13:17:27.19559Z","updated_at":"2026-01-01T23:00:52.644783Z","closed_at":"2026-01-01T23:00:52.644783Z","close_reason":"Slimmed SKILL.md from 822 to 589 lines (28% reduction). Replaced 5 sections with pointers to references. Essential content preserved. Target was \u003c500 — further pass could trim Statistics/Troubleshooting/Bootstrap sections."}
{"id":"skill-beads-tyj","title":"Add bd calls to session-management scripts + explicit Skill(beads) invocation","description":"Enhance open-context.sh with direct bd calls. Add explicit Skill(beads) invocation when GATE_REQUIRED=true instead of relying on semantic matching.","design":"## Approach\n1. Add to open-context.sh:\n   - Check for .beads/ or ~/.beads/\n   - Output GATE_REQUIRED=true\n   - Run bd ready --json, bd list --status in_progress --json\n\n2. Update session-opening skill:\n   - When GATE_REQUIRED=true, call Skill(beads) explicitly\n   - Explicit invocation bypasses unreliable semantic matching\n\n## Why This Matters\nMemory search showed: \"Semantic skill triggering is unreliable compared to explicit invocation\"\nRedundancy works, but explicit invocation is more reliable.\n\n## Cross-Repo\nLives in skill-session-management repo.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-01T21:45:41.06359Z","updated_at":"2026-01-01T23:08:28.683073Z","closed_at":"2026-01-01T23:08:28.683073Z","close_reason":"Moved to skill-session-management repo — work lives where it happens","dependencies":[{"issue_id":"skill-beads-tyj","depends_on_id":"skill-beads-36b","type":"parent-child","created_at":"2026-01-01T21:48:26.924229Z","created_by":"modha","metadata":"{}"}]}
{"id":"skill-beads-x7f","title":"Create proto for skill development workflow with quality gates","description":"Encode skill creation as a beads proto with quality gates as required steps. Prevents skipping anthropic checker and skill-quality-gate.","design":"## Proto Structure\n\nmol-skill-creation\n├── Step 1: Create skill structure (SKILL.md, references/)\n│   └── Acceptance: SKILL.md exists with valid frontmatter\n├── Step 2: Run anthropic skill checker\n│   └── Depends: Step 1 closed\n│   └── Acceptance: Checker passes or issues addressed\n├── Step 3: Run skill-quality-gate\n│   └── Depends: Step 2 closed  \n│   └── Acceptance: Gate passes\n├── Step 4: Final review and commit\n│   └── Depends: Step 3 closed\n\n## Invocation\nbd pour mol-skill-creation --var name=\u003cskill-name\u003e\n\n## Variant Needed\nmol-skill-update for significant changes to existing skills","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T20:13:14.557832Z","updated_at":"2026-01-01T23:02:35.07632Z","closed_at":"2026-01-01T23:02:35.07632Z","close_reason":"Someday/Maybe — skill creation is infrequent. skill-checker skill exists for manual quality checks. Proto automation not worth the setup cost now."}
{"id":"skill-beads-ym5","title":"Replace Compaction/Design Context with pointer to WORKFLOWS.md","description":"~67 lines combined. Keep key trigger, point to reference for full workflow.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-01T22:26:28.112669Z","updated_at":"2026-01-01T22:48:00.460536Z","closed_at":"2026-01-01T22:48:00.460536Z","close_reason":"Combined Surviving Compaction, Capturing Design Context, and Progress Checkpointing into single 'Session Continuity' section. Trimmed from ~67 lines to ~15 lines.","dependencies":[{"issue_id":"skill-beads-ym5","depends_on_id":"skill-beads-tig","type":"parent-child","created_at":"2026-01-01T22:26:49.437074Z","created_by":"modha","metadata":"{}"}]}
{"id":"skill-dbt-coaching-5du","title":"Add README explaining notes structure to future Claude","description":"## Context\nThe apple-notes folder contains personal tuition notes (Jake sessions) vs group module notes. Future Claude sessions need to understand which is which.\n\n## Acceptance Criteria\n- [ ] README in references/apple-notes/ explaining:\n  - DBT Notes - Jake.md = personal tuition sessions\n  - Jake DBT Refresher = summary/refresher\n  - modules/ = group course notes (Module 1 is comprehensive)\n- [ ] Note that 'biscuit gate', 'sausage roll' etc are real family scenarios, not code names","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-03T20:46:54.942047Z","updated_at":"2026-01-03T20:46:54.942047Z"}
{"id":"skill-dbt-coaching-jj5","title":"Gather and organize DBT materials into coaching skill","description":"## Desired Outcome\nBuilt a DBT coaching skill that provides quick reminders and roleplay practice.\n\n## Source Materials\n- Apple Notes (user will paste)\n- Other DBT materials (user will point to location)\n\n## Approach\n1. Gather all materials\n2. Organize by DBT module (Mindfulness, Distress Tolerance, Emotion Regulation, Interpersonal Effectiveness)\n3. Distill key concepts into reference docs\n4. Create roleplay scenarios for practice\n\n## Acceptance Criteria\n- [ ] Core concepts documented in references/\n- [ ] At least one scenario per module in scenarios/\n- [ ] SKILL.md populated with key concepts\n- [ ] Can do a practice roleplay session","status":"open","priority":2,"issue_type":"epic","created_at":"2026-01-03T20:32:11.540516Z","updated_at":"2026-01-03T20:32:11.540516Z"}
{"id":"skill-diagramming-1je","title":"Improve diagram execution fluency through iterative practice","description":"Skill has principles now but execution still not fluent — can't reliably center, still make ragged alignments. Need iterative practice with real diagrams.\n\nCOMPLETED SO FAR:\n- Composition Check (centering calculation, orphan detection)\n- Reduced Size Check step\n- Chesterton's Fence principle\n- Respect the Metaphor (ladder rungs inside rails, etc.)\n- No Orphan Elements, Key/Legend hierarchy\n- Fill the Space with centering\n\nKEY DISCOVERIES:\n- CRAP checks element relationships, not composition placement\n- Centering: calculate (left+right)/2, don't eyeball\n- Reduced size reveals problems that hide at full size\n- Iterative loop (draw → user edits → learn) surfaces things book reading missed","design":"NEXT STEPS:\n- Genre recipes (specific compositional patterns for Venn, ladder, flow)\n- Example gallery of before/after\n- More iterative practice to build fluency\n\nRequires user teaching time — learning happens through iteration, not just reading principles.","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-30T19:51:54.648137Z","updated_at":"2025-12-30T19:51:54.648137Z"}
{"id":"skill-image-generation-3hb","title":"Build image generation skill using Google Imagen (NanoBanana)","description":"## Reference Material (To Digest)\n\n### Nano Banana Pro: 10 Tips\nURL: https://x.com/GoogleAIStudio/status/1994480371061469306\nStatus: NEEDS MANUAL RETRIEVAL (X blocks scraping)\nSource: Google AI Studio Twitter\n\nWhen retrieved, add key tips to skill references/ folder.\n\n### Other References\n- Vertex AI Imagen documentation\n- ITV brand guidelines (get from brand team)","design":"Build a skill for creating images using Google Imagen (Vertex AI). Primary use cases: presentation images, conceptual illustrations. Needs: API integration, prompt engineering guidance, ITV brand constraints.","status":"open","priority":2,"issue_type":"epic","created_at":"2025-12-30T19:46:26.935577Z","updated_at":"2025-12-30T19:46:26.935577Z"}
{"id":"skill-image-generation-dca","title":"Development Direction: External CLI Integration Patterns","description":"Patterns and architecture for building the image generation skill, extracted from analyzing\ngemini_cli_skill (https://github.com/forayconsulting/gemini_cli_skill).\n\nThis epic captures the structural patterns and best practices for integrating external\nimage generation CLIs (DALL-E, Stable Diffusion, Replicate, etc.) with Claude Code.","design":"## Source Analysis\n\nExtracted from gemini_cli_skill which demonstrates how to wrap an external CLI tool\nas a Claude Code skill. Key patterns are tool-agnostic and apply to any CLI integration.\n\n## Skill Directory Structure\n\n```\nskill-image-generation/\n├── SKILL.md              # Core skill (when-to-use, commands, error handling)\n├── templates.md          # Prompt templates by use case (product photos, diagrams, etc.)\n├── reference.md          # CLI flags, models, rate limits, pricing\n└── tools.md              # Tool-specific documentation per backend\n```\n\n## SKILL.md Structure\n\n```yaml\n---\nname: image-generation\ndescription: Generate images using external AI models. Use when user needs \n  visual assets, diagrams, concept art, or any image that benefits from AI.\nallowed-tools:\n  - Bash\n  - Read\n  - Write\n---\n```\n\n### Required Sections\n\n1. **When to Use**: Clear triggers (user asks for image, visual explanation needed)\n2. **When NOT to Use**: Text-only tasks, simple diagrams (Mermaid), screenshots\n3. **Prerequisites**: CLI installation, API key setup\n4. **Core Commands**: Generate, list models, check quota\n5. **Output Handling**: File paths, opening for review\n6. **Error Handling**: Rate limits, auth failures, content policy\n7. **Model Selection**: When to use which quality/speed tier\n\n## Core Patterns\n\n### 1. CLI Verification Before Use\n```bash\n# Always check tool exists\ncommand -v image-cli || which image-cli || {\n  echo \"Error: image-cli not installed. Run: pip install image-cli\"\n  exit 1\n}\n```\n\n### 2. Authentication via Environment Variables\n```bash\n# Never hardcode keys\nexport OPENAI_API_KEY=...      # DALL-E\nexport STABILITY_API_KEY=...   # Stable Diffusion  \nexport REPLICATE_API_TOKEN=... # Replicate\n\n# Verify auth before operations\nimage-cli auth status || echo \"Not authenticated\"\n```\n\n### 3. Command Structure\n```bash\nimage-cli generate \"\u003cprompt\u003e\" \\\n  --output /path/to/output.png \\\n  --width 1024 --height 1024 \\\n  --model dall-e-3 \\\n  2\u003e\u00261\n```\n\nKey elements:\n- Quoted prompt (protect special chars, allow multi-line)\n- Explicit output path\n- Stderr capture for error visibility\n\n### 4. Output Verification\n```bash\noutput=\"/tmp/generated-$(date +%s).png\"\nimage-cli generate \"$prompt\" --output \"$output\"\n\n# Verify success\nif [[ -f \"$output\" \u0026\u0026 -s \"$output\" ]]; then\n  file \"$output\"  # Verify it's actually an image\n  echo \"Generated: $output\"\n  open \"$output\"  # macOS: open for review\nelse\n  echo \"Failed: Empty or missing file\"\nfi\n```\n\n### 5. Generate-Review-Iterate Workflow\n```bash\n# 1. Generate initial\nimage-cli generate \"prompt\" --output /tmp/v1.png\nopen /tmp/v1.png\n\n# 2. User reviews, provides feedback\n\n# 3. Refine (preserve original prompt + add refinements)\nimage-cli generate \"original prompt + make it darker + add fog\" --output /tmp/v2.png\nopen /tmp/v2.png\n```\n\n### 6. Model Selection Strategy\n```\nIs high quality critical? (final deliverable, client-facing)\n├── Yes → Use best model (dall-e-3, sdxl)\n└── No → Is this a draft/iteration?\n    ├── Yes → Use fast model (dall-e-2, sd-turbo)\n    └── No → Use balanced model\n```\n\n### 7. Template Pattern\n```bash\n# Template: Product Photography\n# Variables: [product], [angle], [output_path]\n\nimage-cli generate \"Professional product photo of [product], \n  white background, studio lighting, [angle] view, \n  high resolution, commercial quality\" \\\n  --aspect-ratio 1:1 \\\n  --output [output_path]\n```\n\n### 8. Error Handling\n```bash\nresult=$(image-cli generate \"prompt\" -o json 2\u003e\u00261)\nexit_code=$?\n\nif [[ $exit_code -ne 0 ]]; then\n  # Check for specific errors\n  if echo \"$result\" | grep -q \"rate limit\"; then\n    echo \"Rate limited. Wait and retry, or use lower-tier model.\"\n  elif echo \"$result\" | grep -q \"content policy\"; then\n    echo \"Prompt rejected by content filter. Rephrase.\"\n  else\n    echo \"Error: $result\"\n  fi\nfi\n```\n\n## Implementation Phases\n\n### Phase 1: Single Backend (DALL-E)\n- [ ] SKILL.md with core structure\n- [ ] Basic generate command wrapper\n- [ ] Output verification and preview\n- [ ] Error handling for common failures\n- [ ] 3-5 prompt templates\n\n### Phase 2: Multi-Backend Support  \n- [ ] reference.md with backend comparison\n- [ ] Backend selection logic (quality vs speed vs cost)\n- [ ] tools.md per backend (dall-e.md, stable-diffusion.md)\n- [ ] Unified CLI abstraction layer\n\n### Phase 3: Advanced Features\n- [ ] Image-to-image variations\n- [ ] Inpainting/outpainting\n- [ ] Style presets\n- [ ] Batch generation\n\n## Success Criteria (Alpha)\n- [ ] Can generate image from text prompt\n- [ ] Output opens for user review\n- [ ] Handles rate limits gracefully\n- [ ] At least one prompt template works\n- [ ] Works with at least one backend (DALL-E or Replicate)","status":"open","priority":2,"issue_type":"epic","created_at":"2025-12-31T16:01:53.543941Z","updated_at":"2025-12-31T16:01:53.543941Z"}
{"id":"skill-todoist-gtd-2xm","title":"Critical optimisations for skill effectiveness","description":"Collection of improvements identified during real-world usage that significantly impact the skill's effectiveness. These address gaps between what the skill promises ('MCP provides tools, this skill provides meaning') and what it actually delivers in practice.","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-31T14:45:43.642441Z","updated_at":"2026-01-03T10:12:35.971188Z","closed_at":"2026-01-03T10:12:35.971188Z","close_reason":"All children complete: activation triggers (2xm.1), MCP data model (2xm.2), /open integration (2xm.3), expanded documentation via exploration (2xm.4). Skill now has clear invocation guidance and comprehensive MCP navigation patterns."}
{"id":"skill-todoist-gtd-2xm.1","title":"Add skill activation trigger guidance","description":"## Problem\n\nThe skill description says it triggers on 'clean up outcomes', 'team priorities', 'weekly review', or 'when working with Todoist data'. But in practice, Claude doesn't invoke the skill when making Todoist MCP queries - it goes straight to the MCP tools.\n\n## What happened\n\nUser asked to 'get the links from todoist Claude@Repos'. Claude:\n1. Directly called `find-tasks` with searchText='link' and 'http'\n2. Then `find-tasks-by-date` and `get-overview`\n3. Then `find-tasks` with projectId for Claude@Repos\n4. Then `fetch-object` and `find-comments` to get task details\n\nAll without ever invoking the todoist-gtd skill. User had to explicitly ask 'were you using the todoist-gtd skill?' to surface the gap.\n\n## Proposed solution\n\nThe skill description should explicitly state: **'Invoke before any Todoist MCP queries'**\n\nThis is clearer than 'when working with Todoist data' because:\n- It's action-oriented (invoke BEFORE, not during)\n- It's specific (MCP queries, not vague 'data')\n- It positions the skill as a pre-flight check, not an afterthought\n\n## Related work\n\nCompare to how /open skill uses Todoist - it likely has clearer activation patterns. Review that skill's approach and align.\n\n## Acceptance criteria\n\n- [ ] Skill description updated with explicit 'invoke before any Todoist MCP queries' trigger\n- [ ] Added to 'When to Use This Skill' section prominently\n- [ ] Reviewed /open skill's Todoist integration for patterns to adopt","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-31T14:46:02.019821Z","updated_at":"2026-01-03T09:50:31.36311Z","closed_at":"2026-01-03T09:50:31.36311Z","close_reason":"Added explicit activation triggers: INVOKE BEFORE in description, prominent warning in When to Use section explaining why (MCP lacks GTD context). Removed misleading 'simple queries use MCP directly' guidance.","dependencies":[{"issue_id":"skill-todoist-gtd-2xm.1","depends_on_id":"skill-todoist-gtd-2xm","type":"parent-child","created_at":"2025-12-31T14:46:02.025505Z","created_by":"daemon","metadata":"{}"}]}
{"id":"skill-todoist-gtd-2xm.2","title":"Document MCP data model navigation patterns","description":"## Problem\n\nThe skill focuses on GTD semantic meaning but doesn't teach Claude how to navigate the Todoist MCP's data model. This caused confusion when trying to access task attachments.\n\n## What happened\n\nA task in Claude@Repos had a forwarded GitHub Actions failure email attached. Claude:\n1. Used `find-tasks` - got basic task info but no attachment\n2. Used `fetch-object(type='task', id=...)` - still no attachment visible\n3. Only after prompting, tried `find-comments(taskId=...)` - found the attachment\\!\n\nThe attachment was on a **comment**, not the task itself. This isn't documented anywhere in the skill.\n\n## Missing knowledge\n\nThe skill should document where different metadata lives:\n\n| Data | Location | Query |\n|------|----------|-------|\n| Task title | `content` field | `find-tasks` |\n| Notes/details | `description` field | `find-tasks` or `fetch-object` |\n| **Attachments** | **Comments** | `find-comments(taskId)` |\n| Full task data | All fields | `fetch-object(type='task', id)` |\n\n## Attachment access pattern\n\n1. `find-comments(taskId)` returns comments with `fileAttachment` objects\n2. `fileAttachment` contains: fileName, fileSize, fileType, fileUrl, uploadState\n3. **Critical:** Attachment URLs require Todoist authentication - can't curl directly\n4. URLs redirect from files.todoist.com to app.todoist.com (auth wall)\n\n## Proposed addition\n\nAdd a new section '## MCP Data Model' covering:\n- Where metadata lives (task vs comments vs attachments)\n- Query patterns for getting full data\n- Attachment access workflow\n- Auth limitations on attachment URLs\n\n## Acceptance criteria\n\n- [ ] New section documenting MCP data model structure\n- [ ] Table showing where different metadata types live\n- [ ] Attachment access pattern documented\n- [ ] Note about attachment URL auth requirements\n- [ ] Example workflow for accessing forwarded emails","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-31T14:46:19.910415Z","updated_at":"2026-01-03T09:54:13.908402Z","closed_at":"2026-01-03T09:54:13.908402Z","close_reason":"Added MCP Data Model section: metadata location table (attachments live on comments), attachment access pattern with auth limitation note, forwarded emails workflow example.","dependencies":[{"issue_id":"skill-todoist-gtd-2xm.2","depends_on_id":"skill-todoist-gtd-2xm","type":"parent-child","created_at":"2025-12-31T14:46:19.914493Z","created_by":"daemon","metadata":"{}"}]}
{"id":"skill-todoist-gtd-2xm.3","title":"Review /open skill's Todoist integration patterns","description":"## Problem\n\nThe todoist-gtd skill describes session start behavior (check Claude@Work or Claude@Repos based on cwd) but this pattern may already be implemented in the /open skill. Need to understand:\n1. Does /open already handle Todoist inbox checking?\n2. If so, how does it coordinate with todoist-gtd?\n3. Are there activation patterns in /open we should adopt?\n\n## Context\n\nFrom the skill's 'Session Start Behavior' section:\n```\n1. Detect context from cwd:\n   - ~/Google Drive/... → Claude@Work\n   - ~/Repos/... or ~/.claude/... → Claude@Repos\n\n2. Query the relevant inbox:\n   find_projects()  # Find Claude@Work or Claude@Repos\n   find_tasks(projectId: '\u003cinbox-id\u003e')\n```\n\nBut /open is the skill that runs at session start. If /open already does Todoist queries, we have potential:\n- Duplication of logic\n- Unclear responsibility boundaries\n- Missed coordination opportunities\n\n## Investigation needed\n\n1. Read /open skill (session-opening) to understand its Todoist usage\n2. Identify overlaps with todoist-gtd's session start behavior\n3. Determine correct division of responsibility:\n   - /open = orchestrates session start, may call todoist-gtd\n   - todoist-gtd = semantic layer for Todoist queries\n4. Update both skills if coordination needed\n\n## Acceptance criteria\n\n- [ ] Reviewed /open skill's Todoist integration\n- [ ] Documented overlaps and gaps\n- [ ] Clarified responsibility boundaries between skills\n- [ ] Updated todoist-gtd and/or /open if needed\n- [ ] Ensured no duplicate Todoist queries at session start","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-31T14:46:38.160731Z","updated_at":"2026-01-03T09:53:28.457988Z","closed_at":"2026-01-03T09:53:28.457988Z","close_reason":"Simplified /open Todoist integration: consolidated to single @Claude inbox, removed context detection and daily gating, updated open-context.sh and skill documentation.","dependencies":[{"issue_id":"skill-todoist-gtd-2xm.3","depends_on_id":"skill-todoist-gtd-2xm","type":"parent-child","created_at":"2025-12-31T14:46:38.164913Z","created_by":"daemon","metadata":"{}"}]}
{"id":"skill-todoist-gtd-2xm.4","title":"Expand Claude inbox workflow documentation","description":"## Problem\n\nThe skill mentions Claude@Work and Claude@Repos as 'async inboxes' but doesn't fully explain the workflow or how to process items effectively.\n\n## Current state\n\nThe skill says:\n- Each project has a unique email address for forwarding\n- 'Forward email → becomes task with subject as title, body as description'\n- 'Next Claude session → item surfaces automatically'\n\nBut it doesn't explain:\n1. How the email content actually appears (in description? as attachment?)\n2. That HTML emails become attachments on comments\n3. How to extract and process that content\n4. What 'processing during session' actually looks like\n\n## What happened\n\nUser forwarded a GitHub Actions failure notification to Claude@Repos. The email:\n- Created a task with email subject as title\n- Body appeared to be in description (truncated)\n- **Full HTML was attached as a file on a comment**\n\nClaude didn't know to check comments for the full content.\n\n## Proposed improvements\n\nExpand 'Claude Inbox Patterns' section:\n\n### Email Forwarding Details\n- Subject → task content\n- Plain text body → task description (may be truncated)\n- HTML/rich content → **attached to a comment** as .html file\n- Attachments from email → also on comments\n\n### Processing Workflow\n1. `find-tasks(projectId='\u003cclaude-inbox\u003e')` - get inbox items\n2. For each task, check description AND `find-comments(taskId)`\n3. If comment has fileAttachment, that's the full content\n4. Attachment URLs require Todoist auth (can't fetch directly)\n5. User may need to open in browser or download\n\n### Completion Pattern\n- Process item → `complete-tasks(taskId)`\n- Add resolution note if needed via `add-comments`\n\n## Acceptance criteria\n\n- [ ] Expanded email forwarding section with attachment behavior\n- [ ] Added processing workflow with comment/attachment checks\n- [ ] Documented auth limitation on attachment URLs\n- [ ] Example workflow for processing a forwarded email","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-31T14:47:01.716668Z","updated_at":"2026-01-03T10:12:19.411298Z","closed_at":"2026-01-03T10:12:19.411298Z","close_reason":"Expanded MCP documentation via hands-on exploration: added subtask navigation (one-way), activity log patterns (client type, before/after), labels limitation (no discovery). Supersedes original scope.","dependencies":[{"issue_id":"skill-todoist-gtd-2xm.4","depends_on_id":"skill-todoist-gtd-2xm","type":"parent-child","created_at":"2025-12-31T14:47:01.721966Z","created_by":"daemon","metadata":"{}"}]}
{"id":"skill-todoist-gtd-79t","title":"Add Natural Planning Model section to skill","design":"Link GTD Natural Planning Model (purpose, vision, brainstorming, organizing, next actions) to the skill. Should inform how outcomes are structured and provide coaching on using NPM for project planning. Consider how it connects to beads for issue structuring.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-30T19:48:11.878496Z","updated_at":"2025-12-30T19:48:11.878496Z"}
{"id":"skill-todoist-gtd-7la","title":"Keychain pattern for API keys","description":"Use macOS Keychain instead of .env or plain dotfiles for API keys. Pattern: (1) Store: security add-generic-password -a \"$USER\" -s \"service-name\" -w \"secret\", (2) Retrieve in .zshrc: export API_KEY=\"$(security find-generic-password -a \"$USER\" -w -s \"service-name\" 2\u003e/dev/null)\". Benefits: encrypted at rest, not in version control, portable across shell configs. From Simon Willison/Codex pattern.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-03T10:38:02.298011Z","updated_at":"2026-01-03T10:38:02.298011Z"}
{"id":"skill-todoist-gtd-7v7","title":"MCP exploration as skill development pattern","description":"Hands-on API exploration produces better skill documentation than reading docs alone. Pattern: design ~7 'I wonder...' test scenarios, run them against real data, note (a) worked as expected, (b) didn't work, (c) worked surprisingly. Then distill findings into skill docs. Validated on todoist-gtd skill: discovered subtask one-way navigation, activity log capabilities, label limitation.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-03T10:38:00.49979Z","updated_at":"2026-01-03T10:38:00.49979Z"}
{"id":"sl-052","title":"Explore SpeechAnalyzer API on Tahoe","description":"macOS 26 includes new SpeechAnalyzer API (WWDC25). May be faster/better than hear+SFSpeechRecognizer. User is already on Tahoe.","status":"open","priority":3,"issue_type":"feature","created_at":"2025-12-31T18:25:37.510853Z","updated_at":"2025-12-31T18:25:37.510853Z"}
{"id":"sl-21k","title":"Add error handling to voice_ptt.py","description":"Graceful failures for: hear not installed, mic permission denied, accessibility permission missing. Currently fails ungracefully.","status":"open","priority":3,"issue_type":"chore","created_at":"2025-12-31T18:25:31.634896Z","updated_at":"2025-12-31T18:25:31.634896Z"}
{"id":"sl-34e","title":"Slash commands via voice don't work","description":"Voice input prefixes with [dictated], so '/exit' becomes '[dictated] /Exit' which isn't recognized. Options: strip [dictated] for lines starting with /, or detect and warn user.","status":"open","priority":2,"issue_type":"bug","created_at":"2025-12-31T18:29:04.943328Z","updated_at":"2025-12-31T18:29:04.943328Z"}
{"id":"sl-4h7","title":"Caps Lock hotkey option via Karabiner","description":"Document or automate Karabiner-Elements config to remap Caps Lock to F18 for PTT trigger. More ergonomic than Right Option for some.","status":"open","priority":3,"issue_type":"feature","created_at":"2025-12-31T18:20:19.245997Z","updated_at":"2025-12-31T18:20:19.245997Z"}
{"id":"sl-7zp","title":"Daemonize PTT for always-on availability","description":"Run voice_ptt.py as a background service on login. Options: launchd plist, or menubar app wrapper.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-31T18:19:57.150395Z","updated_at":"2025-12-31T18:19:57.150395Z"}
{"id":"sl-8qm","title":"Alpha Voice Integration for Claude Code","description":"Build an alpha voice integration skill for Claude Code, learning from claude-code-voice \n(https://github.com/mckaywrigley/claude-code-voice) while addressing its limitations.\n\nThe goal is hands-free voice input to Claude Code on macOS.","design":"## Reference Implementation Analysis (claude-code-voice)\n\n### Architecture\n- Microphone → pyaudio → Google Speech API → Stop hook → command injection\n- State managed via temp file (`/tmp/claude_voice_mode.txt`)\n- Activated by typing \"start voice\", deactivated by \"stop voice\"\n\n### Clever Design Choices\n1. **Stop hook as trigger**: After Claude responds, the Stop hook fires and blocks to listen for voice. This creates natural turn-taking.\n2. **Reason field injection**: Transcribed text goes into the hook's `reason` field, which Claude sees as input.\n3. **Continuous loop**: After each Claude response, immediately starts listening again.\n\n### Weaknesses to Address\n1. **Requires internet**: Google Speech API has no offline fallback\n2. **~3-4s latency**: 1s ambient calibration + 2s pause threshold + 500ms-2s API\n3. **Can't interrupt**: Must wait for Claude to finish responding\n4. **Temp file race conditions**: Non-atomic state management\n5. **No wake word**: False triggers if mic catches ambient speech\n6. **Bare except clauses**: Swallows SystemExit/KeyboardInterrupt\n7. **Hardcoded config**: No way to adjust thresholds\n\n## Alternative Design: Local-First with Whisper\n\n### Core Changes\n1. **Local STT via faster-whisper**: No network dependency, better privacy\n   - `base` model: ~1s on M1/M2, good accuracy\n   - `small` model: ~2s, better accuracy for complex speech\n   - Fallback to Google if Whisper unavailable\n\n2. **Wake word option**: Picovoice Porcupine or Snowboy\n   - Custom wake word \"Hey Claude\" or \"Computer\"\n   - Prevents accidental triggers in noisy environments\n   - Optional: can be disabled for quiet environments\n\n3. **Robust state management**: \n   - Unix domain socket for IPC, OR\n   - JSON state file with file locking (`fcntl.flock`)\n   - Clean state on crash recovery\n\n4. **Configuration file**: `~/.claude/voice-config.yaml`\n   ```yaml\n   stt_backend: whisper  # or google\n   whisper_model: base\n   pause_threshold: 2.0\n   energy_threshold: 500\n   wake_word_enabled: false\n   wake_word: \"hey claude\"\n   ```\n\n### Architecture\n\n```\n┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐\n│  Microphone     │───▶│  Audio Buffer    │───▶│  VAD / Whisper  │\n│  (pyaudio)      │    │  (SpeechRecog)   │    │  (local)        │\n└─────────────────┘    └──────────────────┘    └────────┬────────┘\n                                                        │\n                                                        ▼\n┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐\n│  Claude Code    │◀───│  Stop Hook       │◀───│  Transcription  │\n│  (processes)    │    │  (blocks+injects)│    │  Text           │\n└─────────────────┘    └──────────────────┘    └─────────────────┘\n```\n\n### Hook Structure\n\n```\n.claude/hooks/\n├── Stop/\n│   └── voice-listener.py      # Main listener, activates after Claude response\n└── UserPromptSubmit/\n    └── voice-commands.py      # Handles \"start voice\", \"stop voice\" typed commands\n```\n\n## Implementation Phases\n\n### Phase 1: Core Hook Structure (Alpha)\n- [ ] Basic Stop hook that listens and injects\n- [ ] UserPromptSubmit hook for mode toggle\n- [ ] Local Whisper STT (base model)\n- [ ] JSON state file with locking\n- [ ] Basic error handling and logging\n\n### Phase 2: Configuration \u0026 Reliability\n- [ ] Config file support (~/.claude/voice-config.yaml)\n- [ ] Configurable thresholds (pause, energy)\n- [ ] STT backend selection (whisper/google)\n- [ ] Whisper model selection\n- [ ] Crash recovery / state cleanup\n\n### Phase 3: Wake Word (Optional)\n- [ ] Picovoice Porcupine integration\n- [ ] Custom wake word training\n- [ ] Always-on mode with wake word gate\n\n### Phase 4: Polish\n- [ ] Streaming partial transcription display\n- [ ] Audio feedback (beep on listen start/end)\n- [ ] Microphone selection\n- [ ] Tests\n\n## Dependencies\n\n```\n# Core\nSpeechRecognition\u003e=3.10.0\npyaudio\u003e=0.2.11\nfaster-whisper\u003e=0.9.0  # Local STT\n\n# Optional\npvporcupine\u003e=2.0  # Wake word (requires API key)\n```\n\n## Platform Requirements\n- macOS (primary target, uses AVFoundation permissions)\n- Python 3.10+\n- PortAudio (`brew install portaudio`)\n- Microphone access permission granted\n\n## Key Files to Create\n\n1. `SKILL.md` - Skill definition with triggers and usage\n2. `.claude/hooks/Stop/voice-listener.py` - Main listener\n3. `.claude/hooks/UserPromptSubmit/voice-commands.py` - Mode toggle\n4. `requirements.txt` - Dependencies\n5. `voice_config.py` - Config loading/defaults\n6. `whisper_stt.py` - Local STT wrapper\n\n## Success Criteria (Alpha)\n- [ ] Can type \"start voice\" to activate listening\n- [ ] Voice is transcribed locally via Whisper\n- [ ] Transcribed text appears as Claude input\n- [ ] Can say \"stop voice\" to deactivate\n- [ ] Works offline (no network required)\n- [ ] Latency \u003c3s from end of speech to command submission\n- [ ] No race conditions in state management","notes":"Alpha complete: PTT voice input working with Apple native speech recognition via hear CLI. Right Option key to speak, auto-submits to Claude. Known limitation: 'new line' command breaks parsing.","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-31T16:01:46.34345Z","updated_at":"2025-12-31T18:15:32.400062Z","closed_at":"2025-12-31T18:15:32.400066Z"}
{"id":"sl-g7p","title":"Investigate 'new line' command breaking transcription","description":"Apple dictation command 'new line' causes hear output to fragment. Either find workaround or document as known limitation.","status":"open","priority":3,"issue_type":"bug","created_at":"2025-12-31T18:20:25.281927Z","updated_at":"2025-12-31T18:20:25.281927Z"}
{"id":"sl-r5o","title":"Package as Claude Code skill with /listen toggle","description":"Create SKILL.md, integrate with Claude Code hooks. /listen to start/stop the daemon. Status indicator in terminal or menubar.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-31T18:20:13.338445Z","updated_at":"2025-12-31T18:20:13.338445Z"}
{"id":"sl-xnh","title":"Menubar app wrapper with status indicator","description":"Visual feedback: icon shows recording state. Alternative to terminal daemon. Could use rumps or native Swift.","status":"open","priority":3,"issue_type":"feature","created_at":"2025-12-31T18:25:43.483436Z","updated_at":"2025-12-31T18:25:43.483436Z"}
{"id":"spm1001.github.io-q9n","title":"Set up email for blog","design":"Kit newsletter form partially working. Redirect works, but form submission not reaching Kit. Next: debug form POST or use Kit's full embed with CSS override.","notes":"Newsletter working: plain HTML POST form (ad-blocker friendly), domain verified in Kit with CNAME records for SPF/DKIM.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-14T19:29:37.645474Z","updated_at":"2025-12-19T22:47:21.492744Z","closed_at":"2025-12-19T22:47:21.492748Z"}
{"id":"ssm-0e2","title":"Handoffs enable continuity","description":"The handoff artifact persists between sessions. Structured format, traceable to beads, indexed for search. Next Claude starts with full context.","acceptance_criteria":"- [ ] Handoffs include structured fields for machine queries (what_worked, patterns)\n- [ ] Bead IDs appear in Done section for traceability\n- [ ] Handoffs and beads indexed for memory search at /close","status":"open","priority":2,"issue_type":"epic","created_at":"2026-01-03T15:11:49.311683Z","updated_at":"2026-01-03T15:30:36.149718Z"}
{"id":"ssm-0qu","title":"Add /ground command alias or trigger","description":"session-grounding skill exists but no command/alias to invoke it. Need to add trigger like /open and /close have.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-30T18:32:05.856501Z","updated_at":"2025-12-30T18:47:04.17654Z","closed_at":"2025-12-30T18:47:04.17654Z","close_reason":"Created ~/.claude/commands/ground.md to invoke session-grounding skill"}
{"id":"ssm-0yc","title":"Reduce git distraction in /open","description":"Only surface uncommitted files if actually concerning; ignore .handoff, plan debris, normal session artifacts.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T09:51:11.214402Z","updated_at":"2026-01-03T16:20:14.263425Z","closed_at":"2026-01-03T16:20:14.263425Z","close_reason":"Closed in batch - deprioritized"}
{"id":"ssm-17r","title":"Investigate PreCompact hook for checkpoint-before-compaction","description":"PreCompact hook exists in Claude Code. Could use it to update beads notes before context is lost. Discussed but not decided.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T18:01:01.60757Z","updated_at":"2026-01-03T15:40:41.275783Z","closed_at":"2026-01-03T15:40:41.275783Z","close_reason":"Closed in batch - deprioritized","dependencies":[{"issue_id":"ssm-17r","depends_on_id":"ssm-da5","type":"parent-child","created_at":"2026-01-03T15:12:04.063462Z","created_by":"modha","metadata":"{}"}]}
{"id":"ssm-267","title":"Add structured learnings to handoff format","description":"Handoff format captures learnings in prose (Reflection section) but lacks structured fields for aggregation. Auto-Claude's session_insights.json has explicit what_worked/what_failed/patterns_found fields that enable machine queries and cross-session synthesis.","design":"## Source\nAuto-Claude repo analysis (2026-01-02): https://github.com/AndyMik90/Auto-Claude\n\n## Current State\nHandoff template has:\n- Done (list) ✓\n- Gotchas (list) ✓\n- Risks (list) ✓\n- Next (list) ✓\n- Commands (code block) ✓\n- Reflection (prose: Claude observed / User said) — learnings buried here\n\n## Proposed Addition\nAdd structured Learnings section before prose Reflection:\n\n```markdown\n## Learnings\n\n### What Worked\n- [explicit successes — approaches that succeeded]\n\n### What Didn't Work\n- [explicit failures — approaches that failed or were abandoned]\n\n### Patterns Discovered\n- [reusable approaches worth remembering]\n\n## Reflection\n**Claude observed:** [prose synthesis]\n**User said:** [response]\n```\n\n## Implementation Options\n\n### Option A: Always prompt (heavier)\nAdd to /close Phase 2 (Orient) AskUserQuestion:\n```\n{\n  header: \"Learnings\",\n  question: \"Which learning categories should I capture?\",\n  multiSelect: true,\n  options: [\n    { label: \"What worked\", description: \"Approaches that succeeded\" },\n    { label: \"What didn't work\", description: \"Approaches that failed\" },\n    { label: \"Patterns discovered\", description: \"Reusable approaches\" },\n    { label: \"Skip structured\", description: \"Prose reflection only\" }\n  ]\n}\n```\n\n### Option B: Selective prompt (lighter)\nOnly prompt for structured learnings when:\n- Session had significant trial-and-error\n- User explicitly asks for retrospective\n- Context is running low (learnings at risk)\n\nOtherwise, continue with prose-only Reflection.\n\n### Option C: Template change only (lightest)\nJust update the handoff template in SKILL.md. Claude will see the sections and populate if relevant. No new prompts.\n\n## Trade-offs\n- Option A: Most complete, but adds friction to every /close\n- Option B: Adaptive, but adds complexity to skill logic\n- Option C: Simplest, relies on Claude noticing template sections\n\n## Recommendation\nStart with Option C (template change). Monitor whether Claude naturally populates. Escalate to Option B if learnings are frequently skipped.\n\n## Related\n- Codebase map concept (separate bead) — files_understood accumulation\n- Auto-Claude also has session_number for sequencing — not needed for our approach (timestamps suffice)","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-02T20:27:24.641902Z","updated_at":"2026-01-02T20:27:24.641902Z","dependencies":[{"issue_id":"ssm-267","depends_on_id":"ssm-0e2","type":"parent-child","created_at":"2026-01-03T15:12:06.001695Z","created_by":"modha","metadata":"{}"}]}
{"id":"ssm-2fd","title":"Reorganize handoffs to match Claude Code session folder structure","description":"Handoffs should use the same folder organization as Claude Code sessions for consistent project_path matching.","design":"## Problem\n\nCurrently handoffs are stored flat in ~/.claude/handoffs/ with project name embedded in filename:\n```\n~/.claude/handoffs/\n├── claude-memory-2025-12-27-1943.md\n├── skill-session-management-2025-12-29.md\n└── ...\n```\n\nThis requires fuzzy title matching to associate handoffs with projects in mem queries, which is fragile (e.g., \"claude-memory\" vs \"memory\" extraction bugs).\n\n## Solution\n\nFollow Claude Code's session folder structure exactly:\n```\n~/.claude/projects/                    # Sessions (existing)\n├── -Users-modha-Repos-claude-memory/\n│   └── abc123.jsonl\n└── ...\n\n~/.claude/handoffs/                    # Handoffs (new structure)\n├── -Users-modha-Repos-claude-memory/\n│   └── 2025-12-29-1425.md\n└── ...\n```\n\nThe folder name IS the project_path — same format, no conversion needed.\n\n## Why This Is Right\n\n1. **project_path is identical** — `-Users-modha-Repos-claude-memory` used for both\n2. **Trivial to match** — `WHERE project_path = ?` works for sessions AND handoffs\n3. **No parsing needed** — folder name encodes project, no metadata extraction\n4. **Consistent mental model** — projects/ and handoffs/ mirror each other\n5. **Easy manual browsing** — `ls ~/.claude/handoffs/-Users-modha-Repos-claude-memory/`\n\n## Changes Required\n\n### 1. /close ritual (session-closing/SKILL.md or close-context.sh)\n\nCurrently writes to:\n```bash\n~/.claude/handoffs/${project_name}-${timestamp}.md\n```\n\nChange to:\n```bash\n# Get project_path in Claude Code format\nPROJECT_PATH=$(pwd | sed 's|/|-|g' | sed 's|^-||')\nHANDOFF_DIR=\"$HOME/.claude/handoffs/${PROJECT_PATH}\"\nmkdir -p \"$HANDOFF_DIR\"\n# Write handoff\necho \"$HANDOFF_CONTENT\" \u003e \"$HANDOFF_DIR/${timestamp}.md\"\n```\n\n### 2. Handoffs adapter (claude-memory/src/mem/adapters/handoffs.py)\n\nCurrently globs:\n```python\n~/.claude/handoffs/*.md\n```\n\nChange to:\n```python\n~/.claude/handoffs/**/*.md  # Recursive glob\n```\n\nAnd extract project_path from parent folder:\n```python\n# path = ~/.claude/handoffs/-Users-modha-Repos-foo/2025-12-29.md\nproject_path = path.parent.name  # \"-Users-modha-Repos-foo\"\n```\n\n### 3. Database schema\n\nAdd project_path to handoff sources (already nullable in sources table, just populate it).\n\n### 4. mem recent query\n\nSimplify from fuzzy title matching:\n```sql\n-- OLD (fragile)\nAND (s.project_path LIKE ? OR (s.source_type = 'handoff' AND s.title LIKE ?))\n\n-- NEW (clean)\nAND s.project_path LIKE ?\n```\n\n## Migration\n\nExisting handoffs can stay flat (backwards compatible) or be migrated:\n```bash\n# Optional migration script\nfor f in ~/.claude/handoffs/*.md; do\n    # Extract project name from filename, convert to project_path\n    # Move to appropriate subfolder\ndone\n```\n\nNot critical — new handoffs will use new structure, old ones still discoverable.\n\n## Acceptance Criteria\n\n- [ ] /close writes handoffs to ~/.claude/handoffs/{project_path}/{timestamp}.md\n- [ ] project_path format matches Claude Code exactly (e.g., -Users-modha-Repos-foo)\n- [ ] Handoffs adapter discovers files in subdirectories\n- [ ] Handoffs adapter populates project_path field in database\n- [ ] `mem recent` finds handoffs without fuzzy title matching\n- [ ] Old flat handoffs still discoverable (backwards compatible)\n\n## Cross-Project Coordination\n\nThis spans two repos:\n- **skill-session-management**: /close writes the files (this bead)\n- **claude-memory**: Adapter reads the files (separate bead)\n\nFile the claude-memory bead as child/dependency after this one.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-29T15:27:35.915419Z","updated_at":"2025-12-29T23:14:59.81745Z","closed_at":"2025-12-29T23:14:59.81745Z","close_reason":"Handoff storage consolidated to ~/.claude/handoffs/-{path}/. Migrated 73 handoffs. claude-memory adapter works with new structure."}
{"id":"ssm-2zb","title":"Speed optimization: parallelize /open script calls","description":"open-context.sh runs sequentially. Could parallelize: TIME, GIT, BEADS, TODOIST are independent. May reduce /open latency.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-31T13:21:01.052005Z","updated_at":"2025-12-31T13:21:01.052005Z"}
{"id":"ssm-38j","title":"Warn at /close if unread handoff exists","description":"If .handoff exists when /close runs, and /open wasn't invoked this session, warn user: 'Found unread handoff from previous session. Proceed anyway?' Prevents silent loss of learning loop context.","design":"## Approach\nDetect in close-context.sh or Phase 1 of /close:\n1. Check if .handoff exists\n2. Check if /open was run this session (need a marker - .open-ran or env var?)\n3. If handoff exists but /open didn't run, surface warning\n\n## Challenge\nHow to know if /open ran? Options:\n- Write .open-ran marker file, /close checks and cleans up\n- Environment variable (won't survive across tool calls reliably)\n- Check conversation for /open invocation (fragile)\n\nMarker file is simplest: /open writes ~/.claude/.open-ran-{project-hash}, /close checks for it.\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Add marker write to open-context.sh\n3. Add marker check to close-context.sh\n4. Surface warning in /close Phase 1\n5. Clean up marker at /close end","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T14:32:07.572246Z","updated_at":"2026-01-03T15:44:42.670906Z","closed_at":"2026-01-03T15:44:42.670906Z","close_reason":"Closed in batch - deprioritized","dependencies":[{"issue_id":"ssm-38j","depends_on_id":"ssm-da5","type":"parent-child","created_at":"2026-01-03T15:12:04.138504Z","created_by":"modha","metadata":"{}"}]}
{"id":"ssm-3kw","title":"Handoff encoding migration/fallback","description":"Changed encoding from tr '/' to tr '/.' to match Anthropic. Existing handoffs with dots in path (e.g., .claude) use old encoding. Migrated manually for .claude; may need fallback logic or one-time migration script for other dotted paths.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-31T13:21:02.504656Z","updated_at":"2025-12-31T13:21:02.504656Z"}
{"id":"ssm-4f3","title":"Bidirectional spec/plan ↔ beads linking","description":"If plan file exists (spec.md, .claude/plans/*.md), reference it and show where ready beads fit in the larger plan.","design":"## Concept\nBidirectional linking between specs/plans and beads:\n- Specs reference beads (inline markers track implementation chunks)\n- Beads reference specs (design field links to deeper context)\n\n## Spec → Beads\n- Detect plan files in conventional locations (~/.claude/plans/*.md, spec.md, SPEC.md in project)\n- Parse for bead references (convention: `[prefix-xxx]` or `bead:prefix-xxx`)\n- During /open, show spec status: \"auth-spec.md: 3 beads (1 closed, 1 in_progress, 1 open)\"\n- Clickable/actionable: \"Show spec with bead status?\"\n\n## Beads → Spec\n- Convention: design field starts with `Spec: path/to/spec.md` (relative or absolute)\n- `bd show` could surface the spec link prominently\n- Future: `bd create --spec path/to/spec.md` to auto-link\n\n## /open Integration\n1. Check for spec files in known locations\n2. Parse for bead references\n3. Cross-reference with `bd list` to get status\n4. Present summary: which specs exist, bead coverage, status breakdown\n\n## Workflow\n1. DRAW-DOWN: Create TodoWrite items from acceptance criteria\n2. Start with spec detection in open-context.sh\n3. Add bead reference parsing\n4. Update /open SKILL.md to surface spec status\n5. Document convention for beads → spec linking","acceptance_criteria":"- [ ] open-context.sh detects spec files in ~/.claude/plans/ and project root\n- [ ] Bead references in specs are parsed (e.g., [ssm-xyz] pattern)\n- [ ] /open shows spec summary with bead status breakdown\n- [ ] Convention documented for linking beads to specs (design field)\n- [ ] bd show displays spec link when present in design field","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T09:51:11.117094Z","updated_at":"2026-01-03T16:12:06.425984Z","closed_at":"2026-01-03T16:12:06.425984Z"}
{"id":"ssm-4k0","title":"Clear TodoWrite at end of /close ritual","description":"TodoWrite items persist visually after /close completes. Should clear them down after:\n1. User has selected which items to file as beads\n2. Beads are created\n3. Then: clear TodoWrite with empty array\n\nExplain to Claude in skill that clearing is OK because:\n- Items were either saved as beads (if user selected them)\n- Or user was given the option and declined\n- No context lost, just cosmetic cleanup\n\nExample from field: /close ends with visible todos (some checked, some not) even though session is complete.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-31T12:36:22.849899Z","updated_at":"2025-12-31T12:42:29.790326Z","closed_at":"2025-12-31T12:42:29.790326Z","close_reason":"Added step 4f to clear TodoWrite with empty array before exit. Explained why it's safe (beads captured, user given option, stale todos confuse next session)."}
{"id":"ssm-524","title":"Reflection captures what matters","description":"The /close reflection dialogue extracts learning while context is rich. Open-ended questions, not checklists. Energy that invites insight, not data collection.","acceptance_criteria":"- [ ] Reflection questions invite genuine insight, not checkbox completion\n- [ ] User selections feel like real asks, not template-following\n- [ ] Claude's observations are open (\"what resonates?\") not closed (\"pick from list\")","status":"closed","priority":2,"issue_type":"epic","created_at":"2026-01-03T15:11:48.400799Z","updated_at":"2026-01-03T15:55:23.167791Z","closed_at":"2026-01-03T15:55:23.167791Z"}
{"id":"ssm-5fk","title":"Surface actionable commands from updates","description":"When updates surface things like 'bd upgrade review', tell user to run them or offer to run them. Currently update news can include actionable items that get lost.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T09:51:41.56365Z","updated_at":"2026-01-03T15:20:23.99527Z","closed_at":"2026-01-03T15:20:23.99527Z","close_reason":"Closed in batch - deprioritized"}
{"id":"ssm-6uh","title":"Cross-project Claude coordination via --prefix","description":"When Claude A needs to write a bead to Claude B's project, the naive approach (cd to other repo) fails: Claude forgets to cd back and reads wrong beads. Use bd --prefix flag instead to write to other project's beads without changing working directory.","design":"## The Problem\nClaude A in ~/Repos/project-a wants to notify Claude B (project-b) of something.\nNaive: cd ~/Repos/project-b \u0026\u0026 bd create \"message\"\nFailure: Forgets to cd back, subsequent bd reads wrong database.\n\n## Solution: --prefix flag (bd v0.39.0+)\nbd create \"message for project-b\" --prefix proj-b\n\nThis writes to project-b's database without changing cwd. No cd, no forgetting to return.\n\n## Requirements\n- Know target project's bead prefix\n- Target project must have .beads/ initialized\n\n## Pattern for Inter-Claude Messages\nWhen running parallel Claudes and need coordination:\n1. Identify target project's prefix\n2. Use: bd create \"For Claude B: \u003cmessage\u003e\" --prefix \u003ctarget-prefix\u003e --type task\n3. Target Claude picks it up on next bd ready\n\n## Alternative: Subshell\n(cd ~/Repos/project-b \u0026\u0026 bd create \"message\")\nThe parentheses scope the cd, auto-returns. Works but more verbose.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T14:49:20.317937Z","updated_at":"2026-01-03T15:17:33.990878Z","closed_at":"2026-01-03T15:17:33.990878Z","close_reason":"Closed in batch - deprioritized"}
{"id":"ssm-6x1","title":"Add phase counter to /close output","description":"Add 'Phase N of Q' to output for situational awareness during /close ritual.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-29T09:51:20.257088Z","updated_at":"2025-12-29T09:51:20.257088Z","close_reason":"Closed in batch - deprioritized"}
{"id":"ssm-7lb","title":"Improve reflection energy in /close","description":"Reframe Claude's observations as 'what resonates / what am I missing?' not 'pick from this list'. Reduce closed-list energy that feels like data collection.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T09:51:20.349702Z","updated_at":"2026-01-03T15:51:59.115149Z","closed_at":"2026-01-03T15:51:59.115149Z","close_reason":"Closed in batch - deprioritized","dependencies":[{"issue_id":"ssm-7lb","depends_on_id":"ssm-524","type":"parent-child","created_at":"2026-01-03T15:12:04.953376Z","created_by":"modha","metadata":"{}"}]}
{"id":"ssm-7v2","title":"Verify /ground gate consistency with /open","description":"Check that /ground's gate pattern (line 50-54 in SKILL.md) is consistent with /open's new gate pattern. Both should load beads skill when .beads/ exists.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-03T20:26:16.457327Z","updated_at":"2026-01-03T20:26:16.457327Z"}
{"id":"ssm-8e0","title":"/close checkpoint implementation","description":"Implement .close-checkpoint file that survives /compact. Allows interrupted /close to resume.","design":"## Approach\n\nWrite checkpoint at each /close phase to ~/.claude/.close-checkpoint:\n\n```yaml\nphase: \"4c\"\nhandoff_path: \"/path/to/handoff.md\"\nhandoff_written: true\ngit_committed: false\ntodos_cleared: false\nsession_id: \"xxx\"\ntimestamp: \"2026-01-03T10:30:00Z\"\n```\n\n## Workflow\n1. Add checkpoint writes to session-closing/SKILL.md at each phase\n2. Update session-start.sh to detect and warn about checkpoint (already done)\n3. Add /close --resume handling\n4. Delete checkpoint on successful close completion\n\n## Acceptance Criteria\n- [ ] Checkpoint file written at each /close phase\n- [ ] session-start hook detects and warns (done)\n- [ ] /close --resume picks up from checkpoint\n- [ ] Checkpoint deleted on clean close","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-03T11:07:30.389047Z","updated_at":"2026-01-03T15:40:41.238842Z","closed_at":"2026-01-03T15:40:41.238842Z","dependencies":[{"issue_id":"ssm-8e0","depends_on_id":"ssm-da5","type":"parent-child","created_at":"2026-01-03T15:12:04.024861Z","created_by":"modha","metadata":"{}"}]}
{"id":"ssm-9dn","title":"Capture AskUserQuestion theatre insight in CLAUDE.md","description":"User selections via AskUserQuestion feel different to Claude than template text. Creates genuine engagement vs mechanical execution. Worth capturing as durable learning.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-30T18:32:15.721833Z","updated_at":"2025-12-30T18:47:57.900931Z","closed_at":"2025-12-30T18:47:57.900931Z","close_reason":"Added theatre insight to ~/.claude/CLAUDE.md under Structured Questions section"}
{"id":"ssm-9ss","title":"Heavy updates optimization (parallelization)","description":"Parallelize update-all.sh operations to reduce first-session latency.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-03T11:07:46.85651Z","updated_at":"2026-01-03T11:07:46.85651Z"}
{"id":"ssm-9u2","title":"Session rituals reliably load beads context","description":"Deterministic scripts + explicit Skill(beads) invocation, not semantic matching.","design":"## Vision\nWhen /open runs, beads context is always available:\n- open-context.sh calls bd ready, bd list --status in_progress\n- GATE_REQUIRED=true triggers explicit Skill(beads) invocation\n- Draw-down pattern reliably triggers\n\n## Next Actions\n1. Add bd calls to open-context.sh\n2. Add explicit Skill(beads) invocation when GATE_REQUIRED=true\n3. Optional: Add bd blocked check for strategic context\n4. Optional: Add means-ends alignment gate at /close\n\n## Origin\nMoved from skill-beads repo — work lives where it happens.","status":"closed","priority":1,"issue_type":"epic","created_at":"2026-01-01T23:08:50.618144Z","updated_at":"2026-01-03T15:25:02.039575Z","closed_at":"2026-01-03T15:25:02.039575Z"}
{"id":"ssm-9zy","title":"/close consistency review","description":"Review /close skill for patterns inconsistent with hook-based architecture (GATE_REQUIRED, etc).","design":"## Approach\n\nRead through session-closing/SKILL.md and check for:\n- GATE_REQUIRED references (removed from /open)\n- Assumptions about /open having run\n- Any skill-loading gates that don't make sense with hooked context\n\n## Acceptance Criteria\n- [ ] /close SKILL.md reviewed for hook-architecture consistency\n- [ ] Any outdated patterns updated\n- [ ] GODAR table still accurate","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-03T11:07:31.805794Z","updated_at":"2026-01-03T15:44:42.633972Z","closed_at":"2026-01-03T15:44:42.633972Z","dependencies":[{"issue_id":"ssm-9zy","depends_on_id":"ssm-da5","type":"parent-child","created_at":"2026-01-03T15:12:04.100758Z","created_by":"modha","metadata":"{}"}]}
{"id":"ssm-apj","title":"Observe two-block reflection structure in /close","design":"Track whether the Looking Back / Looking Ahead split adds value or just ceremony. Watch for: paraphrasing of 'All of these', whether users engage both blocks, quality of reflections produced.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-30T10:01:50.883947Z","updated_at":"2025-12-30T10:01:50.883947Z","close_reason":"Observation complete: two-block structure works. Users typically select 'All of these' but the theatre of making it user input matters — Claude treats selected questions as genuine asks rather than template-following. The ceremony creates authenticity."}
{"id":"ssm-b7l","title":"Include bead IDs in handoff Done section","description":"Handoff Done section lists completions but not which beads were closed.\n\nCurrent:\n## Done\n- Fixed RF optimization\n- Closed 4 RF beads\n\nBetter:\n## Done\n- Fixed RF optimization (closed infra-openwrt-jm2, -gxw, -020, -1g8)\n\nThis enables traceability: next session can bd show those beads for context.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-31T13:14:58.385158Z","updated_at":"2025-12-31T13:14:58.385158Z","dependencies":[{"issue_id":"ssm-b7l","depends_on_id":"ssm-0e2","type":"parent-child","created_at":"2026-01-03T15:12:06.039659Z","created_by":"modha","metadata":"{}"}]}
{"id":"ssm-bb2","title":"Clean up SKILL backup files","description":"SKILL-v1-backup.md and SKILL-v2-backup.md files in session-closing/ and session-opening/. Housekeeping - can delete or archive.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-30T18:32:23.241539Z","updated_at":"2025-12-30T18:48:10.823092Z","closed_at":"2025-12-30T18:48:10.823092Z","close_reason":"Deleted session-closing/SKILL-v2-backup.md and session-opening/SKILL-v2-backup.md"}
{"id":"ssm-br4","title":"Consolidate session-start hook into this repo","description":"Move session-start.sh from ~/.claude/hooks/ to this repo and symlink back. Keeps related stuff together.","design":"## Approach\n\nCurrently:\n- ~/.claude/hooks/session-start.sh (in claude-config repo)\n- ~/Repos/skill-session-management/scripts/open-context.sh (in this repo)\n\nThe hook calls the script across repo boundaries. Consolidate:\n1. Move session-start.sh to this repo's scripts/ directory\n2. Symlink ~/.claude/hooks/session-start.sh -\u003e here\n3. Update any references\n\n## Acceptance Criteria\n- [ ] session-start.sh lives in this repo\n- [ ] Symlink from ~/.claude/hooks/ works\n- [ ] Hook still fires correctly on session start\n- [ ] README/ARCHITECTURE updated to reflect","notes":"Moved session-start.sh to this repo, symlinked from ~/.claude/hooks/. Tested script runs correctly. Real test on next session start.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-03T11:07:32.93804Z","updated_at":"2026-01-03T15:04:01.021937Z","closed_at":"2026-01-03T15:04:01.021939Z"}
{"id":"ssm-bz4","title":"Fresh-eyes refactor of /open and /close skills","description":"Skills have sprawled through incremental changes. A fresh Claude should read both end-to-end and propose cleaner structure. Key insight: Claude paraphrases templates rather than following exactly — simpler skills = less interpretation drift.","design":"Give new Claude both skills with brief: 'These are paired rituals for session start/end. They've sprawled. Strip to essentials, propose cleaner structure.'","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-29T22:58:58.893449Z","updated_at":"2025-12-30T18:31:50.781738Z","closed_at":"2025-12-30T18:31:50.781738Z","close_reason":"Fresh-eyes refactor complete. Unified /open, /close, /ground around GODA structure (Gather→Orient→Decide→Act). Added two-bucket Decide (Now/Later). Created extraction script. Fixed AskUserQuestion theatre insight. ~50% size reduction in /close."}
{"id":"ssm-d9z","title":"Add session extraction at /close start","description":"Integrate hybrid extraction into the /close ritual so sessions get indexed automatically. Fire extraction early in sequence so it runs in parallel with wrap-up dialogue.","design":"## Goal\nTrigger extraction at the START of /close so it runs in parallel with wrap-up dialogue.\n\n## Approach — NOW IMPLEMENTED\n\n**Phase 0: Index only (background, immediate)**\n```bash\ncd ~/Repos/claude-memory \u0026\u0026 uv run mem process \u003csession.jsonl\u003e --no-hybrid --no-extract --quiet \u0026\n```\n\n**Phase 1: In-context extraction (Claude Code does the LLM work)**\n```bash\n# Get the prompt with session content\nPROMPT=$(cd ~/Repos/claude-memory \u0026\u0026 uv run mem extract-prompt claude_code:\u003csession-id\u003e)\n\n# Claude processes prompt inline, generates extraction JSON\n# Then store the results:\necho '\u003cextraction-json\u003e' | cd ~/Repos/claude-memory \u0026\u0026 uv run mem store-extraction claude_code:\u003csession-id\u003e\n```\n\n**Session file location:** \n`~/.claude/projects/{project-path}/{session-id}.jsonl`\n- Project path derived from cwd (e.g., `-Users-modha-Repos-foo`)\n- Session ID is a UUID (still need to figure out how to get current session ID)\n\n**What extraction produces:**\n- summary (2-3 sentences)\n- arc (started_with, key_turns, ended_at)\n- builds (things created/modified)\n- learnings (insight, why_it_matters, context)\n- friction (problems encountered)\n- patterns (session-level observations)\n- open_threads (unfinished business)\n\n## Open question: Session ID discovery\nNeed to find current session ID. Options:\n1. Check for env var: `$CLAUDE_SESSION_ID` or similar\n2. Fallback: most recently modified .jsonl in project directory\n\n## Constraints\n- Extraction must not block the /close flow\n- Use nohup/disown for background tasks\n- Graceful failure if extraction unavailable","acceptance_criteria":"- [ ] Extraction fires at start of /close sequence (before wrap-up dialogue)\n- [ ] Runs in background (nohup/disown) — doesn't block /close\n- [ ] Uses Max subscription (Claude Code session) not pay-as-you-go API\n- [ ] Graceful failure if extraction unavailable (skill continues)\n- [ ] Test: run /close, verify extraction appears in mem search\n- [ ] Optional: Handoff includes session UUID for traceability","notes":"SESSION: 2025-12-29\n\nCOMPLETED:\n- Phase 0 updated with new extraction flow:\n  - Step 0a: Index with `mem process --no-hybrid --no-extract` (background bash)\n  - Step 0b: Spawn Task agent to generate extraction using Max subscription\n- Session detection heuristic works (most recent non-agent .jsonl)\n- SESSION_ID captured and included in handoff format\n- Full flow tested and verified:\n  - `mem extract-prompt` outputs prompt with session content + format instructions\n  - `mem store-extraction` accepts JSON, stores in DB, shows in `mem drill`\n\nVERIFIED:\n- Indexing: ✅ works\n- Extract prompt: ✅ outputs correct format\n- Store extraction: ✅ saves to DB\n- Drill shows extraction: ✅ confirmed\n\nREMAINING:\n- Acceptance test: run actual /close, verify extraction agent completes","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-29T09:45:51.601904Z","updated_at":"2025-12-29T11:55:10.473581Z","closed_at":"2025-12-29T11:55:10.473581Z","close_reason":"Implemented session extraction at /close start:\n- Phase 0 added: index + spawn extraction agent in background\n- Session ID detection via most-recently-modified heuristic\n- In-context extraction (Max subscription, not API)\n- Acceptance test passed: full pipeline verified (index → prompt → store → drill)"}
{"id":"ssm-da5","title":"/close is resilient and complete","description":"Make /close robust against interruption, context loss, and incomplete runs. Survive compaction, checkpoint progress, resume if interrupted.","acceptance_criteria":"- [ ] /close survives context exhaustion (checkpoint written before compaction)\n- [ ] Interrupted /close can be resumed next session\n- [ ] No silent failures — user warned if /close incomplete","status":"closed","priority":2,"issue_type":"epic","created_at":"2026-01-03T15:11:37.447746Z","updated_at":"2026-01-03T15:44:42.707367Z","closed_at":"2026-01-03T15:44:42.707367Z"}
{"id":"ssm-drq","title":"Index handoffs and beads at /close","description":"/close writes handoff but doesn't index it. Beads may change during session but aren't indexed. Gap means recent handoffs and beads aren't searchable until manual mem scan.","design":"## Current State\n\nSession-end hook indexes Claude Code sessions automatically via:\n- ~/.claude/hooks/session-end.sh\n- Calls: uv run mem process \u003csession.jsonl\u003e\n- Works: sessions searchable ~30-60s after close\n\nBut /close skill:\n- Writes handoff to ~/.claude/handoffs/{encoded-path}/{timestamp}.md\n- May close beads (bd close) or update bead notes\n- Does NOT trigger any indexing\n- Result: handoffs and beads require manual `mem scan`\n\n## The Gap\n\n| Source | Auto-indexed? | Trigger |\n|--------|--------------|---------|\n| Claude Code sessions | ✅ Yes | session-end hook |\n| Handoffs | ❌ No | /close writes but doesn't index |\n| Beads | ❌ No | bd commands don't trigger indexing |\n| Local markdown | ❌ No | Manual scan only |\n\n## Proposed Fix\n\nAdd to /close SKILL.md Act phase (after writing handoff, before commit):\n\n```bash\n# Index the handoff we just wrote + any beads changes\ncd ~/Repos/claude-memory \u0026\u0026 uv run mem scan --source handoffs --source beads\n```\n\nOr more targeted single-file indexing:\n```bash\nuv run mem process-handoff \u003chandoff-path\u003e\nuv run mem scan --source beads  # or just current project's beads\n```\n\n## Considerations\n\n1. **Performance**: Full scan of all handoffs/beads vs just current session's changes\n   - Full scan: ~1-2s for handoffs (75 files), ~1s for beads (400+ across projects)\n   - Targeted: Would need new commands or flags\n\n2. **Location**: The scan needs to run from claude-memory repo (uv context)\n   - /close may be in any project directory\n   - Need `cd ~/Repos/claude-memory \u0026\u0026` prefix\n\n3. **Beads scope**: Index all beads or just current project?\n   - Current project only: faster, but misses cross-project references\n   - All projects: slower, but complete\n   - Recommendation: All projects (beads are small, scan is fast)\n\n4. **Error handling**: If scan fails, should /close fail?\n   - Probably not — indexing is secondary to the handoff being written\n   - Log warning but continue\n\n## Implementation\n\n1. Edit ~/.claude/skills/session-closing/SKILL.md\n2. Add step after \"4c. Write handoff\" and before \"4d. Finalize handoff\":\n\n```markdown\n### 4c-ii. Index handoff and beads\n\nAfter writing handoff, index it for search:\n```bash\ncd ~/Repos/claude-memory \u0026\u0026 uv run mem scan --source handoffs --source beads 2\u003e/dev/null || echo \"Warning: indexing skipped\"\n```\n\nThis makes the handoff immediately searchable in future sessions.\n```\n\n## Related\n\n- claude-memory-axq: Field report about sessions not being searchable (FIXED - FTS sync)\n- claude-memory-5z2: Beads adapter (DONE - beads can now be indexed)\n- Session-end hook: ~/.claude/hooks/session-end.sh (working)\n\n## Acceptance Criteria\n\n- [ ] /close indexes the handoff it writes\n- [ ] /close indexes beads (at least current project)\n- [ ] Next session's /open can find previous handoff via mem search\n- [ ] Indexing failure doesn't block /close completion","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-02T21:26:59.526757Z","updated_at":"2026-01-03T16:00:17.129981Z","closed_at":"2026-01-03T16:00:17.129981Z","dependencies":[{"issue_id":"ssm-drq","depends_on_id":"ssm-0e2","type":"parent-child","created_at":"2026-01-03T15:12:06.076068Z","created_by":"modha","metadata":"{}"}]}
{"id":"ssm-f0n","title":"Make HANDOFF_DIR usage explicit in /close skill","description":"close-context.sh now outputs HANDOFF_DIR but /close skill doesn't reference it directly. Claude infers from encoding docs. Should be: 'Use HANDOFF_DIR from script output for handoff path.'","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-31T13:21:05.105562Z","updated_at":"2025-12-31T13:21:05.105562Z"}
{"id":"ssm-jg8","title":"Improve reflection prompting in /close","description":"Consider more open prompting ('what's on your mind?') vs specific questions that trigger off-topic responses. Current questions sometimes mismatch what user wants to discuss.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T09:51:20.392034Z","updated_at":"2026-01-03T15:51:59.076604Z","closed_at":"2026-01-03T15:51:59.076604Z","close_reason":"Closed in batch - deprioritized","dependencies":[{"issue_id":"ssm-jg8","depends_on_id":"ssm-524","type":"parent-child","created_at":"2026-01-03T15:12:04.917134Z","created_by":"modha","metadata":"{}"}]}
{"id":"ssm-k6g","title":"Field report: /close reflection questions compressed into multiple-choice","description":"During infra-openwrt session (2026-01-01), Claude compressed the /close reflection questions into a single AskUserQuestion with pre-baked multiple-choice options instead of asking open-ended questions.\n\n**What happened:**\n- User said \"wrap with /close now given context\"\n- Claude rushed due to perceived context pressure\n- Asked 4 questions in AskUserQuestion but reflection was multiple-choice: \"What stood out?\" with 4 pre-set options\n- Skipped open-ended questions like \"What did we miss?\", \"What should persist to CLAUDE.md?\"\n\n**What should have happened:**\n- Open-ended reflection: \"What haven't we done? What might we have missed?\"\n- Ask about CLAUDE.md persistence\n- Ask about gotchas for next session\n- Check if memory skill available and offer to index\n\n**Impact:**\n- User couldn't surface insights Claude hadn't pre-listed\n- Defeats the purpose of reflection (capturing what matters before context lost)\n- Rushing the close ritual is counterproductive\n\n**Root cause:**\n- \"given context\" interpreted as pressure to move fast\n- Irony: rushing close defeats its purpose","design":"## Potential fixes\n\n1. **Add explicit step in SKILL.md** - \"Ask open-ended reflection questions BEFORE structured questions\"\n\n2. **Template the questions** - Include exact questions to ask so they don't get compressed:\n   - \"What haven't we done? What might we have missed?\"\n   - \"Any learnings that should persist to CLAUDE.md?\"\n   - \"Gotchas the next session should know?\"\n\n3. **Memory skill check** - Add explicit step: \"Check if memory skill installed, offer to index\"\n\n4. **Anti-pattern note** - \"Don't compress reflection into multiple-choice - defeats the purpose\"","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-01T21:36:47.053277Z","updated_at":"2026-01-03T15:48:12.653545Z","closed_at":"2026-01-03T15:48:12.653545Z","dependencies":[{"issue_id":"ssm-k6g","depends_on_id":"ssm-524","type":"parent-child","created_at":"2026-01-03T15:12:04.879663Z","created_by":"modha","metadata":"{}"}]}
{"id":"ssm-l1a","title":"Update /open to read new handoff format","description":"The v2 /close writes richer handoffs (Gotchas, Commands, Risks sections). /open needs to surface these to the next Claude.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T18:00:55.299699Z","updated_at":"2025-12-29T18:12:45.368837Z","closed_at":"2025-12-29T18:12:45.368837Z","close_reason":"Already implemented in commit 68d6fa4. Verified working: /open correctly surfaced Gotchas, Commands, and Risks from v2 handoff."}
{"id":"ssm-ns0","title":"Remote session testing","description":"Verify hooked context output works in CLAUDE_CODE_REMOTE=true environments. Existing BD installation logic may need integration.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-03T11:07:48.831739Z","updated_at":"2026-01-03T11:07:48.831739Z"}
{"id":"ssm-pgl","title":"Polish open/close ritual edge cases","design":"Fixes identified from claude-memory research session (2025-12-28):\n\n## /open improvements\n1. **Plan \u003e Beads integration** — If plan file exists (spec.md, .claude/plans/*.md), reference it and show where ready beads fit in the larger plan\n2. **Scope mismatch detection** — Question incongruent handoffs based on cwd (don't blindly present handoff from project A when in project B)\n3. **Git distraction reduction** — Only surface uncommitted files if actually concerning; ignore .handoff, plan debris, normal session artifacts\n\n## /close improvements  \n4. **Phase counter** — Add \"Phase N of Q\" to output for situational awareness\n5. **Time greetings** — Get actual time via command, or drop time-based salutations entirely\n6. **Reflection closed-list energy** — Reframe Claude's observations as \"what resonates / what am I missing?\" not \"pick from this list\"\n7. **Reflection answer mismatch** — Consider more open prompting (\"what's on your mind?\") vs specific questions that trigger off-topic responses\n\n## Context\n- Friction patterns surfaced by analyzing /open and /close usage via claude-memory\n- User feedback: wants ritual to remember plan context, reduce cognitive load from non-issues, make reflection feel like dialogue not data collection","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T09:46:03.813829Z","updated_at":"2025-12-29T09:51:27.710138Z","closed_at":"2025-12-29T09:51:27.710138Z","close_reason":"Split into 7 individual beads: ssm-4f3, ssm-the, ssm-0yc, ssm-6x1, ssm-t9f, ssm-7lb, ssm-jg8"}
{"id":"ssm-s55","title":"Codify ritual prompts as structural scaffolding","description":"Observation: prompts like 'what have we missed?', 'what could go wrong?', 'what could be better?' are unreasonably effective but require user to remember to ask. These should be built into skill phase gates, hooks, or periodic nudges — not dependent on human memory.","notes":"SESSION 2025-12-29: Major pivot from original plan\n\nINTENDED: Iterate on v2 /close based on test\nACTUAL: Comprehensive /open and /close refactoring\n\nCOMPLETED:\n- Reviewed /open experience from fresh Claude perspective\n- Identified friction: hedging, non-actionable commands, no auto-expand, git noise\n- Simplified handoff storage: central-only (~/.claude/handoffs/-{path}/)\n- Removed: cross-project handoffs, episodic memory, git check in /open, local .handoff\n- Added: absolute timestamps, scope mismatch detection, actionable Commands to Resume\n- Moved draw-down content from /open to beads skill (gate forces skill load)\n- Consolidated gate check language (\"HALT\")\n- Migrated 73 existing handoffs to new folder structure\n- Tested gate with subagents to verify skill loading\n\nOBSERVATION: Claude paraphrases skill templates rather than following exactly.\nThis suggests skills are too complex — simpler = less room for interpretation.\n\nNEXT: Fresh Claude to review and potentially strip/rebuild both skills.","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-29T09:46:24.050547Z","updated_at":"2025-12-30T18:54:40.424611Z","closed_at":"2025-12-30T18:54:40.424611Z","close_reason":"Ritual prompts now structural: /close phase 5 reflection (AskUserQuestion) + global CLAUDE.md 'Approaching Closure' triggers. Delivered through v3 GODA refactor."}
{"id":"ssm-t7u","title":"Improve updater to surface actionable commands and consider hook vs manual /open","design":"Two parts: (1) When updates surface things like 'bd upgrade review', tell user to run them or offer to run them. (2) Consider whether updater should fire a hook automatically vs current manual /open ritual.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T09:48:17.149759Z","updated_at":"2025-12-29T09:51:41.630705Z","closed_at":"2025-12-29T09:51:41.630705Z","close_reason":"Split into 2 beads: one for actionable commands, one for hook vs manual decision"}
{"id":"ssm-t9f","title":"Fix time greetings in /close","description":"Get actual time via command, or drop time-based salutations entirely. Currently time is often wrong.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-29T09:51:20.304114Z","updated_at":"2025-12-29T09:51:20.304114Z","close_reason":"Added TIME section to open-context.sh and close-context.sh (NOW, TIME_OF_DAY, YEAR). Added inline date check to /ground. Claude now has accurate time for greetings and year awareness."}
{"id":"ssm-the","title":"Add scope mismatch detection to /open","description":"Question incongruent handoffs based on cwd — don't blindly present handoff from project A when in project B.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-29T09:51:11.165912Z","updated_at":"2025-12-29T09:51:11.165912Z","close_reason":"Deprioritized - edge case"}
{"id":"ssm-vjf","title":"Consider hook vs manual /open trigger","description":"Should updater fire a hook that auto-triggers /open behavior, or keep current manual ritual? Trade-off between convenience and user control.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-29T09:51:41.607668Z","updated_at":"2025-12-29T14:30:41.463505Z","closed_at":"2025-12-29T14:30:41.463505Z","close_reason":"Decision: keep manual /open separate from auto-update hook. Hook does hygiene (updates, bd doctor), /open does context loading. This gives user control - sometimes memoryless sessions are useful."}
{"id":"ssm-vnb","title":"Field Report: open-context.sh should show hub status when in ~/Repos","description":"Session opening doesn't surface hub availability, making cross-project features undiscoverable.","design":"## Context\nUser asked about 'central DB across all repos'. Claude didn't know about the hub feature despite it being set up and working.\n\n## Observation\nopen-context.sh runs `bd ready` from current directory but doesn't indicate when you're in a hub with aggregated cross-project view available. The hub concept (~/Repos/.beads aggregating all projects) was invisible until user prompted reading the beads skill thoroughly.\n\n## Suggestion\nWhen cwd is ~/Repos (or any directory with a hub .beads that has additional repos registered):\n- Show hub indicator in BEADS section\n- Maybe show `bd-portfolio.sh` summary or mention it's available\n- Surface `bd activity --town` as an option\n\nThis would make cross-project features discoverable at session start.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-03T14:57:10.857538Z","updated_at":"2026-01-03T14:57:10.857538Z","labels":["field-report"]}
{"id":"ssm-w7o","title":"Error handling for hook failures","description":"Graceful degradation if session-start hook or open-context.sh fails. User should see something rather than silent failure.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-03T11:07:47.784131Z","updated_at":"2026-01-03T11:07:47.784131Z"}
{"id":"ssm-x06","title":"Add plan file cleanup to /close ritual","description":"When closing an epic, /close should detect and handle associated plan files.","design":"## Approach\n1. Detect plan files matching epic (by ID in filename or content)\n2. Offer: archive or delete\n3. If archive, move to ~/.claude/plans/archive/{name}-{date}.md\n\n## Where\nAdd to Phase 3 (Execute) in session-closing SKILL.md, after beads updates.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T09:46:12.366472Z","updated_at":"2026-01-03T16:10:10.537154Z","closed_at":"2026-01-03T16:10:10.537154Z","close_reason":"Premise was flawed: plan files aren't tied to beads/epics, they're tied to sessions (filename = session whimsical name).\n\nFinding: Claude Code's plan association is purely filename-based — no metadata linking plans to beads. A session might work on multiple beads, a bead might span sessions. The imagined spec↔beads linkage doesn't exist.\n\nCleanup options identified but belong elsewhere:\n- Age-based: find ~/.claude/plans -mtime +30 -delete\n- Session-based: offer cleanup at session end (would go in /close)\n- Manual: periodic review\n\nIf session-based cleanup is wanted, file a new bead with correct framing.","dependencies":[{"issue_id":"ssm-x06","depends_on_id":"ssm-4f3","type":"blocks","created_at":"2025-12-29T14:34:30.525135Z","created_by":"daemon","metadata":"{}"}]}
{"id":"ssm-x8h","title":"Figure out how to update draft handoff before finishing with /exit","description":"Handoff is a living document during /close. Late additions emerge from the reflection conversation. Currently we append manually, but could be more structured - e.g., a 'finalize handoff' step before /exit that prompts for additions.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-29T18:09:58.146602Z","updated_at":"2025-12-29T18:09:58.146602Z","close_reason":"Added 4d (Finalize handoff) step: explicit 'anything to add?' checkpoint before commit. Also added instruction after 4c to state handoff is living until commit."}
{"id":"ssm-zxc","title":"Add .hook-trace rotation","description":"The timing telemetry file ~/.claude/.hook-trace will grow unbounded. Add rotation or cleanup mechanism.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-03T20:26:15.000914Z","updated_at":"2026-01-03T20:26:15.000914Z"}
